#### Phrase Retrieval Learns Passage Retrieval, Too 

#### 摘要

在多种自然语言处理（NLP）任务中，稠密检索方法相较于稀疏检索方法展现了巨大的潜力。其中，稠密短语检索——最细粒度的检索单元——因其短语可以直接作为问答和槽填充任务的输出而备受关注。${ }^{1}$ 在本研究中，我们基于“检索短语自然涉及检索更大文本块”的直觉，探讨了短语检索是否可以作为包括段落和文档在内的粗粒度检索的基础。我们首先观察到，一个未经任何重新训练的稠密短语检索系统在段落检索准确率上已经优于段落检索器（在Top-5准确率上提升$+3-5\%$），这也有助于在输入更少段落的情况下实现更优的端到端问答性能。接着，我们解释了为什么短语级别的监督比段落级别的监督更有助于学习更好的细粒度蕴含关系，并展示了短语检索可以在文档检索任务（如实体链接和基于知识的对话）中通过改进实现具有竞争力的性能。最后，我们展示了如何通过短语过滤和向量量化将索引大小减少$4-10$倍，使稠密短语检索成为多粒度检索中实用且通用的解决方案。${ }^{2}$

## 1 引言

稠密检索旨在通过为查询和文本片段学习稠密表示，从大规模语料库中检索相关上下文。最近，段落稠密检索（Lee et al., 2019; Karpukhin et al., 2020; Xiong et al., 2021）在一系列知识密集型NLP任务（Petroni et al., 2021）中表现优于传统的稀疏检索方法（如TF-IDF和BM25），这些任务包括开放域问答（QA）（Chen et al., 2017）、实体链接（Wu et al., 2020）和基于知识的对话（Dinan et al., 2019）。

---

这些稠密检索方法的一个自然设计选择是检索单元。例如，稠密段落检索器（DPR）（Karpukhin et al., 2020）将固定大小的100词文本块编码为基本检索单元。而在另一个极端，最近的研究（Seo et al., 2019; Lee et al., 2021）表明，短语也可以作为检索单元。特别是，Lee et al. (2021) 证明，仅学习短语的稠密表示就能在多种开放域问答和槽填充任务中实现具有竞争力的性能。这一点尤其吸引人，因为短语可以直接作为输出，而无需依赖额外的阅读器模型来处理文本段落。

---

在本研究中，我们基于一个直观的动机：每个短语都嵌入在更大的文本上下文中，并提出了以下问题：如果一个检索器能够定位短语，我们是否可以直接将其用于段落甚至文档检索？我们提出了基于短语的段落检索方法，其中段落的得分由其内部短语的最大得分决定（见图1的示意图）。通过在流行的问答数据集上评估DensePhrases（Lee et al., 2021），我们观察到，与DPR相比，它在段落检索准确率上实现了具有竞争力甚至更好的性能，且无需对原始模型进行任何重新训练或修改（表1）。当$k$较小时（例如5），Top-$k$准确率的提升尤为显著，这也有助于在使用更少段落作为生成式阅读器模型输入的情况下实现强大的开放域问答准确率（Izacard and Grave, 2021b）。

- 图1：DPR（Karpukhin et al., 2020）和DensePhrases（Lee et al., 2021）段落表示的比较。与为每个段落使用单一向量不同，DensePhrases用多个短语向量表示每个段落，段落的得分可以通过其内部短语的最大得分计算。
- 表1：开放域问答段落检索结果。我们使用公式（3）从DensePhrases中检索Top $k$段落。我们报告了Top-$k$段落检索准确率（Top-$k$）、$k$处的平均倒数排名（MRR @ $k$）和$k$处的精确率（$\mathrm{P} @ k$）。$\diamond$：在每个数据集上独立训练。${ }^{\star}$：在多个开放域问答数据集上训练。更多细节见$\S 3.1$。${ }^{\dagger}$：（Yang and Seo, 2020）。${ }^{\ddagger}$：（Karpukhin et al., 2020）。

---

为了更好地理解稠密检索方法的本质，我们仔细分析了短语检索和段落检索方法的训练目标。尽管两种模型中的批内负样本损失都鼓励它们检索主题相关的段落，但我们发现，DensePhrases中的短语级别监督比使用BM25的硬负样本提供了更强的训练信号，并帮助DensePhrases检索到正确的短语，从而检索到正确的段落。基于这一积极发现，我们进一步探讨了短语检索是否可以扩展到更粗粒度的检索或其他NLP任务。通过在文档级别监督下微调查询编码器，我们能够在KILT基准测试（Petroni et al., 2021）中的实体链接（Hoffart et al., 2011）和基于知识的对话检索（Dinan et al., 2019）任务中取得具有竞争力的性能。

---

最后，我们将其与多向量段落编码模型（Khattab and Zaharia, 2020; Luan et al., 2021）联系起来，其中短语检索模型可以被视为为每个段落学习一组动态向量。我们展示了一种从问答数据集中学习的简单短语过滤策略，使我们能够控制每个段落的向量数量与检索准确率之间的权衡。由于短语检索器编码了更多的向量，我们还提出了一种基于优化乘积量化（Ge et al., 2013）的量化感知微调方法，将全英文维基百科的短语索引大小从307 GB减少到69 GB（或通过更激进的短语过滤减少到30 GB以下），且没有任何性能损失。这与段落检索器的索引大小相匹配，使稠密短语检索成为多粒度检索中实用且通用的解决方案。

## 2 背景

段落检索。给定一组文档$\mathcal{D}$，段落检索旨在为问题$q$提供一组相关段落。通常，$\mathcal{D}$中的每个文档被分割为一组不重叠的段落，我们将$\mathcal{D}$中的所有段落集合表示为$\mathcal{P}=\left\{p_{1}, \ldots, p_{M}\right\}$，其中每个段落可以是一个自然段落或固定长度的文本块。段落检索器的设计目标是返回Top-$k$段落$\mathcal{P}_{k} \subset \mathcal{P}$，以检索与问题相关的段落。在开放域问答中，如果段落包含问题的答案，则被视为相关段落。然而，许多其他知识密集型NLP任务（例如基于知识的对话）提供了人工标注的证据段落或文档。

---

传统的段落检索模型依赖于稀疏表示（如BM25）（Robertson and Zaragoza, 2009），而最近的方法通过段落和问题的稠密表示展现了有希望的结果，并能够检索与问题词汇重叠较少的段落。具体而言，Karpukhin et al. (2020) 引入了DPR，它包含一个段落编码器$E_{p}(\cdot)$和一个问题编码器$E_{q}(\cdot)$，并在问答数据集上训练，通过使用内积作为段落和问题之间的相似度函数来检索段落：

$$
\begin{equation*}
f(p, q)=E_{p}(p)^{\top} E_{q}(q) . \tag{1}
\end{equation*}
$$

对于需要提供确切答案字符串$a$的开放域问答，检索到的Top $k$段落$\mathcal{P}_{k}$随后被输入到阅读理解模型（如BERT模型）（Devlin et al., 2019）中，这被称为检索器-阅读器方法（Chen et al., 2017）。

---

短语检索。尽管段落检索器需要另一个阅读器模型来找到答案，Seo et al. (2019) 引入了短语检索方法，该方法对每个文档中的短语进行编码，并在所有短语向量上执行相似性搜索以直接定位答案。根据之前的工作（Seo et al., 2018, 2019），我们使用“短语”一词来表示任何长度不超过$L$个词的连续文本片段（包括单个词），它不一定是语言学意义上的短语，我们取长度$L=20$以内的短语。给定来自段落$p$的短语$s^{(p)}$，它们的相似性函数$f$计算如下：

$$
\begin{equation*}
f\left(s^{(p)}, q\right)=E_{s}\left(s^{(p)}\right)^{\top} E_{q}(q) \tag{2}
\end{equation*}
$$

其中$E_{s}(\cdot)$和$E_{q}(\cdot)$分别表示短语编码器和问题编码器。由于这将开放域问答纯粹形式化为最大内积搜索（MIPS），因此可以显著提高端到端效率。尽管之前的工作（Seo et al., 2019; Lee et al., 2020）依赖于稠密和稀疏向量的组合，Lee et al. (2021) 证明，仅使用短语的稠密表示就足以缩小与检索器-阅读器系统的性能差距。有关短语表示学习的更多细节，我们建议感兴趣的读者参考Lee et al. (2021)。

## 3 短语检索用于段落检索

短语自然有其提取的源文本。基于这一事实，我们定义了一种简单的基于短语的段落检索策略，其中我们根据短语检索得分来检索段落：

$$
\begin{equation*}
\tilde{f}(p, q):=\max _{s^{(p)} \in \mathcal{S}(p)} E_{s}\left(s^{(p)}\right)^{\top} E_{q}(q), \tag{3}
\end{equation*}
$$

其中$\mathcal{S}(p)$表示段落$p$中的短语集合。在实践中，我们首先检索稍多数量的短语，计算每个段落的得分，并返回Top $k$个唯一段落。${ }^{3}$ 根据我们的定义，短语可以作为任何其他粒度（如句子或文档）的基本检索单元，只需更改$\mathcal{S}(p)$（例如，对于文档$d$，$s^{(d)} \in \mathcal{S}(d)$）。需要注意的是，由于得分聚合的成本可以忽略不计，基于短语的段落检索的推理速度与短语检索相同，这在Lee et al. (2021) 中被证明是高效的。在本节中，我们评估了段落检索性能（公式（3）），以及基于短语的段落检索如何为端到端开放域问答做出贡献。

### 3.1 实验：段落检索

数据集。我们使用两个开放域问答数据集：Natural Questions（Kwiatkowski et al., 2019）和TriviaQA（Joshi et al., 2017），遵循开放域问答评估的标准训练/开发/测试划分。对于这两个模型，我们使用2018-12-20的维基百科快照。为了提供公平的比较，我们使用为DPR预处理的维基百科文章，这些文章被分割为2100万个文本块，每个文本块恰好包含100个词。需要注意的是，DPR在这种设置下训练，而DensePhrases使用自然段落进行训练。${ }^{4}$

---

模型。对于DPR，我们使用公开可用的检查点${ }^{5}$，这些检查点分别在每个数据集上训练（$\mathrm{DPR}^{\diamond}$）或在多个问答数据集上训练（DPR ${ }^{*}$），我们发现它们的性能略优于Karpukhin et al. (2020) 中报告的结果。对于DensePhrases，我们使用作者提供的代码${ }^{6}$在Natural Questions（DensePhrases ${ }^{\diamond}$）或多个问答数据集（DensePhrases ${ }^{\wedge}$）上训练。需要注意的是，我们没有对DensePhrases的架构或训练方法进行任何修改，并实现了与报告中相似的开放域问答准确率。对于基于短语的段落检索，我们使用DensePhrases计算公式（3）并返回Top $k$个段落。

---

指标。根据之前关于开放域问答段落检索的工作，我们测量Top-$k$段落检索准确率（Top-$k$），它表示Top $k$个检索段落中至少包含一个正确答案的问题比例。为了进一步描述每个系统的行为，我们还包含以下评估指标：$k$处的平均倒数排名（MRR@ $k$）和$k$处的精确率（$\mathrm{P} @ k$）。MRR@ $k$是Top $k$段落中第一个相关段落（包含答案）的平均倒数排名。MRR@ $k$越高，表示相关段落出现在更高的排名。同时，$\mathrm{P} @ k$是Top $k$段落中相关段落的平均比例。$\mathrm{P} @ k$越高，表示Top $k$段落中包含答案的比例越大。

---

结果。如表1所示，DensePhrases在段落检索准确率上与DPR具有竞争力，同时在Natural Questions（Top-1准确率$+6.9 \%$）和TriviaQA（Top-1准确率$+8.1 \%$）的Top-1或Top-5准确率上具有明显优势。尽管Top-20（以及未显示的Top-100）准确率在不同模型之间相似，但MRR@20和P@20揭示了DensePhrases的有趣特性——它将相关段落排名更高，并提供更多正确的段落。我们的结果表明，DensePhrases即使没有明确针对段落检索进行训练，也能非常准确地检索段落。在本文的其余部分，我们主要比较DPR 和DensePhrases 模型，它们都在多个问答数据集上进行了训练。

### 3.2 实验：开放域问答

最近，Izacard和Grave（2021b）提出了Fusion-in-Decoder（FiD）方法，他们将DPR检索到的Top 100段落输入到生成模型T5（Raffel et al., 2020）中，并在开放域问答基准测试中取得了最先进的性能。由于他们的生成模型需要计算100段落中所有Token的隐藏状态，因此需要大量的GPU内存，Izacard和Grave（2021b）使用了64块Tesla V100 32GB GPU进行训练。

---

在本节中，我们使用基于DensePhrases的短语段落检索来替代FiD中的DPR，并探讨是否可以使用更少的段落实现可比的性能，从而大大减少计算需求。我们使用4块24GB RTX GPU训练T5-base模型，这在学术预算范围内更为可行。需要注意的是，使用5或10段落训练T5-base也可以在11GB GPU上完成。我们保持所有超参数与Izacard和Grave（2021b）相同。${ }^{7}$

---

结果。如表2所示，使用DensePhrases作为段落检索器在基于DPR的FiD中实现了具有竞争力的性能，并显著提升了原始DensePhrases的性能（NQ = 41.3 EM，无需阅读器）。在较小的$k$值下，其更好的Top-$k$检索质量确实转化为更好的开放域问答准确率，当$k=5$时，与基于DPR的FiD相比，性能提升了$+6.4 \%$。为了在使用100段落的FiD中获得类似的性能，DensePhrases需要更少的段落（$k=25$或50），这可以适应内存较小的GPU。

- 表2：开放域问答结果。我们通过将Top $k$段落输入T5-base模型来报告每个模型的精确匹配（EM）。DensePhrases可以大大降低运行生成阅读器模型的计算成本，同时保持具有竞争力的性能。

## 4 稠密检索的统一视角

如前一节所示，基于短语的段落检索能够实现具有竞争力的段落检索准确率，尽管模型并未明确针对此进行训练。在本节中，我们详细比较了DPR和DensePhrases的训练目标，并解释了DensePhrases如何学习段落检索。

### 4.1 训练目标

DPR和DensePhrases都旨在学习段落或短语与问题之间的相似性函数$f$。段落和短语的主要区别在于特征长度，因此我们将它们统称为检索单元$x .^{8}$ DPR和DensePhrases均采用双编码器方法，并使用内积相似性，如公式（1）和（2）所示，它们分别使用BERT（Devlin et al., 2019）和SpanBERT（Joshi et al., 2020）进行初始化。

---

这些双编码器模型通过负对数似然损失进行训练，以区分正检索单元和负检索单元：

$$
\begin{equation*}
\mathcal{L}=-\log \frac{e^{f\left(x^{+}, q\right)}}{e^{f\left(x^{+}, q\right)}+\sum_{x^{-} \in \mathcal{X}^{-}} e^{f\left(x^{-}, q\right)}} \tag{4}
\end{equation*}
$$

其中$x^{+}$是与问题$q$对应的正短语或段落，$\mathcal{X}^{-}$是负样本集合。负样本的选择在此设置中至关重要，DPR和DensePhrases都对此进行了重要调整。

---

**批内负样本**。批内负样本是定义$\mathcal{X}^{-}$的常见方式，因为在编码一个小批次的样本时，它们无需额外成本即可获得。具体来说，在一个包含$B$个样本的小批次中，我们可以为每个正样本添加$B-1$个批内负样本。由于每个小批次是从所有训练段落中随机抽取的，批内负样本通常在主题上是负相关的，即模型可以仅根据主题来区分$x^{+}$和$\mathcal{X}^{-}$。

---

**硬负样本**。尽管与主题相关的特征在识别广泛相关的段落时很有用，但它们通常缺乏在大型语料库中精确定位包含答案的段落的精度。Karpukhin et al. (2020) 提出使用额外的硬负样本，这些负样本与给定问题具有较高的BM25词汇重叠，但不包含答案。这些硬负样本可能共享相似的主题，并鼓励DPR学习更细粒度的特征，以将$x^{+}$排在硬负样本之上。图2（左）展示了一个示例。

- 图2：DPR和DensePhrases训练目标的比较。虽然两种模型都使用批内负样本，但DensePhrases使用段落内负样本（短语），而DPR使用BM25硬负样本段落。需要注意的是，DensePhrases中的每个短语都可以直接作为开放域问题的答案。

---

**段落内负样本**。虽然DPR仅限于使用包含答案的正段落$x^{+}$，但DensePhrases被训练为预测正短语$x^{+}$是答案。因此，短语的细粒度结构提供了另一种负样本来源，即段落内负样本。具体来说，DensePhrases将负样本集合$\mathcal{X}^{-}$扩展为包含同一段落中不表达答案的所有短语。${ }^{9}$ 参见图2（右）的示例。我们假设这些段落内负样本实现了与DPR的硬负样本类似的效果：它们要求模型超越简单的主题建模，因为它们不仅共享相同的主题，还共享相同的上下文。我们的基于短语的段落检索器可能受益于这种短语级别的监督，这已经在从阅读器到检索器的知识蒸馏背景下被证明是有用的（Izacard和Grave，2021a；Yang和Seo，2020）。

### 4.2 主题负样本 vs. 硬负样本

为了验证我们的假设，我们希望研究DPR和DensePhrases使用的这些不同类型的负样本如何影响它们对主题和细粒度蕴含线索的依赖。我们基于两个指标（损失）来表征它们的段落检索性能：$\mathcal{L}_{\text {topic }}$和$\mathcal{L}_{\text {hard }}$。我们使用公式（4）定义$\mathcal{L}_{\text {topic }}$和$\mathcal{L}_{\text {hard }}$，但使用不同的负样本集合$\mathcal{X}^{-}$。对于$\mathcal{L}_{\text {topic }}$，$\mathcal{X}^{-}$包含与黄金段落主题不同的段落——在实践中，我们从英文维基百科中随机抽取段落。对于$\mathcal{L}_{\text {hard }}$，$\mathcal{X}^{-}$使用包含主题相似段落的负样本，因此$\mathcal{L}_{\text {hard }}$估计模型在主题相似的段落中精确定位包含确切答案的段落的准确性。从与问题配对的正段落中，我们通过删除包含答案的句子创建一个硬负样本。${ }^{10}$ 在我们的分析中，这两个指标均在Natural Questions开发集上估计，该开发集提供了一组问题和（黄金）正段落。

---

结果。图3展示了在NQ上训练的DPR和DensePhrases与两种损失的比较。对于DensePhrases，我们使用公式（3）中描述的$\tilde{f}(p, q)$计算段落得分。首先，我们观察到批内负样本在降低$\mathcal{L}_{\text {topic }}$方面非常有效，因为仅使用段落内负样本训练的DensePhrases具有相对较高的$\mathcal{L}_{\text {topic }}$。此外，我们观察到在DensePhrases中使用段落内负样本（+in-passage）显著降低了$\mathcal{L}_{\text {hard }}$，甚至低于使用BM25硬负样本的DPR（+BM25）。使用多个数据集（+multi. dataset）进一步改善了两种模型的$\mathcal{L}_{\text {hard }}$。DPR的$\mathcal{L}_{\text {topic }}$通常比DensePhrases更好（更低），这可能是由于DensePhrases的训练批次大小较小（因此批内负样本数量较少）所致。结果表明，DensePhrases对主题特征的依赖较少，并且更擅长基于细粒度蕴含线索检索段落。这可能有助于表1中检索段落的更好排名，其中DensePhrases在MRR@20和$\mathrm{P} @ 20$上表现更好，而Top-20准确率相似。

- 图3：DPR和DensePhrases在NQ（开发集）上$\mathcal{L}_{\text {topic }}$和$\mathcal{L}_{\text {hard }}$的比较。从每个使用批内负样本训练的模型（in-batch）开始，我们展示了使用硬负样本（+BM25）、段落内负样本（+in-passage）以及在多个问答数据集上训练（+multi. dataset）的效果。$x$轴采用对数刻度以便更好地可视化。对于这两个指标，数值越低越好。

---

DensePhrases是否需要硬负样本？我们在DensePhrases中测试了两种不同类型的硬负样本，以查看在存在段落内负样本的情况下其性能是否可以进一步提高。对于每个训练问题，我们通过BM25相似性或找到包含黄金答案短语但可能上下文错误的另一个段落来挖掘硬负样本段落。然后，我们将硬负样本段落中的所有短语作为额外的硬负样本添加到$\mathcal{X}^{-}$中，与现有的段落内负样本一起。如表3所示，DensePhrases在使用额外硬负样本后并未获得实质性改进，这表明段落内负样本在生成良好的短语（或段落）表示方面已经非常有效。

- 表3：在NQ开发集上使用硬负样本对DensePhrases的影响。我们报告了在给定单个黄金段落$(\mathcal{D}=\{p\})$或从NQ开发集中收集所有黄金段落提供的6K段落（$\mathcal{D}=\mathcal{D}_{\text {small }}$）时的EM。这两种硬负样本并未对DensePhrases带来明显改进。

---

**注**：本文中的“Token”均保留原文，未进行翻译。

## 5 改进粗粒度检索

虽然我们展示了DensePhrases隐式地学习了段落检索，但图3表明，DensePhrases可能不太适合那些主题比细粒度蕴含更重要的检索任务，例如为实体链接检索单一证据文档。在本节中，我们提出了一种简单的方法，可以使DensePhrases适应更大的检索单元，尤其是在主题相关性更为重要的情况下。

---

方法。我们修改了Lee et al. (2021) 提出的查询端微调方法，该方法通过减少训练和推理时间之间的差异，显著提升了DensePhrases的性能。由于在索引后更新大量短语表示是不可行的，因此仅对查询编码器在维基百科中的所有短语集上进行微调。给定问题$q$和标注文档集$\mathcal{D}^{*}$，我们最小化：

$$
\begin{equation*}
\mathcal{L}_{\mathrm{doc}}=-\log \frac{\sum_{s \in \tilde{\mathcal{S}}(q), d(s) \in \mathcal{D}^{*}} e^{f(s, q)}}{\sum_{s \in \tilde{\mathcal{S}}(q)} e^{f(s, q)}} \tag{5}
\end{equation*}
$$

其中$\tilde{\mathcal{S}}(q)$表示从所有短语向量中为问题$q$检索到的Top $k$短语。为了更好地检索粗粒度文本，我们只需检查条件$d(s) \in \mathcal{D}^{*}$，这意味着$s$的源文档$d(s)$包含在问题标注的黄金文档集$\mathcal{D}^{*}$中。通过$\mathcal{L}_{\text {doc }}$，模型被训练为检索包含在相关文档中的任何短语。需要注意的是，$d(s)$可以更改为反映任何所需的粒度级别，例如段落。

---

数据集。我们在KILT（Petroni et al., 2021）中的实体链接（Hoffart et al., 2011; Guo and Barbosa, 2018）和基于知识的对话（Dinan et al., 2019）任务上测试了使用$\mathcal{L}_{\mathrm{doc}}$训练的DensePhrases。实体链接包含三个数据集：AIDA CoNLL-YAGO (AY2)（Hoffart et al., 2011）、WNED-WIKI (WnWi)（Guo and Barbosa, 2018）和WNED-CWEB (WnCw)（Guo and Barbosa, 2018）。实体链接数据集中的每个查询都包含用特殊标记（即[START_ENT], [END_ENT]）标注的命名实体，这些实体需要链接到维基百科文章之一。对于基于知识的对话，我们使用Wizard of Wikipedia (WoW)（Dinan et al., 2019），其中每个查询由对话历史组成，生成的对话应基于维基百科文章之一。我们遵循KILT指南，评估模型在给定每个查询时的文档（即维基百科文章）检索性能。我们使用R-precision，即Top $R$结果中成功检索到的页面比例，其中$R$是出处集中不同页面的数量。然而，在所考虑的任务中，R-precision等同于precision@1，因为每个问题仅标注了一个文档。

---

模型。DensePhrases使用原始查询端微调损失（记为$\mathcal{L}_{\text {phrase }}$）或公式（5）中的$\mathcal{L}_{\mathrm{doc}}$进行训练。当DensePhrases使用$\mathcal{L}_{\text {phrase }}$训练时，它将任何匹配黄金文档标题的短语标记为正样本。训练后，DensePhrases返回包含Top段落的文档。对于基线检索方法，我们报告了Petroni et al. (2021) 中TF-IDF和DPR的性能。我们还包含了DPR和DensePhrases的多任务版本，它们使用整个KILT训练数据集。${ }^{11}$ 虽然这不是我们主要的比较重点，但我们还报告了Petroni et al. (2021) 中其他基线的性能，这些基线使用生成模型（例如RAG（Lewis et al., 2020））或任务特定模型（例如BLINK（Wu et al., 2020），它进行了额外的实体链接预训练）。需要注意的是，这些方法在检索模型之上使用了额外的组件，例如生成模型或交叉编码器模型。

---

结果。表4显示了在三个实体链接任务和一个基于知识的对话任务上的结果。在所有任务中，我们发现使用$\mathcal{L}_{\text {doc }}$的DensePhrases比使用$\mathcal{L}_{\text {phrase }}$的DensePhrases表现更好，并且与使用额外大型生成模型生成文档标题的RAG性能相当。使用$\mathcal{L}_{\text {phrase }}$表现非常差，因为它专注于短语级别的蕴含，而不是文档级别的相关性。与DPR的多任务版本（即DPR*）相比，DensePhrases-$\mathcal{L}_{\text {doc }}{ }^{\boldsymbol{\phi}}$可以轻松适应非问答任务（如实体链接），并在没有训练集的任务（$\mathrm{WnWi}, \mathrm{WnCw}$）上具有更好的泛化能力。

- 表4：KILT测试集上的结果。我们在每个任务上报告了页面级别的R-precision，在这些数据集上等同于precision@1。*：多任务模型。

---

**注**：本文中的“Token”均保留原文，未进行翻译。

## 6 DensePhrases作为多向量段落编码器

在本节中，我们展示了DensePhrases可以被解释为一种多向量段落编码器，最近的研究表明这种方法在段落检索中非常有效（Luan et al., 2021; Khattab and Zaharia, 2020）。由于这种多向量编码模型需要较大的磁盘空间，我们展示了如何通过过滤控制每个段落的向量数量（从而减少索引大小）。我们还引入了量化技术，以构建更高效的短语检索模型，而不会显著降低性能。

### 6.1 多向量编码

由于我们不是用单一向量表示段落，而是用一组短语向量（分解为Token级别的起始和结束向量，参见Lee et al. (2021)），我们注意到这与之前的工作有相似之处，这些工作解决了稠密、固定长度段落编码的容量限制问题。虽然这些方法为每个段落存储固定数量的向量（Luan et al., 2021; Humeau et al., 2020）或所有Token级别的向量（Khattab and Zaharia, 2020），但短语检索模型为每个段落存储动态数量的短语向量，其中许多短语通过基于问答数据集训练的模型进行过滤。

---

具体来说，Lee et al. (2021) 训练了一个二元分类器（或短语过滤器），根据短语表示过滤短语。该短语过滤器由问答数据集中的答案标注进行监督，因此标记为候选答案短语。在我们的实验中，我们调整过滤阈值以控制段落检索中每个段落的向量数量。

### 6.2 高效短语检索

多向量编码模型以及我们的模型由于为整个语料库中的每个段落存储多个向量表示，因此占用空间巨大。我们引入了一种基于向量量化的方法，可以在不降低性能的情况下安全地减少短语索引的大小。

---

优化乘积量化。由于多向量编码模型因其多个表示而占用空间巨大，我们进一步引入了一种基于向量量化的方法，可以在不降低性能的情况下安全地减少短语索引的大小。我们使用乘积量化（PQ）（Jegou et al., 2010），其中原始向量空间被分解为子空间的笛卡尔积。使用PQ，使用$N$个$d$维中心向量的内存占用从$N d$减少到$N^{1 / M} d$，其中$M$为子空间数量，而每个数据库向量需要$\log _{2} N$位。在PQ的不同变体中，我们使用优化乘积量化（OPQ）（Ge et al., 2013），它学习一个正交矩阵$R$以更好地分解原始向量空间。有关OPQ的更多细节，请参见Ge et al. (2013)。

---

量化感知训练。尽管这种激进的向量量化可以显著减少内存使用，但它通常会因量化损失而导致性能下降。为了缓解这个问题，我们使用量化感知查询端微调，这受到了最近量化感知训练成功案例的启发（Jacob et al., 2018）。具体来说，在查询端微调期间，我们使用训练好的（优化后的）乘积量化器重建短语向量，然后用于最小化公式（5）。

### 6.3 实验结果

在图4中，我们展示了DensePhrases中不同短语索引大小下的Top-5段落检索准确率。首先，应用优化乘积量化（OPQ）可以将DensePhrases的索引大小从307GB减少到69GB，但在没有量化感知查询端微调的情况下，Top-5检索准确率较差。此外，通过调整短语过滤器的阈值$\tau$，可以减少每个段落的向量数量（\# vec / $p$），而不会显著影响性能。性能随着每个段落向量数量的增加而提高，这与多向量编码模型的发现一致（Khattab and Zaharia, 2020; Luan et al., 2021）。我们的结果表明，DensePhrases中每个段落有8.8个向量时，其检索准确率与DPR相似。

- 图4：Natural Questions（开发集）上不同索引大小的DensePhrases的Top-5段落检索准确率。索引大小（GB）和每个段落保存的平均向量数量（\# vec / $p$）通过过滤阈值$\tau$控制。例如，随着$\tau$的增加，\# vec / $p$从28.0减少到5.1，索引大小也从69GB减少到23GB。OPQ：优化乘积量化（Ge et al., 2013）。

## 7 相关工作

文本检索在信息检索领域有着悠久的历史，无论是直接为用户提供相关信息，还是将其输入计算成本高昂的下游系统。传统研究主要集中在设计启发式方法，例如稀疏向量模型（如TF-IDF和BM25），而最近它已成为机器学习研究者的活跃研究领域。这一趋势由开放域问答作为标准问题设置的兴起（Chen et al., 2017）以及检索器-阅读器范式的普及（Yang et al., 2019; Nie et al., 2019）所推动。研究兴趣已扩展到包括更多样化的下游任务，例如事实核查（Thorne et al., 2018）、实体链接（Wu et al., 2020）或对话生成（Dinan et al., 2019），这些问题需要访问大规模语料库或知识源。最近，REALM（Guu et al., 2020）和RAG（检索增强生成）（Lewis et al., 2020）被提出为通用预训练模型，通过检索器显式访问世界知识。还有一系列工作将文本检索与结构化知识图谱相结合（Sun et al., 2018, 2019; Min et al., 2020）。我们建议参考Lin et al. (2020) 以全面了解神经文本检索方法。

## 8 结论

在本文中，我们展示了短语检索模型无需任何修改即可学习段落检索。通过分析DPR和DensePhrases的目标之间的联系，我们更好地理解了短语检索如何学习段落检索，这也在多个基准测试的实证评估中得到了支持。具体来说，基于短语的段落检索在$k$较小时对Top $k$段落具有更好的检索质量，这转化为开放域问答中段落的高效使用。我们还展示了DensePhrases可以针对更粗粒度的检索单元进行微调，作为任何检索单元的基础。我们计划进一步评估基于短语的段落检索在标准信息检索任务（如MS MARCO）中的表现。

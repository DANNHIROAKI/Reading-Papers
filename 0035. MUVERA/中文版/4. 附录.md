

## A 第 2.1 节的缺失证明  

在本节中，我们提供了第 2.1 节中缺失的证明。为方便起见，我们在证明前重新列出了主文中出现的定理陈述。我们首先分析计算查询和文档 FDE 的运行时间，以及查询的稀疏性。  

**引理 A.1** 对于任意 FDE 参数 $k_{\text{sim}}$, $d_{\text{proj}}$, $R_{\text{reps}} \geqslant 0$ 和集合 $Q, P \subset \mathbb{R}^{d}$，我们可以在时间  

$$
T_{q}:=O\left(R_{\text {reps }}|Q| d\left(d_{\text {proj }}+k_{\text {sim }}\right)\right)
$$

内计算 $\mathbf{F}_{q}(Q)$，以及在时间  

$$
O\left(T_{q}+R_{\text {reps }}|P| 2^{k_{\text {sim }}} k_{\text {sim }}\right)
$$

内计算 $\mathbf{F}_{q}(P)$。此外，$\mathbf{F}_{q}(Q)$ 的非零项最多为  

$$
O\left(|Q| d_{\text {proj }} R_{\text {reps }}\right)。
$$

**证明** 我们首先考虑查询。为了生成查询，首先需要通过内部随机线性投影 $\psi_{i}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d_{\mathrm{proj}}}$ 投影 $|Q|$ 个查询。这一步需要  

$$
O\left(|Q| d d_{\mathrm{proj}} R_{\mathrm{reps}}\right)
$$

的时间，用于所有重复次数的矩阵-查询乘法操作。  

接下来，我们需要计算 $\varphi_{i}(q)$，对每个 $q \in Q$ 和重复次数 $i \in\left[R_{\text {reps }}\right]$，每个值的计算需要  

$$
d \cdot k_{\text {sim }}
$$

的时间，将 $q \in \mathbb{R}^{d}$ 与 $k_{\text {sim }}$ 个高斯向量相乘。因此，该步骤的总运行时间为  

$$
O\left(R_{\text {reps }}|Q| d k_{\text {sim }}\right)。
$$

最后，一旦 $\varphi_{i}(q), \boldsymbol{\psi}_{i}(q)$ 计算完成，将相关值累加到 FDE 中可以在时间  

$$
O\left(|Q| d_{\text {proj }}\right)
$$

内完成。  

关于稀疏性，注意 FDE 中仅包含与具有至少一个 $q \in|Q|$ 且满足 $\varphi_{i}(q)=k$ 的重复 $i$ 中簇 $k$ 对应的坐标块非零项。在最坏情况下，最多有  

$$
O\left(R_{\text {reps }}|Q|\right)
$$

个此类块，每个块包含  

$$
O\left(d_{\text {proj }}\right)
$$

个坐标。  

对于文档的运行时间，类似于查询，但需要额外考虑执行 `fill_empty_clusters` 选项的复杂性。对于每次重复，需要找出与给定簇 $k$ 最近的 $p \in P$。这需要  

$$
O\left(|P| \cdot k_{\text {sim }}\right)
$$

的时间，因为我们需要遍历所有 $|p|$ 的 $\varphi(p)$ 值，并检查有多少位与 $k$ 不同。因此，总运行时间为  

$$
O\left(R_{\text {reps }}|P| B k_{\text {sim }}\right)=O\left(R_{\text {reps }}|P| 2^{k_{\text {sim }}} k_{\text {sim }}\right)。
$$

在接下来的分析中，我们需要以下关于随机投影近似保持内积的标准事实。其证明相对标准，可参考文献 [2]，或者更一般的界限请参见关于近似矩阵乘法的结果 [52]。  

**事实 A.2 ([2])** 设定 $\varepsilon, \delta > 0$。对于任意 $d \geqslant 1$ 和 $x, y \in \mathbb{R}^{d}$，令 $S \in \mathbb{R}^{t \times d}$ 为一个矩阵，其元素独立且均匀分布于 $\{1, -1\}$，其中  

$$
t=O\left(\frac{1}{\varepsilon^{2}} \log \delta^{-1}\right)。
$$

则有  

$$
\mathbb{E}[\langle S x, S y\rangle]=\langle x, y\rangle，
$$

并且以至少 $1-\delta$ 的概率满足  

$$
|\langle S x, S y\rangle-\langle x, y\rangle| \leqslant \varepsilon\|x\|_{2}\|y\|_{2}。
$$

为了分析 FDE 的近似性能，我们首先证明 FDE 内积值的上界。事实上，我们证明了一个更强的结果：即 FDE 具有作为单侧估计器的理想特性——它们不会高估真实的 Chamfer 相似度。这一结果总结如下引理。  

**引理 A.3（单侧误差估计器）**  
固定任意单位向量集合 $Q, P \subset \mathbb{R}^{d}$，其中 $|Q|+|P|=m$。若 $d=d_{\text{proj}}$，则始终有  

$$
\frac{1}{|Q|}\left\langle\mathbf{F}_{q}(Q), \mathbf{F}_{doc}(P)\right\rangle \leqslant \operatorname{NChAMFER}(Q, P)。
$$

此外，对于任意 $\delta>0$，若设置  

$$
d_{\text {proj }}=O\left(\frac{1}{\varepsilon^{2}} \log \frac{m}{\delta}\right)，
$$

则以下结果在期望和至少 $1-\delta$ 的概率下成立：  

$$
\frac{1}{|Q|}\left\langle\mathbf{F}_{q}(Q), \mathbf{F}_{doc}(P)\right\rangle \leqslant \operatorname{NChAMFER}(Q, P)+\varepsilon。
$$

**证明** 第一个结论直接源于这样一个事实：一组数值的子集的平均值不会大于该集合中最大值的数学性质。更正式地，有：
$$
\begin{align*}
\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathbf{q}}(Q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle & =\frac{1}{|Q|} \sum_{k=1}^{B} \sum_{\substack{q \in Q \\
\varphi(q)=k}} \frac{1}{\left|P \cap \boldsymbol{\varphi}^{-1}(k)\right|} \sum_{\substack{p \in P \\
\varphi(p)=k}}\langle q, p\rangle \\
& \leqslant \frac{1}{|Q|} \sum_{k=1}^{B} \sum_{\substack{q \in Q \\
\varphi(q)=k}} \frac{1}{\left|P \cap \boldsymbol{\varphi}^{-1}(k)\right|} \sum_{\substack{p \in P \\
\varphi(p)=k}} \max _{p^{\prime} \in P}\left\langle q, p^{\prime}\right\rangle  \tag{4}\\
& =\frac{1}{|Q|} \sum_{k=1}^{B} \sum_{\substack{q \in Q \\
\varphi(q)=k}} \max _{p^{\prime} \in p}\langle q, p\rangle=\operatorname{NCHAMFER}(Q, P)
\end{align*}
$$

这完成了引理的第一部分证明。对于第二部分，当 $d_{\text{proj}} < d$ 且使用内部随机投影时，通过应用**事实 A.2**，我们首先得到：  

对于任意 $q \in Q, p \in P$，有  

$$
\mathbb{E}[\langle\boldsymbol{\psi}(p), \boldsymbol{\psi}(q)\rangle]=\langle q, p\rangle。
$$

其次，通过对 $|P| \cdot |Q| \leqslant m^{2}$ 对进行联合界限分析（union bound），可以得到以下结果：  

对于所有 $q \in Q, p \in P$，同时满足  

$$
\langle q, p\rangle=\langle\boldsymbol{\psi}(p), \boldsymbol{\psi}(q)\rangle \pm \varepsilon
$$

的概率至少为 $1-\delta$，其中 $C > 1$ 为任意常数。因此，引理的第二部分可类似上述过程证明。  

现在，我们准备给出关于 FDE 近似的主定理证明。  

**定理 2.1（FDE 近似）**  
设定任意 $\varepsilon, \delta>0$，以及单位向量集合 $Q, P \subset \mathbb{R}^{d}$，令 $m=|Q|+|P|$。  

选择以下参数：  

- $k_{\text{sim}}=O\left(\frac{\log \left(m \delta^{-1}\right)}{\varepsilon}\right)$  
- $d_{\text{proj}}=O\left(\frac{1}{\varepsilon^{2}} \log \left(\frac{m}{\varepsilon \delta}\right)\right)$  
- $R_{\text{reps}}=1$  

使得  

$$
d_{F D E}=(m / \delta)^{O(1 / \varepsilon)}，
$$

则我们有：


$$
\operatorname{NChamFER}(Q, P)-\varepsilon \leqslant \frac{1}{|Q|}\left\langle\mathbf{F}_{q}(Q), \mathbf{F}_{d o c}(P)\right\rangle \leqslant \operatorname{NChamFER}(Q, P)+\varepsilon
$$

期望情况下，以及至少 $1-\delta$ 的概率下成立。  

**定理 2.1 的证明。**  

上界直接由引理 A.3 得出，因此我们只需证明下界。我们首先考虑没有随机投影 $\psi$ 的情况，并在证明末尾移除此假设。  

注意，由构造可知，$\mathbf{F}_{\mathrm{q}}$ 是一个线性映射，因此  

$$
\mathbf{F}_{\mathrm{q}}(Q)=\sum_{q \in Q} \mathbf{F}(q)，
$$

所以  

$$
\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle=\sum_{q \in Q}\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle。
$$

因此，我们只需证明：  

$$
\begin{equation*}
\operatorname{Pr}\left[\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle \geqslant \max _{p \in P}\langle q, p\rangle-\varepsilon\right] \geqslant 1-\varepsilon \delta /|Q| \tag{5}
\end{equation*}
$$

对所有 $q \in Q$ 成立。  

然后，通过联合界限，式 (5) 对所有 $q \in Q$ 以至少 $1-\varepsilon \delta$ 的概率成立，在此情况下，我们有  

$$
\begin{align*}
\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle & \geqslant \frac{1}{|Q|} \sum_{q \in Q}\left(\max _{p \in P}\langle q, p\rangle-\varepsilon\right)  \tag{6}\\
& =\operatorname{NChAMFER}(Q, P)-\varepsilon。
\end{align*}
$$

这完成了定理的证明。  

接下来，对于任意 $x, y \in \mathbb{R}^{d}$，定义它们之间的夹角为 $\theta(x, y) \in[0, \pi]$。现在固定任意 $q \in Q$，令  

$$
p^{*}=\arg \max _{p \in P}\langle q, p\rangle，
$$

并设  

$$
\theta^{*}=\theta\left(q, p^{*}\right)。
$$

根据构造，总存在某个点集 $S \subset P$，使得  

$$
\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle=\left\langle q, \frac{1}{|S|} \sum_{p \in S} p\right\rangle。
$$

此外，上述公式右侧的值总是被 1 约束（绝对值），因为这是归一化向量 $q, p \in \mathcal{S}^{d-1}$ 的点积的平均值。  

特别地，存在两种情况：  

- 情况 (A)：$S$ 是满足 $\varphi(p)=\varphi(q)$ 的点集。  
- 情况 (B)：$S$ 是单个点 $\arg \min _{p \in P}\|\varphi(p)-\varphi(q)\|_{0}$，其中 $\|x-y\|_{0}$ 表示任意两个比特字符串 $x, y \in\{0,1\}^{k_{\mathrm{sim}}}$ 之间的汉明距离。  

在这里，我们将 $\boldsymbol{\varphi}(p), \boldsymbol{\varphi}(q)$ 解释为比特字符串。此外，设 $g_{1}, \ldots, g_{k_{\text {sim }}} \in \mathbb{R}^{d}$ 为用于定义分区函数 $\varphi$ 的随机高斯向量。  

为了分析 $S$，我们首先证明以下声明：  

**声明 A.4.** 对于任意 $q \in Q$ 和 $p \in P$，有  
$$
\operatorname{Pr}\left[\left|\|\varphi(p)-\varphi(q)\|_{0}-k_{\mathrm{sim}} \cdot \frac{\theta(q, p)}{\pi}\right|>\sqrt{\varepsilon} k_{\mathrm{sim}}\right] \leqslant\left(\frac{\varepsilon \delta}{m^{2}}\right)。
$$

**证明。**  

固定任意 $p$，对于 $i \in\left[k_{\text {sim }}\right]$，定义指示变量 $Z_{i}$ 表示以下事件：  

$$
\mathbf{1}\left(\left\langle g_{i}, p\right\rangle>0\right) \neq \mathbf{1}\left(\left\langle g_{i}, q\right\rangle>0\right)。
$$

首先注意，  

$$
\|\varphi(p)-\varphi(q)\|_{0}=\sum_{i=1}^{k_{\text {sim }}} Z_{i}。
$$

由于高斯分布的旋转不变性，对于任意高斯向量 $g \in \mathbb{R}^{d}$，有：  

$$
\operatorname{Pr}[\mathbf{1}(\langle g, x\rangle>0) \neq \mathbf{1}(\langle g, y\rangle>0)]=\frac{\theta(x, y)}{\pi}，
$$

适用于任意两个向量 $x, y \in \mathbb{R}^{d}$。  

因此，$Z_{i}$ 是一个伯努利随机变量，其期望值为  

$$
\mathbb{E}\left[Z_{i}\right]=\frac{\theta(x, y)}{\pi}。
$$

利用 Hoeffding 不等式，我们得到：


$$
\begin{align*}
& \operatorname{Pr}\left[\left|\|\boldsymbol{\varphi}(p)-\boldsymbol{\varphi}(q)\|_{0}-k_{\mathrm{sim}} \cdot \frac{\theta(q, p)}{\pi}\right|>\sqrt{\varepsilon} k_{\mathrm{sim}}\right] \\ 
& =\operatorname{Pr}\left[\left|\sum_{i=1}^{k_{\mathrm{sim}}} Z_{i}-\mathbb{E}\left[\sum_{i=1}^{k_{\mathrm{sim}}} Z_{i}\right]\right|>\sqrt{\varepsilon} k_{\mathrm{sim}}\right] \\
& \leqslant \exp \left(-2 \varepsilon k_{\mathrm{sim}}\right) \\
& \leqslant\left(\frac{\varepsilon \delta}{m^{2}}\right) \tag{7}
\end{align*}
$$

其中，我们取
$$
k_{\text {sim }} \geqslant 1 / 2 \cdot \log \left(\frac{m^{2}}{\varepsilon \delta}\right) / \varepsilon
$$


这完成了证明。

现在我们假设引理 A.4 中的事件对所有 $p \in P$ 都成立，根据联合界限，该事件的概率至少为  

$$
1 - |P| \cdot\left(\frac{\varepsilon \delta}{m^{2}}\right) > 1 - \left(\frac{\varepsilon \delta}{m}\right)。
$$

将该事件记作 $\mathcal{E}$，并在以下证明中基于该条件进行分析。  

首先假设我们处于情况 (B)，即映射到簇 $\varphi(q)$ 的点集 $S$ 是  

$$
S=\left\{p^{\prime}\right\}，
$$

其中  

$$
p^{\prime}=\arg \min _{p \in P}\|\boldsymbol{\varphi}(p)-\boldsymbol{\varphi}(q)\|_{0}。
$$

1. 如果 $p^{\prime}=p^{*}$，那么直接得出  

$$
\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle=\left\langle q, p^{*}\right\rangle，
$$

因此式 (5) 成立，证明完成。  

2. 如果 $p^{\prime} \neq p^{*}$，根据引理 A.4 可知  

$$
\left|\theta\left(q, p^{\prime}\right)-\theta\left(q, p^{*}\right)\right| \leqslant \pi \cdot \sqrt{\varepsilon}。
$$

利用余弦函数的泰勒展开式  

$$
\cos(x) = 1 - \frac{x^{2}}{2} + O\left(x^{4}\right)，
$$

我们得到：

$$
\left|\cos \left(\theta\left(q, p^{\prime}\right)\right)-\cos \left(\theta\left(q, p^{*}\right)\right)\right| \leqslant O(\varepsilon)
$$

因此

$$
\begin{align*}
\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle & =\left\langle q, p^{\prime}\right\rangle \\
& =\cos \left(\theta\left(q, p^{\prime}\right)\right) \\
& \geqslant \cos \left(\theta\left(q, p^{*}\right)\right)-O(\varepsilon)  \tag{8}\\
& =\max _{p \in P}\langle q, p\rangle-O(\varepsilon)
\end{align*}
$$

经过对 $\varepsilon$ 的常数因子重新缩放后，这证明了所需的结论 (5)。  

接下来，假设我们处于情况 (A)，其中  

$$
S=\left\{p \in P^{\prime} \mid \boldsymbol{\varphi}(p)=\varphi(q)\right\}
$$

非空。在这种情况下，$S$ 包含所有满足  

$$
\|\varphi(p)-\varphi(q)\|_{0}=0
$$

的点 $p$。  

根据引理 A.4 可知，对于任意 $p \in S$，有  

$$
\theta(q, p) \leqslant \sqrt{\varepsilon} \pi。
$$

因此，利用与上述相同的推理过程，我们得到：

$$
\begin{align*}
\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle & =\frac{1}{|S|} \sum_{p \in S} \cos \left(\theta\left(q, p^{\prime}\right)\right) \\
& \geqslant \frac{1}{|S|} \sum_{p \in S}(1-O(\varepsilon))  \tag{9}\\
& \geqslant \frac{1}{|S|} \sum_{p \in S}\left(\left\langle q, p^{*}\right\rangle-O(\varepsilon)\right) \\
& =\max _{p \in P}\langle q, p\rangle-O(\varepsilon)
\end{align*}
$$

这再次证明了在情况 (A) 下所需的结论 (5)，从而完成了在没有随机投影的情况下的完整证明。  

##### 关于期望的分析  

注意，由于  

$$
\left|\left\langle\mathbf{F}_{\mathbf{q}}(q), \mathbf{F}_{\text {doc }}(P)\right\rangle\right| \leqslant 1
$$

是确定性的，上述 $\mathcal{E}$ 不成立的小概率事件 $O(\varepsilon \delta)$ 最多会在期望中引入一个  

$$
O(\varepsilon \delta) \leqslant \varepsilon
$$

的附加误差，这在对 $\varepsilon$ 进行常数因子重新缩放后是可以接受的。  


##### 考虑投影的情况  

最后，为了纳入随机投影，通过约翰逊-林登施特劳斯引理的标准结果（**事实 A.2**），设置  

$$
d_{\text{proj}}=O\left(\frac{1}{\varepsilon^{2}} \log \frac{m}{\varepsilon}\right)，
$$

并通过随机高斯矩阵或 $\pm 1$ 矩阵 $\boldsymbol{\psi}: \mathbb{R}^{d} \rightarrow \mathbb{R}^{d_{\text{proj}}}$ 进行投影，对于任意集合 $S \subset P$，有  

$$
\mathbb{E}\left[\left\langle\boldsymbol{\psi}(q), \boldsymbol{\psi}\left(\frac{1}{|S|} \sum_{p \in S} p\right)\right\rangle\right]=\left\langle q, \frac{1}{|S|} \sum_{p \in S} p\right\rangle，
$$

并且对所有 $q \in Q, p \in P$，有至少 $1-\varepsilon \delta$ 的概率满足：  

$$
\left\langle q, \frac{1}{|S|} \sum_{p \in S} p\right\rangle = \left\langle\boldsymbol{\psi}(q), \boldsymbol{\psi}\left(\frac{1}{|S|} \sum_{p \in S} p\right)\right\rangle\|q\|_{2}\left\|\frac{1}{|S|} \sum_{p \in S} p\right\|_{2} \pm \varepsilon。
$$

注意到 $\|q\|_{2}=1$，且由三角不等式有  

$$
\left\|\frac{1}{|S|} \sum_{p \in S} p\right\|_{2} \leqslant \frac{1}{|S|} \sum_{p \in S}\|p\|_{2}=1。
$$

因此，令  

- $\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}(P)$ 表示没有内层投影 $\psi$ 的 FDE 值  
- $\mathbf{F}_{\mathrm{q}}^{\psi}(Q), \mathbf{F}_{\mathrm{doc}}^{\psi}(P)$ 表示具有内层投影 $\psi$ 的 FDE 值  

根据上述条件可得：

$$
\begin{align*}
\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathrm{q}}^{\psi}(Q), \mathbf{F}_{\mathrm{doc}}^{\psi}(P)\right\rangle & =\frac{1}{|Q|} \sum_{q \in Q}\left\langle\mathbf{F}_{\mathrm{q}}^{\psi}(q), \mathbf{F}_{\mathrm{doc}}^{\psi}(P)\right\rangle \\
& =\frac{1}{|Q|} \sum_{q \in Q}\left(\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle \pm \varepsilon\right)  \tag{10}\\
& =\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle \pm \varepsilon
\end{align*}
$$

最终，关于期望的分析。注意，由于

$$
\left|\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle\right| \leqslant \frac{1}{|Q|} \sum_{q \in Q}\left|\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}(P)\right\rangle\right| \leqslant 1
$$

结合之前的分析，考虑上述小概率事件对期望值的影响，其变化最多为一个 $\varepsilon$ 的加性因子。因此，在对 $\varepsilon$ 进行常数因子重新缩放后，这完成了定理的证明。

有了定理 2.1 和引理 A.1 中的稀疏性界限之后，我们现在准备证明关于 Chamfer 相似度下的近似最近邻搜索的主定理。  

**定理 2.2（近似最近邻搜索）**  

设定任意 $\varepsilon>0$，查询集 $Q$ 和数据集  

$$
P=\left\{P_{1}, \ldots, P_{n}\right\}，
$$

其中 $Q \subset \mathbb{R}^{d}$，每个 $P_{i} \subset \mathbb{R}^{d}$ 为单位向量集。  

令  

$$
m=|Q|+\max _{i \in[n]}\left|P_{i}\right|。
$$

设置以下参数：  

- $k_{\text {sim }}=O\left(\frac{\log m}{\varepsilon}\right)$  
- $d_{\text {proj }}=O\left(\frac{1}{\varepsilon^{2}} \log \frac{m}{\varepsilon}\right)$  
- $R_{\text {reps }}=O\left(\frac{1}{\varepsilon^{2}} \log n\right)$  

使得  

$$
d_{F D E}=m^{O(1 / \varepsilon)} \cdot \log n。
$$

令  

$$
i^{*}=\arg \max _{i \in[n]}\left\langle\mathbf{F}_{q}(Q), \mathbf{F}_{doc}\left(P_{i}\right)\right\rangle，
$$

则以高概率（即 $1-1 / \operatorname{poly}(n)$）满足以下条件：

$$
\operatorname{NChamFER}\left(Q, P_{i^{*}}\right) \geqslant \max _{i \in[n]} \operatorname{NChamFER}\left(Q, P_{i}\right)-\varepsilon
$$

给定查询 $Q$，文档 $P^{*}$ 可以在以下时间内恢复：  

$$
O\left(|Q| \max \{d, n\} \frac{1}{\varepsilon^{4}} \log \left(\frac{m}{\varepsilon}\right) \log n\right)。
$$

##### **定理 2.2 的证明**  

首先注意，对于任意子集 $P_{j} \in D$，根据定理 2.1，我们有  

$$
\mathbb{E}\left[\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}\left(P_{j}\right)\right\rangle\right]=\operatorname{NChamFer}(Q, P) \pm \varepsilon。
$$

此外，如定理 2.1 的证明中所示，设 $\delta=1 / 10$，则有  

$$
\left|\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}\left(P_{j}\right)\right\rangle\right| \leqslant \frac{1}{|Q|} \sum_{q \in Q}\left|\left\langle\mathbf{F}_{\mathrm{q}}(q), \mathbf{F}_{\mathrm{doc}}\left(P_{j}\right)\right\rangle\right| \leqslant 1。
$$

因此，对于每个重复 $i \in\left[R_{\text{reps}}\right]$，令  

$$
\mathbf{F}_{\mathbf{q}}(Q)^{i}, \mathbf{F}_{\text{doc}}\left(P_{j}\right)^{i}
$$

分别表示对应于该重复的最终 FDE 向量中的坐标，则随机变量  

$$
X_{i}=\frac{1}{|Q|}\left\langle\mathbf{F}_{\mathbf{q}}^{i}(Q), \mathbf{F}_{\mathrm{doc}}^{i}\left(P_{j}\right)\right\rangle
$$

的取值范围为 $[-1, 1]$，且期望为  

$$
\operatorname{NChamFer}\left(Q, P_{j}\right) \pm \varepsilon。
$$

根据 Chernoff 界限，对 $R_{\text{reps}}=O\left(\frac{1}{\varepsilon^{2}} \log (n)\right)$ 次重复取平均，有：  

$$
\begin{equation*}
\left|\sum_{i=1}^{R_{\text{reps}}} \frac{1}{R_{\text{reps}}|Q|}\left\langle\mathbf{F}_{\mathrm{q}}^{i}(Q), \mathbf{F}_{\mathrm{doc}}^{i}\left(P_{j}\right)\right\rangle-\operatorname{NChAMFER}\left(Q, P_{j}\right)\right| \leqslant 2 \varepsilon \tag{11}
\end{equation*}
$$

概率至少为  

$$
1-1 / n^{C}
$$

其中 $C > 1$ 是任意常数。  

注意：  

$$
\sum_{i=1}^{R_{\text{reps}}} \frac{1}{R_{\text{reps}}|Q|}\left\langle\mathbf{F}_{\mathrm{q}}^{i}(Q), \mathbf{F}_{\text{doc}}^{i}\left(P_{j}\right)\right\rangle=\frac{1}{R_{\text{reps}}|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\text{doc}}\left(P_{j}\right)\right\rangle，
$$

其中 $\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\text{doc}}\left(P_{j}\right)$ 是最终的 FDE 值。  

对所有文档 $j \in [n]$，条件 (11) 通过联合界限成立，概率至少为  

$$
1 - 1 / n^{C-1}。
$$

在此条件下，我们有：  

$$
\begin{align*}
\operatorname{NChAMFER}\left(Q, P_{i^{*}}\right) & \geqslant \frac{1}{R_{\mathrm{reps}}|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}\left(P_{i^{*}}\right)\right\rangle-2 \varepsilon \\
& =\max _{j \in[n]} \frac{1}{R_{\mathrm{reps}}|Q|}\left\langle\mathbf{F}_{\mathrm{q}}(Q), \mathbf{F}_{\mathrm{doc}}\left(P_{j}\right)\right\rangle-2 \varepsilon  \tag{12}\\
& \geqslant \max _{j \in[n]} \operatorname{NChAMFER}\left(Q, P_{j}\right)-6 \varepsilon。
\end{align*}
$$

这证明了近似误差在 $\varepsilon$ 上的常数因子缩放后满足条件，从而完成定理的证明。  

##### **运行时间分析**  

运行时间由计算 $\mathbf{F}_{\mathrm{q}}(Q)$ 所需时间决定，其为：  

$$
O\left(|Q| R_{\text {reps }} d\left(d_{\text {proj }}+k_{\text {sim }}\right)\right)
$$

即  

$$
O\left(|Q| \frac{\log n}{\varepsilon^{2}} d\left(\frac{1}{\varepsilon^{2}} \log (m / \varepsilon)+\frac{1}{\varepsilon} \log m\right)\right)。
$$

此外，进行最近点积搜索所需的计算时间与 $\mathbf{F}_{\mathrm{q}}(Q)$ 的稀疏性成正比，最多为：  

$$
O\left(|Q| d_{\text {proj }} R_{\text {reps }}\right)
$$

即  

$$
O\left(|Q| \frac{1}{\varepsilon^{4}} \log (m / \varepsilon) \log n\right)。
$$

将这两个时间界限相加，得到最终的运行时间界限：  

$$
O\left(|Q| \max \{d, n\} \frac{1}{\varepsilon^{4}} \log \left(\frac{m}{\varepsilon}\right) \log n\right)。
$$

## B 附加数据集信息  

在表 8 中，我们提供了本文中使用的 BEIR 检索数据集的更多特定信息。具体而言，我们列出了查询和语料库的规模，以及 ColBERTv2 模型为每个文档生成的平均嵌入数量。  

我们特别考虑了六个 BEIR 检索数据集：MS MARCO [40]、NQ [31]、HotpotQA [53]、ArguAna [47]、SciDocs [11] 和 Quora [46]。  

需要注意的是，MV 语料库（在所有文档上生成 MV 嵌入后）的总嵌入数量为：  

$$
\#Corpus \times (\text{每篇文档的平均嵌入数})
$$

有关更多详细信息，请参阅 BEIR 论文 [46]。  

| 数据集                                 | MS MARCO | HotpotQA |   NQ   | Quora  | SciDocs | ArguAna |
| :---------------------------------: | :------: | :------: | :----: | :----: | :-----: | :-----: |
| 查询数量 (\#Queries)                 |  6,980   |  7,405   | 3,452  | 10,000 |  1,000  |  1,406  |
| 语料库大小 (\#Corpus)                |  8.84 M  |  5.23 M  | 2.68 M | 523 K  | 25.6 K  |  8.6 K  |
| 每篇文档的平均嵌入数 (Avg \# Embeddings per Doc) |   78.8   |  68.65   | 100.3  | 18.28  | 165.05  | 154.72  |

**图 8**：本文所使用 BEIR 数据集的具体统计信息。

## C 附加实验与图表

在本节中，我们提供了支持第 3 节实验结果的附加图表。具体包括所有六个数据集的图表以及第 3.1 节实验中 $x$ 轴的附加范围。此外，我们还展示了其他实验结果，例如方差评估以及 FDE 最终投影质量的评估。

##### **FDE 与 SV 启发式实验**

在图 9 和图 10 中，我们展示了进一步的数据集分析以及更广泛的召回范围，用于比较 SV 启发式与基于 FDE 的检索方法。

我们发现，维度 $4k+$ 的 FDE 方法在大多数数据集中优于去重后的 SV 启发式方法（SV 启发式的成本略显不现实，因为它需要过度检索以处理重复项），尤其是在低召回率条件下表现突出。

在表 1 中，我们比较了 SV 启发式方法（包括去重和非去重）以及 FDE 方法分别需要检索多少候选项才能超过特定的召回阈值。

| 召回 <br> 阈值 | SV 非去重 | SV 去重 | 20k FDE | 10k FDE | 4k FDE | 2k FDE |
| :------------: | :-------: | :-----: | :-----: | :-----: | :----: | :----: |
|     $80\%$     |   1200    |   300   |   60    |   60    |   80   |  200   |
|     $85\%$     |   2100    |   400   |   90    |   100   |  200   |  300   |
|     $90\%$     |   4500    |   800   |   200   |   200   |  300   |  800   |
|     $95\%$     | $>10000$  |  2100   |   700   |   800   |  1200  |  5600  |

**表 1**：FDE 与 SV 启发式方法的候选项数量比较：每种方法在 MS MARCO 数据集上超过给定召回率所需的候选项数量。前两列为 SV 非去重与去重启发式方法，其余四列为 FDE 方法的候选项数量，分别对应 FDE 维度 ${20480,10240,4096,2048}$。

召回率 @ $N$ 值以 10 为增量在 10-100 范围内计算，并以 100 为增量在 100-10000 范围内计算，不考虑 $N > 10000$ 的情况。

##### **相对于精确 Chamfer 的检索质量** 

在图 11 中，我们展示了基于 Chamfer 相似度的 1-最近邻恢复结果的完整 FDE 召回率曲线，这些数据集包括六个 BEIR 数据集，其中 SciDocs 和 ArguAna 在主文中被省略的两组数据也包含在内。

## C.1 FDE 方差分析  

由于 FDE 的生成是一个随机过程，一个自然的疑问是不同随机种子下召回质量是否存在较大的方差。幸运的是，我们表明情况并非如此，FDE 的召回方差实际上可以忽略不计，并且可以通过轻微的额外检索轻松弥补。  

为了评估这一点，我们选择了四组 FDE 参数 ($R_{\text {reps }}, k_{\text {sim }}, d_{\text {proj }}$)，这些参数在各自的维度中表现为帕累托最优。我们针对整个 MS MARCO 数据集生成了 10 组独立的查询和文档 FDE，并计算了召回率@100 和 1000 的平均值及其标准差。  

结果如表 2 所示，在所有实验中，标准差介于召回率的 $0.08-0.3 \%$ 之间，而召回率范围在 $80-95 \%$ 之间。需要注意的是，Recall@1000 的标准差约为 Recall@100 的一半。  

---

##### **表 2：MS MARCO 数据集上 FDE 召回质量的方差分析**  

| FDE 参数 $\left(R_{\text {reps }}, k_{\text {sim }}, d_{\text {proj }}\right)$ | $(20,5,32)$ | $(20,5,16)$ | $(20,4,16)$ | $(20,4,8)$ |
| :----------------------------------------------------------: | :---------: | :---------: | :---------: | :--------: |
|                        FDE 维度                              |    20480    |    10240    |    5120     |    2560    |
|                        Recall@ 100                           |    83.68    |    82.82    |    80.46    |   77.75    |
|                      标准差                                  |    0.19     |    0.27     |    0.29     |    0.17    |
|                        Recall@ 1000                          |    95.37    |    94.88    |    93.67    |   91.85    |
|                      标准差                                  |    0.08     |    0.11     |    0.16     |    0.12    |

---

##### **表 3：基于最终投影的 FDE 召回质量（$d_{\text {FDE }} \in\{2460,5120\}$）**  

|  实验         | 无投影 | 有投影 | 无投影 | 有投影 |
| :----------: | :------------: | :-----------: | :------------: | :-----------: |
|  维度         |      2460      |     2460      |      5120      |     5120      |
| Recall@ 100  |     77.71      |     78.82     |     80.37      |     83.35     |
| Recall@1000  |     91.91      |     91.62     |     93.55      |     94.83     |
| Recall@10000 |     97.52      |     96.64     |     98.07      |     98.33     |

---

##### **表 4：基于最终投影的 FDE 召回质量（$d_{\text {FDE }} \in\{10240,20480\}$）**  

|  实验         | 无投影 | 有投影 | 无投影 | 有投影 |
| :----------: | :------------: | :-----------: | :------------: | :-----------: |
|  维度         |     10240      |     10240     |     20480      |     20480     |
| Recall@ 100  |     82.31      |     85.15     |     83.36      |     86.00     |
| Recall@ 1000 |     94.91      |     95.68     |     95.58      |     95.95     |
| Recall@10000 |     98.76      |     98.93     |     98.95      |     99.17     |

## C. 2 与最终投影的比较

我们现在展示使用最终投影来降低 FDE 的目标维度所产生的效果。在所有实验中，最终投影 $\psi^{\prime}$ 的实现方式与内部投影相同，即通过与一个随机的 $\pm 1$ 矩阵相乘来实现。我们选择了四个目标维度，$d_{\text{FDE}} \in {2460, 5120, 10240, 20480}$，并从第 3.1 节中不使用最终投影的网格搜索结果中选择帕累托最优参数 $\left(R_{\text{reps}}, k_{\text{sim}}, d_{\text{proj}}\right)$，其值分别为 $(20,4,8), (20,5,8), (20,5,16), (20,5,32)$。

接下来，我们基于参数 $\left(R_{\text{reps}}, k_{\text{sim}}, d_{\text{proj}}\right) = (40,6,128)$ 构建了一个高维 FDE。在这里，由于 $d = d_{\text{proj}}$，因此在构建 FDE 时不使用任何内部投影。然后，我们使用单个随机最终投影将此 FDE 的维度从 $R_{\text{reps}} \cdot 2^{k_{\text{sim}}} \cdot d_{\text{proj}} = 327680$ 降低到上述各个目标维度 $d_{\text{FDE}}$。

结果如表 3 和表 4 所示。请注意，引入最终投影对召回率（Recall）可能产生显著影响，尤其是在 Recall@100 上，可以提高约 $3%$。特别是，带有最终投影的 FDE 通常比不带最终投影但维度是其两倍的 FDE 表现更好。唯一的例外是维度为 2460 的 FDE，其 Recall@100 仅提高了 $1.1%$，而 Recall@1000 实际上下降了 $0.3%$。

## C. 3 球体划分（Ball Carving）

我们现在进一步详细介绍第 3.2 节中描述的球体划分技术，该技术用于我们的在线实验。具体而言，为了提高重新评分的延迟性能，我们通过一个预聚类阶段减少查询嵌入的数量。具体做法是，将查询集 $Q$ 分组为簇 $C_{1}, \ldots, C_{k}$，设 $c_{i}=\sum_{q \in C_{i}} q$，并定义 $Q_{C}=\left\{c_{1}, \ldots, c_{k}\right\}$。然后，在使用 FDE 检索一组候选文档后，我们不是针对每个候选文档 $P$ 使用 CHAMFER$(Q, P)$ 重新评分，而是使用 CHAMFER$\left(Q_{C}, P\right)$ 进行评分，该过程的时间复杂度为 $O\left(\left|Q_{C}\right| \cdot|P|\right)$。当簇的数量较少时，这种方法可以显著加速处理速度。

而且，我们不是固定 $k$ 的值，而是执行一种贪心的球体划分过程，使 $k$ 能够根据 $Q$ 进行自适应调整。具体来说，给定一个阈值 $\tau$，我们选择查询集 $Q$ 中的任意一点 $q$，将其与所有满足 $\left\langle q, q^{\prime}\right\rangle \geqslant \tau$ 的其他点 $q^{\prime}$ 聚类到一起，然后移除已聚类的点，重复此过程直到所有点都被划分到簇中。

在图 12 中，我们展示了 MUVERA 在端到端 Recall@$k$ 性能与球体划分阈值之间的权衡关系。请注意，对于 $k=100$ 和 $k=1000$，Recall 曲线在阈值 $\tau=0.6$ 之后急剧变平，并且在所有数据集上，当 $\tau \geqslant 0.7$ 时基本保持平稳。因此，对于这些较高的阈值，球体划分几乎不会带来质量损失。因此，我们在端到端实验中选择 $\tau=0.7$ 作为阈值。

另一方面，我们表明，采用阈值 0.7 的球体划分可显著提高效率。具体而言，在图 13 中，我们绘制了 MS MARCO 数据集上不同球体划分阈值下每核每秒查询次数（QPS）的变化情况（即计算 CHAMFER$\left(Q_{C}, P\right)$ 的速率）。对于顺序重新评分，球体划分阈值 $\tau=0.7$ 提供了 $25%$ 的 QPS 提升；当重新评分在所有核心上同时并行进行时，提升幅度为 $20%$。

此外，阈值 $\tau=0.7$ 下，MS MARCO 数据集平均每个查询生成 5.9 个簇。这将每个查询的嵌入数量减少了 $5.4 \times$，从初始固定值 $|Q|=32$ 降低下来。这表明，在重新评分之前对查询进行预聚类可以显著提升运行时效率，并且质量损失可以忽略不计。这还表明，固定设置 $|Q|=32$ 个查询嵌入对于 MV 相似度质量而言可能是过多的，使用更少的查询嵌入即可达到类似的性能。

## C. 4 产品量化（Product Quantization）

##### PQ 详细说明

我们使用基于“教科书式”的 $k$-means 算法实现了产品量化器（PQ）。请注意，$\mathrm{AH}-C-G$ 表示每组连续的 $G$ 维度由 $C$ 个中心表示。我们训练量化器的过程如下：

1. 从数据集中每组维度抽取最多 100,000 个向量样本的坐标。
2. 在该样本上运行 $k$-means 聚类，使用 $k=C=256$ 个中心，直到收敛。

对于任意向量 $x \in \mathbb{R}^{d}$，我们将其分割为 $d / G$ 个坐标块，每个块的大小为 $G$，表示为 $x_{(1)}, \ldots, x_{(d / G)} \in \mathbb{R}^{G}$。

然后，通过计算 $x_{(i)}$ 到第 $i$ 组中最接近的质心的距离，将块 $x_{(i)}$ 压缩为质心的索引。由于每组有 256 个质心，因此每个块 $x_{(i)}$ 可以用一个字节表示。

##### 实验结果

在图 14 和图 15 中，我们展示了第 3.2 节中所有 BEIR 数据集上 QPS（每秒查询次数）实验的完整结果。结果包括 Recall@100（图 14）和 Recall@1000（图 15）。

##### 关键发现

我们发现 PQ-256-8 在所有测试数据集中始终是性能最好的 PQ 编码格式。如果不使用 PQ，相比于使用 PQ，在相同光束宽度下的性能会显著下降（降低至少 $5 \times$）。然而，使用 PQ-256-8 导致的召回率损失是最小的，通常只有不到百分之一的下降。

由于我们的检索引擎通过 FDE 进行过度检索，并使用 Chamfer 相似性进行重新排序，因此在 FDE 中使用 PQ 近似产生的损失可以通过稍微多检索一些候选项来补偿。

##### 高低召回率对比

我们还观察到，不同 PQ 编码格式在低召回率和高召回率场景下表现存在显著差异：

1. 在较低召回率场景下（例如检索前 1000 个候选项），不同 PQ 编码格式的 QPS 差异更大。图 15 中的大多数图表显示，在低召回率情况下，QPS 呈现明显的分层现象。
2. PQ-256-16（最压缩和内存效率最高的格式）在低召回率下通常优于其他格式；但在高召回率要求下，其表现远不及压缩率稍低的格式，如 PQ-256-8 和 PQ-256-4。

## 3 评估  

在本节中，我们评估 FDEs 作为多向量 (MV) 检索方法的表现。首先，我们离线评估 FDEs 本身作为 Chamfer 相似度的代理性能 (§3.1)。在 (§3.2) 中，我们讨论 MUVERA 的实现以及在搜索过程中进行的多项优化。随后，我们将 MUVERA 的延迟与 PLAID 进行比较，并研究前述优化的效果。  

---

**数据集。** 我们的评估包括六个广泛研究的 BEIR [46] 信息检索数据集的结果：MS MARCO [40] (CC BY-SA 4.0)、HotpotQA (CC BY-SA 4.0) [53]、NQ (Apache-2.0) [31]、Quora (Apache-2.0) [46]、SciDocs (CC BY 4.0) [11] 和 ArguAna (Apache-2.0) [47]。这些数据集的选择基于语料库规模的多样性（$8 \mathrm{~K}-8.8 \mathrm{M}$）以及文档标记的平均数量（18-165）；详细的数据集统计信息参见附录 (§B)。  

根据 [43]，我们在 MS MARCO 上使用开发集进行实验，而其他数据集则使用测试集进行实验。  

---

**MV 模型、MV 嵌入大小和 FDE 维度。** 我们的 FDE 是基于 **ColBERTv2** 模型 [44] (MIT License) 生成的 MV 嵌入计算得到的，该模型的嵌入维度为 $d=128$，每个查询固定生成 $|Q|=32$ 个嵌入向量。  

文档的嵌入数量是可变的，从 Quora 数据集的平均 18.3 到 SciDocs 数据集的 165 不等。这导致文档平均包含 2,300 到 21,000 个浮点数（例如，MS MARCO 的平均浮点数为 10,087）。  

因此，在构建 FDE 时，我们考虑了一个相当的维度范围 $d_{\text {FDE }}$，大约在 $1,000-20,000$ 之间。此外，我们在 (§3.2) 中展示，通过 **产品量化 (product quantization)**，FDE 可以在质量损失极小的情况下压缩 **32 倍**，进一步提高 FDE 的实际可用性。  

### 3.1 FDE 质量的离线评估  

我们评估 FDE 作为 Chamfer 相似度代理的质量，采用的是不进行重新排序且使用精确（离线）搜索的方式。首先，我们展示 FDE 的召回率质量会随着维度 $d_{\text {FDE }}$ 的增加而稳定提升，使得该方法相对容易调整。随后，我们证明 FDE 是比单向量 (SV) 启发式方法更有效的检索方法。具体而言，FDE 方法在召回率 Recall@$N$ 上超过了 SV 启发式方法的 Recall@2-4N，且在理论上扫描的浮点数与后者相似。这表明，SV 启发式方法的成功在很大程度上归因于对其进行了大量优化（如 [37] 所支持的结果），而类似的优化投入到 FDE 上可能会带来更大的效率提升。附录 (§C) 提供了更多相关曲线图。  

所有召回率曲线均使用单次 FDE 实例计算，因为在 (§C.1) 中我们证明 FDE 召回率的方差可以忽略不计。  

---

**FDE 质量 vs. 维度。** 我们研究了 FDE 的检索质量如何随维度 $d_{\text {FDE }}$ 的变化而变化。  

具体来说，我们对 FDE 参数进行网格搜索，包括：  

- $R_{\text {reps }} \in\{1,5,10,15,20\}$，  
- $k_{\text {sim }} \in\{2,3,4,5,6\}$，  
- $d_{\text {proj }} \in\{8,16,32,64\}$，  

并在 MS MARCO 数据集上计算召回率（见图 3）。  

结果表明，Pareto 最优参数通常在较大的 $R_{\text {reps }}$ 上取得，而 $k_{\text {sim }}$ 和 $d_{\text {proj }}$ 对质量提升的影响较小。具体来说，以下组合是各自维度上的 Pareto 最优解：  

$$
\left(R_{\text {reps }}, k_{\text {sim }}, d_{\text {proj }}\right) \in\{(20,3,8),(20,4,8),(20,5,8),(20,5,16)\}
$$

其中维度为 $R_{\text {reps }} \cdot 2^{k_{\text {sim }}} \cdot d_{\text {proj }}$。  

尽管不同参数选择会有细微差异，但 FDE 的质量与维度密切相关；增加维度通常会带来质量提升。  

我们还尝试使用 $k$-means 聚类作为分区方法，而不是 SimHash。具体而言，我们对文档嵌入进行 $k$-means 聚类，并将 $\varphi(x)$ 设置为 $x$ 最近质心的索引。  

我们对相同参数进行网格搜索（但将 $k \in\{4,8,16,32,64\}$ 与 $B=2^{k_{\text {sim }}}$ 匹配）。  

结果显示：  

- $k$-means 分区在 Pareto 前沿上并未比 SimHash 带来质量提升，且表现通常更差。  
- 此外，基于 $k$-means 的 FDE 构造不再是与数据分布无关的。  

因此，我们选择 SimHash 作为分区的首选方法，并在后续实验中采用。  

---

**基于 Chamfer 相似度的评估。**  

在图 4 中，我们根据 Chamfer 相似度（而不是标注的真实数据）评估 FDE 的检索质量。  

我们计算 1Recall@$N$，即 Chamfer 最近邻位于 FDE 点积中前 $N$ 个最相似结果中的查询比例。  
在上述网格搜索中，我们选择维度上 Pareto 最优的 FDE 参数。  

实验结果表明，相较于原始 MV 表示，维度较低的 FDE 在多个 BEIR 检索数据集上表现出了显著的召回率。例如，在 MS MARCO 数据集上（其中 $d \cdot m_{\text {avg }} \approx 10 \mathrm{~K}$），当 $d_{\mathrm{FDE}}=5120$ 时，仅检索 75 个候选项即可达到 **95%** 的召回率。  

---

**单向量启发式 vs. FDE 检索。**  

我们将 FDE 作为检索代理的质量与前述的单向量 (SV) 启发式方法进行比较，该方法是 PLAID 的核心算法。回顾该方法，对于每个查询向量 $q_{i}$（$i=1, \ldots, 32$），计算来自所有文档标记嵌入集合 $\cup_{i} P_{i}$ 的 $k$ 个最近邻 $p_{1, i}, \ldots, p_{k, i}$。  

为了计算 Recall@$N$，我们创建一个有序列表 $\ell_{1,1}, \ldots, \ell_{1,32}, \ell_{2,1}, \ldots$，其中 $\ell_{i, j}$ 是包含 $p_{i, j}$ 的文档 ID。该列表首先包含查询的 1-最近邻，然后是 2-最近邻，以此类推。在重新排序阶段，需要从列表中删除重复的文档 ID。  

由于在初始 32 次 SV MIPS 查询中无法检测重复项，SV 启发式方法需要**过度检索**以确保足够数量的唯一候选项。因此，SV 启发式实现的真实召回曲线（例如 PLAID）在无去重和完全去重之间变化；我们在图 5 中分别与两种情况进行了比较。  

---

**计算成本比较。**  

为了比较 SV 启发式方法与 FDE 在运行 MIPS 时的成本，我们考虑两者在暴力搜索中扫描的浮点数总量：  

- FDE 方法需要扫描 $n \cdot d_{\text {FDE }}$ 个浮点数来计算 $k$ 个最近邻。  
- SV 启发式方法需要对 $n \cdot m_{\text {avg }}$ 向量（每个 128 维）运行 32 次暴力扫描，其中 $m_{\text {avg }}$ 是每个文档的平均嵌入数量（见附录 §B 的统计数据）。  

例如，在 MS MARCO 数据集中，$m_{\text {avg }}=78.8$，因此 SV 启发式方法需要扫描 $32 \cdot 128 \cdot 78.8 \cdot n$ 个浮点数。  

这意味着 FDE 方法可以使用 $d_{\text {FDE }}=322,764$ 的维度，同时保持与 SV 方法类似的计算成本！  

在快速近似搜索场景下，假设 $n$ 个向量的近似 MIPS 可在子线性时间 $n^{\varepsilon}$ 内完成，其中 $\varepsilon \in(0,1)$。即使在极端假设 $\varepsilon=0$ 的情况下，FDE 仍然可以使用 $d_{\text {FDE }}=32 \cdot 128=4096$ 的维度保持成本可控。  

---

**实验结果。**  

图 5 显示了实验结果。  

我们为每个维度构建 FDE，其中：  

- $R_{\text {reps }}=40$  
- $k_{\text {sim }}=6$  
- $d_{\text {proj }}=d=128$  

然后通过最终投影将维度减少到目标维度（关于最终投影影响的实验详见附录 C.2）。  

在 MS MARCO 数据集上，即使是 4096 维的 FDE 也能匹配 SV 启发式方法（去重后）的召回率，同时检索候选项数量减少了 **1.75-3.75 倍**（我们的 Recall@$N$ 与 SV 启发式的 Recall@1.75-3.75$N$ 相当），相比未去重的 SV 启发式方法减少了 **10.5-15 倍**。  

对于 10240 维的 FDE，这些减少率分别达到了 **2.6-5 倍** 和 **20-22.5 倍**。  

例如：  

- 当 $d_{\mathrm{FDE}}=10240$ 时，我们使用 60 个候选项达到 **80%** 的召回率。  
- 当 $d_{\mathrm{FDE}}=4096$ 时，使用 80 个候选项达到 **80%** 的召回率。  
- 而 SV 启发式方法需要 300 个候选项（去重）和 1200 个候选项（未去重）才能达到相同召回率。  

更多详细比较请参见表 1。  

---

**方差分析。**  

尽管 FDE 生成过程具有随机性，我们在 (§C.1) 中证明 FDE 召回率的方差几乎可以忽略不计。例如，对于维度 $2-10k$ 的 FDE，Recall@1000 的标准差最多仅为 **$0.08-0.16 \%$**。  

### 3.2 在线实现与端到端评估

我们在 C++ 中实现了 Muvera，这是一种用于 FDE 生成和端到端检索的引擎。在 (§3.1) 中，我们讨论了 FDE 生成及其优化和权衡。接下来，我们将介绍如何对 FDE 进行检索以及其他进一步的优化措施。

---

**基于 DiskANN 的单向量 MIPS 检索**

我们的单向量检索引擎使用了一种可扩展实现 [38]，基于 **DiskANN** [25] (MIT 许可)，这是目前最先进的基于图的近似最近邻搜索 (ANNS) 算法之一。

我们使用未压缩的文档 FDE 构建 DiskANN 索引，最大节点度设置为 200，构建过程的束宽 (beam-width) 设置为 600。

检索过程如下：

1. 使用束搜索 (beam search) 在 DiskANN 索引中查询，束宽设为 $W$。
2. 对检索到的候选项用 Chamfer 相似度进行重新排序。

系统中唯一需要调整的参数是 $W$：增大 $W$ 会增加 MUVERA 检索到的候选项数量，从而提升召回率。

---

**球切分 (Ball Carving)**

为了提升重新排序的速度，我们通过球切分方法对查询嵌入进行聚类，并用每个簇中嵌入的总和代替原始嵌入。这种方法在加速重新排序的同时不会降低召回率；更多细节请参见附录 (§C.3)。

---

**产品量化 (Product Quantization, PQ)**

为了进一步优化 MUVERA 的内存使用，我们对 FDE 采用了一种标准的向量压缩技术——**产品量化 (PQ)**，并结合**非对称查询 (asymmetric querying)** [19, 26]。

我们将每 $G$ 个维度分组，并使用 $C$ 个中心对其进行量化，记作 PQ-C-G。例如，**PQ-256-8** 在实验中表现出最佳的质量与压缩率平衡：

- 每连续 8 维的浮点数被压缩为 256 个中心之一。
- 相较于每个维度用单精度浮点数存储，这种方法提供了 **32 倍压缩率**，因为每 8 个浮点数被表示为 1 个字节。

更多关于 PQ 的实验和细节请参见附录 (§C.4)。

---

**实验设置**

我们在 Google Cloud 上的 Intel **Sapphire Rapids** 服务器 (c3-standard-176) 上运行在线实验。

- 该机器支持多达 176 个超线程。
- 延迟实验使用单线程运行。
- 每秒查询数 (QPS) 实验使用所有 176 个线程运行。

---

**QPS 与召回率**

检索系统的一个重要指标是在给定召回率下每秒可处理的查询数量 (**QPS**, Queries Per Second)。评估系统的 QPS 可以充分利用系统资源（例如多通道内存和缓存的带宽），并适合处理机器同时服务多个查询的部署环境。

图 6 展示了 MUVERA 在 BEIR 数据集子集上的 **QPS 与 Recall@100** 的关系，并使用不同的 PQ 方案对 FDE 进行压缩。附录中提供了更多数据集以及 Recall@1000 的结果。

实验表明：

- 使用 **PQ-256-8** 不仅将 FDE 的存储空间减少了 **32 倍**，而且在相同查询束宽下，将 QPS 提升了最多 **20 倍**，同时对端到端召回率的影响极小。
- 我们的方法对数据集规模依赖较小，这与基于图的 ANNS 数据结构的研究一致，因为束搜索中进行的距离比较次数大致随数据集规模的对数增长 [25, 38]。

我们尝试为 PLAID [43] 提供 QPS 数据，但遗憾的是其实现不支持并行运行多个查询，并且优化方向侧重于测量延迟而非 QPS。

---

**延迟与召回率对比：MUVERA vs. PLAID**

我们在前文 (§3) 中提到的 6 个 BEIR 基准数据集上评估了 MUVERA 和 PLAID [43]。

图 7 显示：

- 在 MS MARCO 数据集上，MUVERA 的 Recall@$k$ 与 PLAID 基本相当（差距在 **0.4%** 以内）。
- 在其他数据集（例如 **HotpotQA**）上，MUVERA 的召回率比 PLAID 高出最多 **1.56 倍**。

实验配置：

- PLAID 使用推荐的系统设置，并成功重现了 MS MARCO 的召回率结果。
- 在所有 6 个数据集上，以及 $k \in {100,1000}$ 的平均性能比较中：
  - **MUVERA 的 Recall@$k$ 比 PLAID 高出 10%**（最高可达 **56%**）。
  - **MUVERA 的延迟降低 90%**（最高可达 **5.7 倍**）。

---

**关键优势总结**

MUVERA 在所有测量的数据集上都保持了高召回率和低延迟。此外，该方法不需要耗时的参数调整即可实现上述性能：

- 所有实验使用相同的 **10240 维 FDE**，并采用 **PQ-256-8** 进行压缩。
- 系统唯一调整的参数是查询束宽，以确保召回率与 PLAID 匹配。

如图 7 所示，在 **NQ** 和 **HotpotQA** 等数据集上，MUVERA 在较低延迟下获得了显著更高的召回率。

根据这些结果，我们认为 MUVERA 相较于现有的多向量检索系统的显著特点在于：

- 它能够在多种数据集上始终保持高召回率和低延迟。
- 所需参数调整较少，部署更加简便高效。

## 4 结论

在本文中，我们提出了 **MUVERA**——一种系统化且实用的多向量 (MV) 检索算法，该算法通过构建多向量表示的固定维度编码 (FDEs)，将 MV 相似度转换为单向量 (SV) 相似度。

我们证明了 FDE 点积能够高质量地近似 Chamfer 相似度 (§2.1)。

实验结果表明，FDE 比 SV 启发式方法更有效，因为它仅需检索 **2-4 倍更少的候选项**即可达到相同的召回率 (§3.1)。

我们进一步通过端到端评估验证了 MUVERA 的性能，结果显示：

- 相较于 PLAID，MUVERA 平均召回率提高 **10%**，延迟降低 **90%**。
- 尽管 PLAID 针对 SV 启发式方法进行了广泛的优化，我们在 6 个 BEIR 数据集中的 5 个上仍显著优于 PLAID (§3)。

考虑到 FDE 方法相较于 SV 启发式的检索效率优势，我们相信，通过进一步优化 FDE 方法，仍可获得显著的性能提升。我们将这一方向留作未来研究。

---

**更广泛的影响与局限性：**

检索是大型语言模型 (LLMs) 的重要组成部分，而 LLMs 本身可能带来更广泛的社会影响。不过，我们的检索算法只是提高了检索效率，并未引入任何全新的功能，因此不会直接导致这些影响。

**局限性：**

- 尽管我们在 6 个数据集中的 5 个上显著超越了 PLAID，但在 **MS MARCO** 数据集上的表现略逊一筹，这可能是因为 PLAID 针对 MS MARCO 进行了精细调优，鉴于该数据集的广泛使用。
- 此外，我们未研究文档的平均嵌入数量 $m_{\text {avg }}$ 对 FDE 检索质量的具体影响。这是一个值得进一步探索的研究方向。

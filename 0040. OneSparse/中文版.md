# OneSparse：面向多索引向量搜索的统一系统

#### 摘要

多索引向量搜索已经成为许多应用（如推荐系统）的基石。在这种多模式混合向量空间中进行高效搜索具有挑战性，因为没有一种单一的索引设计能够适用于所有类型的向量数据。现有处理多索引混合查询的方法要么受到算法限制，要么处理效率低下。本文提出了一种名为OneSparse的==统一==多向量索引查询系统，该系统整合了多个基于posting的向量索引，这使得能够高效检索多模式数据集。OneSparse引入了一种新的多索引查询引擎设计——索引间交集下推，并优化了向量posting格式以加速多索引查询。我们的实验表明，OneSparse实现了超过6倍的搜索性能提升，同时保持了可比较的准确性。OneSparse已被集成到微软在线网页搜索和广告系统中，在Bing网页搜索上实现了超过5倍的延迟收益，在Bing赞助搜索上实现了2.0%的每千次展示收入（RPM）增长。

# 1 引言

过去几年中，数据挖掘和机器学习技术将大量非结构化数据（例如图像、视频、文档）转换为高维向量。不同类型的向量在编码非结构化数据集的不同特征方面具有各自独特的特点。例如，==密集向量特别适合于提取语义==信息，而==稀疏向量则适用于关键词匹配==任务。因此，如多模态查询[31]和多模型集成查询[28, 33]等多索引混合查询被广泛应用。这些查询在多个向量索引上运行联合搜索，比如在混合数据集中查找相似项目[29, 32]，使用稀疏和密集特征混合的协同过滤[9]等。实践证明，==多索引混合查询==在提高查询结果准确性方面非常有效[28, 33]。

---

然而，由于向量索引特殊的遍历方式，多索引联合检索面临挑战，因为无法直接对多个向量索引之间的交集进行下推操作。许多向量索引是为高效处理近似Top $K$查询而构建的，能够在毫秒内返回接近最优的$K$个近似结果$[1,8]$。如果要求以单调的方式返回结果，成本会非常高，因为它们不能在没有查询向量的情况下预先对所有向量进行排序。这些索引的遍历方式首先是接近目标区域，然后大约稳定地远离[35]。因此，在联合遍历过程中，一个索引返回的结果是否会从另一个索引中检索出来是不确定的。因此，早期交集不适用。只有在分别搜索不同的索引之后才能进行交集操作，所以现有解决方案要么以隔离的方式执行多索引搜索[14, 28, 31]，要么将多个向量融合成一个大向量然后执行单索引搜索[22, 23, 33]。

---

向量融合[22, 23, 33]将多个向量连接成一个混合向量，并在此基础上构建单一的向量索引。然而，由向量融合导致的向量维度增加会带来额外的成本，如存储、延迟和带宽。此外，由于向量相似度函数需要是可分解的（例如内积），向量融合在实际应用中受到限制。

---

另一方面，独立搜索[14, 28, 31]对向量距离度量没有限制，但它遇到了处理效率低下的问题。如图1(a)所示，这种方法为不同的向量分别独立地建立索引（例如，为稀疏向量建立倒排索引，为密集向量建立近似最近邻索引），并在每个索引上运行查询。然后，通过数据ID聚合从这些索引召回的候选者并进行排名以产生最终的Top $K$结果。然而，这种独立解决方案存在两个主要缺点，导致处理效率低下：

- 难以确定每个索引需要返回的最佳候选数量（即$K^{\prime}$），该数量能够在最小化搜索延迟的同时实现相对较高的召回率。超过$K^{\prime}$的结果会导致较长的延迟；而少于$K^{\prime}$的结果则导致较低的搜索准确性。由于$K^{\prime}$对于每次查询都是动态变化的，因此独立搜索无法预设一个固定的$K^{\prime}$来在所有情况下都达到高搜索准确性和高效率。Milvus[31]通过在交集后的剩余候选数小于所需K时迭代地扩大$K^{\prime}$来解决这个问题。然而，每次迭代都会产生大量的冗余计算，导致更长的延迟。
- 交集和排名只能在所有独立索引完成各自的$\mathrm{Top} K^{\prime}$搜索之后进行。这可能导致大量用于对每个索引的Top $K^{\prime}$候选进行评分计算和磁盘I/O的浪费，因为大部分候选将在最终的索引间交集后被丢弃。Elasticsearch[14]通过使用来自HNSW的Top $K^{\prime}$结果来缩短从倒排索引中匹配的倒排列表，减少了许多BM25计算，从而缓解了这一问题。然而，由于近似最近邻搜索是在交集之前完成的，所以并没有减少ANN距离计算。此外，它也面临着$K^{\prime}$的选择问题。

---

高性能向量索引设计的最新趋势显示出在向量数据组织和查询处理方面的相似性，这为优化多索引查询的独立搜索提供了新的机会。稀疏向量的倒排索引[27]和数十亿规模密集向量的最先进近似最近邻索引[8]都将向量组织成交叉列表。在Top $K$搜索过程中，这些索引首先找到匹配的交叉列表，然后扫描这些列表以计算Top $K$向量。

---

基于向量索引的这种共同设计，我们观察到了交集下推的关键设计优化，它可以有效解决传统多索引独立搜索中的两个主要缺点。在将搜索范围缩小到少量最近的posting列表之后，我们提出不是在每个索引的Top $K^{\prime}$操作之后对向量候选进行交集，而是在最终阶段的Top $K$之前绕过每个索引的$\operatorname{Top} K^{\prime}$操作并对向量候选进行交集，如图1(b)所示。这种方法使系统能够早期过滤低质量的数据点，从而节省大量的计算和I/O。由于我们消除了单独的$\operatorname{Top} K^{\prime}$操作，传统方法中识别最优$K^{\prime}$的困难也完全得到解决。

---

基于这一关于交集下推的关键观察，我们提出了OneSparse，一个用于多索引向量搜索的统一索引系统。OneSparse能够执行多索引混合查询，并动态生成最佳的posting合并计划，以在评分计算和排名之前实现快速的索引间交集和索引内联合。OneSparse将稀疏和密集索引统一到一个倒排索引中，并根据文档ID重新排列所有posting列表。因此，在候选posting列表的细粒度遍历过程中，当一个索引扫描到某个ID时，另一个索引中小于该ID的候选可以跳过BM25得分和欧几里得距离计算，这解决了在联合遍历过程中识别一个结果是否可以被过滤出去的难题。

---

此外，OneSparse对密集向量的posting列表应用了压缩优化，大大减少了I/O以及距离计算。与存储完整向量不同，假设posting列表存储的是一个小半径的紧凑簇，则posting中的密集向量通过其质心表示。这样，每个posting只需存储一个向量，从而可以显著减少繁重的向量距离计算。

---

简而言之，OneSparse做出了以下贡献：

- 我们提出了一种新颖的多索引搜索设计，通过交集下推高效地合并和排名向量结果。这使得对于繁重的Top $K$计算，显著减少了计算和I/O需求，从而大大提升了查询性能。
- 我们进一步压缩了密集向量的posting列表，以减少密集向量距离计算的高计算和I/O成本。
- 我们通过结合两种向量搜索算法（SPANN用于密集向量，倒排索引用于稀疏向量）实现了OneSparse。我们的实验表明，OneSparse在实现可比较的召回准确率的同时，延迟提高了超过6倍。

---

OneSparse已被证明在现实世界中有效加速多索引向量查询。它已成功集成到微软的产品线中，服务于各种在线网页搜索和广告系统，在Bing网页搜索中实现了超过5倍的延迟增益，在Bing赞助搜索中实现了2.0%的每千次展示收入（RPM）增长。

# 2 背景与相关工作

## 2.1 多索引搜索

深度学习的繁荣催生了大量的神经网络模型，这些模型将非结构化数据（如文本数据）转换为密集向量（例如具有数百维度的嵌入），比如word2vec[25]、Bert[12]和GPT-3[6]。数据集的不同表示形式（即稀疏词袋和密集向量）展示了不同方面的特征。密集向量特别适合于提取语义信息，例如在寻找与特定主题相关的文档时；而稀疏向量非常适合于关键词匹配任务，如查询与特定名称或位置关联的文档。因此，利用从单一数据集中提取的多种特征的多索引混合查询[9, 22, 23, 28]在许多场景中使用越来越广泛，并被证明可以提高搜索准确性[28, 33]。

---

**问题定义。** 给定一个由$N$个数据点组成的数据集，我们从中提取了$m$种不同的特征，表示为一组向量$X=\left\{X^{1}, X^{2}, \cdots, X^{m}\right\}$，其中$X^{i} \in \mathbb{R}^{N \times n_{i}}$是具有$n_{i}$维度的数据集的第$i^{th}$特征的集合。类似地，查询$q$可以写成$\left\{q^{1}, q^{2}, \cdots, q^{m}\right\}$，其中$q^{i} \in \mathbb{R}^{n_{i}}$。对于每个$X^{i}$，我们建立一个索引来加速搜索过程。多索引向量搜索被定义为找到所有索引检索到的Top $K$个数据项，并基于聚合函数$f$拥有最高分数：
$$
\begin{equation*}
f\left(X_{i}, q\right)=f\left(g_{1}\left(X_{i}^{1}, q^{1}\right), g_{2}\left(X_{i}^{2}, q^{2}\right), \cdots, g_{m}\left(X_{i}^{m}, q^{m}\right)\right) \tag{1}
\end{equation*}
$$

这里，$g_{1}, \cdots, g_{m}$是相似度函数，可以表示$X_{i}$和$q$之间的相关性。根据特征向量的特性选择相似度函数。对于像特征嵌入这样的密集向量，广泛使用的有欧氏距离、余弦距离和内积。对于稀疏表示如词袋模型，BM25 $[18,19]$是一种流行的选择，它可以评估查询与文档之间的相关性。

---

为了加速搜索过程，在向量上使用索引。根据向量的不同稀疏性，索引算法差异很大。对于稀疏数据，倒排索引[27]被广泛应用，利用每向量的稀疏性来优化检索速度和内存使用。倒排索引还提供索内的posting列表交集/联合，以避免由于索引本身以及不会出现在最终结果中的低质量候选者引入的重复计算和I/O成本。对于密集向量，由于维度灾难[10]，密集向量索引只提供具有一定查询准确度（即召回率）的近似结果。这些近似最近邻（ANN）索引要么组织为邻域图[13,24]或分区（基于树的[5, 26, 30]，基于哈希的[11, 20]和基于聚类的[1, $4,8,15]$）。为了支持超大规模数据集，SPANN [8]实现了最先进的性能，已被广泛应用于实际生产中支持数十亿规模的向量搜索。SPANN将数据划分为大量的posting列表（簇），并为posting列表的质心构建了一个名为SPTAG [7]的树-图混合索引，以加速最近质心的搜索过程。

---

当尝试以单调顺序检索结果时，这些索引带来了相当大的计算成本，主要是因为它们缺乏在不访问查询向量的情况下对所有向量进行预排序的能力。相反，它们遵循一种遍历方式，首先接近目标区域，然后大约逐渐远离[35]。因此，在联合遍历过程中，从一个索引获得的结果是否能从另一个索引中检索出来仍然不确定，因此简单地通过下推交集来统一多索引联合搜索是不适用的。

## 2.2 传统方法

执行多索引混合向量搜索具有挑战性，因为没有单一算法能对所有类型的数据表现良好。传统的多索引混合向量搜索方法可以分为两类：向量融合和独立搜索。

---

**向量融合**[22, 23, 33]。这种方法假设相似度函数是可分解的，如内积，并且聚合函数是加性的，如求和。通过将多个向量连接成一个混合向量，在这个混合向量上使用构建的单一索引来执行多索引混合搜索。这种方法虽然简单，但对于相似度函数和聚合函数有特殊的算法限制，这限制了它在现实世界中的应用。此外，当融合多个向量时，向量维度的增加导致存储、延迟和带宽成本上升。而且，稀疏向量的极高维度使得它们难以直接应用于向量融合框架中。

---

**独立搜索**[14, 28, 31]。这种方法使用不同的算法和数据结构分别对多个特征进行索引和搜索。以稀疏和密集混合搜索为例，独立方法利用倒排索引来管理稀疏数据（即词袋），并使用BM25得分来确定文档与查询之间的相似性。同时，它们在密集数据（即嵌入）上建立近似最近邻（ANN）索引，例如HNSW [24]或FAISS [15]。当查询到来时，首先会在两个索引中分别搜索，并从倒排索引中召回$\operatorname{Top} K^{\prime}$候选者，从ANN索引中召回Top $K^{\prime \prime}$候选者。之后，这些候选者将根据其ANN距离和BM25得分合并并排名，以获得最终的TopK结果。图1(a)展示了上述过程。

---

然而，预测两个独立索引返回的候选集大小以最小化搜索延迟同时保持准确性是一项具有挑战性的任务。考虑$S_{1}$和$S_{2}$分别为从倒排索引和ANN索引检索到的候选集。如果它们的交集大小$\left|S_{1} \cap S_{2}\right|$小于所需的结果数量$K$，一些候选者可能缺乏ANN距离和BM25得分用于最终排名阶段，从而导致准确性降低。另一方面，如果$\left|S_{1} \cap S_{2}\right|$大于$K$，结果会更准确，但这会带来额外的索引遍历成本。由于不同查询具有独特的特性，不可能为所有场景设置固定的$K^{\prime}$和$K^{\prime \prime}$大小。Milvus [31]通过迭代执行独立搜索并在交集后的剩余候选数少于所需$K$时逐步扩大$K^{\prime}$来解决这个问题。然而，每次迭代都会导致过多的向量访问和距离计算，进而导致更长的延迟。

---

另一个独立搜索的问题是，交集和排名只能在所有独立索引完成各自的Top $K^{\prime}$候选搜索后才能进行。由于每个索引扫描过程中遍历的许多候选者可能不会出现在最终的索引间交集中，这会导致大量的不必要计算和I/O成本。Elasticsearch [14]通过部分下推交集过程来缓解这一问题。它首先通过ANN搜索生成$K^{\prime}$个候选者，然后使用它们从倒排索引中筛选匹配的倒排列表，减少了许多BM25计算。然而，由于ANN搜索是在交集之前完成的，因此ANN距离计算并没有减少，被交集移除的候选者的距离仍然会被计算。此外，它也面临$K^{\prime}$的选择问题。

# 3 系统设计

在本节中，我们将提出OneSparse的架构，介绍加速搜索过程所采用的关键创新——交集下推及优化，并最终解释OneSparse为何能取得卓越性能的原因。

## 3.1 OneSparse架构

为了支持多索引混合查询，OneSparse通过管理基于posting列表的各种数据来构建统一的索引系统。图2展示了OneSparse一个典型场景（一个稀疏索引+一个密集索引）的架构。OneSparse要求所有向量索引以统一的基于posting列表的格式存储向量。

---

对于稀疏数据，OneSparse通过倒排posting列表维护稀疏向量的一个维度（即术语），这允许快速查找查询中某个词的所有相关文档。存储在倒排posting列表中的值是ID和一维特征（例如词频）的对。对于密集向量，OneSparse通过SPANN将它们聚类成若干个posting列表。此外，它还在聚类质心上构建了一个内存中的SPTAG ANN索引，以便快速导航到最近的SPANN posting列表。存储在一个SPANN posting列表中的值是该聚类内ID和密集向量的对。所有的倒排posting列表和SPANN posting列表都保存在磁盘上。表1的左两列总结了传统倒排posting列表与SPANN posting列表之间的比较。

---

OneSparse的解决方案是通用且灵活的。尽管我们的OneSparse实现结合了稀疏和密集索引（如图2所示），但只要遵循相同的基于posting的格式，OneSparse的设计也能够支持多个稀疏索引、多个密集索引及其他索引组合。

## 3.2 交集下推

通过利用OneSparse的统一架构，我们将每个索引的Top $K$接口分解，并将交集操作下推到posting列表遍历过程中。如图1所示，与传统方法在所有索引的单独Top $K^{\prime}$搜索结果之间进行交集相比，OneSparse在posting列表遍历期间就在索引间的posting列表中对向量候选进行交集。因此，我们可以绕过不在所有索引的候选posting列表中出现的数据点的评分计算（即ANN距离计算、BM25得分计算等），从而大大减少了繁重的$\mathrm{Top} K$计算中的计算和I/O，极大提升了查询性能。此外，通过下推交集，我们消除了传统独立方法中的单独Top $K$操作，因此传统方法中识别最优$K^{\prime}$的难题也得到了彻底解决。

---

然而，在联合索引遍历过程中，由于无法确定一个结果是否能在另一个索引中被检索出来（因为ANN索引和倒排索引的遍历模式不是单调的），难以判断一个数据点是否可以被丢弃。基于传统倒排索引能够在倒排列表遍历时执行索内交集/联合的特点，我们通过根据ID对SPANN posting列表中的元素进行排序来解决上述问题，这与传统的倒排索引保持一致（见表1）。这使得我们可以在多索引遍历过程中同时执行快速的多路索间posting列表交集以及索内联合。当一个索引扫描到某个ID时，另一个索引中小于该ID的候选者的BM25得分和ANN距离计算可以被跳过，从而带来显著的计算节省。我们称这种快速的多路合并算法为“fast multi-way merge algorithm”。

---

图3展示了快速多路合并算法的执行过程。在图3(a)中，OneSparse有两个不同索引的四个posting列表。我们对$_{11}$列表和$_{12}$列表取并集，以及对$_{21}$列表和$_{22}$列表取并集（索内联合），同时在两个索引的并集结果之间进行交集（索间交集）。由于每个posting列表中的ID是有序的，我们可以同时在这四个列表上计算索内联合和索间交集。例如，我们给每个候选posting列表分配一个指针，从第一列开始。假设由四个指针指向的ID分别表示为$c_{11}, c_{12}, c_{21}, c_{22}$，我们比较来自每个索引的最小指向ID，分别是$c_{1}=\min \left(c_{11}, c_{12}\right)$和$c_{2}=\min \left(c_{21}, c_{22}\right)$。这样就能高效地找到共同存在的文档ID，减少不必要的计算。

---

如果$c_{1}=c_{2}$，这意味着该候选者被所有索引召回，并可以被认为是高质量的。然后，我们根据相似度函数和聚合函数计算其排名分数，并将其插入到一个堆中（在图3中标记为黄色）。之后，我们将所有指向此ID的指针向后移动。如图3(b)所示，我们发现$c_{1}=c_{2}=1$，因此我们计算ID为1的候选者的得分并将其放入堆中。接着，将$_{11}$列表、$_{12}$列表和$_{22}$列表的指针移动到下一个候选者。

---

如果$c_{1} \neq c_{2}$，我们选择$c_{1}$和$c_{2}$中的最大值，记作$c_{\max }=\max \left(c_{1}, c_{2}\right)$。然后，所有指针可以直接跳转到ID不小于$c_{\max }$的最近候选者。我们在每个posting列表上构建跳跃表以加速这个查找过程。通过这种方式，我们可以跳过从磁盘读取的许多页面，从而减少大量的I/O成本。如图3(c)所示，我们发现$c_{1}=2$而$c_{2}=3$，因此，我们只需将$_{11}$列表和$_{12}$列表的指针移动到ID不小于3的最近候选者，分别是10和5。

---

重复上述过程直到某个索引的所有posting列表的指针完成遍历。然后，我们可以停止搜索过程，从堆中返回最终的Top-$K$结果。可以看出，OneSparse的执行时间与posting列表联合大小最小的那个索引相关。相比之下，独立方法必须等待所有索引返回Top $K^{\prime}$结果，即使快速索引早已完成搜索。这种方法能够有效减少不必要的计算和I/O开销，提高了查询的整体效率。

## 3.3 Posting-list压缩

我们发现，如果一个SPANN posting列表表示一个小的邻域，则该posting列表的质心在计算到查询向量的距离方面能够足够准确地代表其中的所有密集向量。因此，为了进一步加速搜索过程，OneSparse使用质心来代表相应posting列表中的原始全尺寸向量，从而大大减少磁盘使用。此外，由于我们不需要在索引中维护原始向量，每个posting列表的大小可以被显著压缩，这也减少了遍历索引时的磁盘I/O。更重要的是，查询向量与原始数据向量之间的距离可以用查询向量与质心之间的距离来代替。这意味着无论每个posting列表包含多少元素，距离只需要计算一次，这进一步显著节省了计算。

---

有趣的是，根据我们的实验，使用SPANN的默认设置且replication_count $=8$时，压缩后搜索准确性显著下降（例如recall@100从91%降至84%）。这是因为复制导致簇半径的增长，降低了质心的代表性。因此，我们在构建SPANN索引时通过将replication_count设置为$=1$并增加质心的数量来消除这种副作用。这样，压缩只会轻微影响搜索准确性，但却能极大地减少查询延迟。我们将在第5.2节展示这些结果。

## 3.4 OneSparse的效率

在本节中，我们将基于图4中的计算数据流图分析OneSparse稀疏和密集混合搜索的效率。这将展示设计优势，这些优势使得OneSparse相比SPANN + 倒排索引独立方法具有更优越的性能。通过这种方式，我们可以看出OneSparse如何有效地减少计算和I/O成本，同时保持较高的搜索准确性，进而实现更快、更高效的查询处理。

---

在传统的独立搜索解决方案中（图4(a)），为了计算稀疏和密集混合数据集中针对查询$q$的Top $K$最近结果，首先需要通过SPTAG定位$n_{1}$个密集向量posting列表，并通过术语匹配定位$n_{2}$个稀疏向量posting列表。然后遍历posting列表中的每个元素并计算它们的得分，这些得分要么是ANN距离，要么是BM25得分。总共进行$r_{1}$次ANN距离计算和$r_{2}$次BM25得分计算。之后，分别基于它们的得分对$r_{1}$和$r_{2}$个候选者进行排序，产生Top $K^{\prime}$和Top $K^{\prime \prime}$结果。最后，系统对$K^{\prime}$和$K^{\prime \prime}$个候选者进行交集，并再次通过聚合函数对其进行排序，产生最终的Top $K$结果。此过程的计算成本如公式2所示。

$$
\begin{align*}
t_{1}= & T_{\text {locate }}+r_{1} \times T_{\text {distance }}+r_{2} \times T_{\text {bm25 }} \\
& +T_{\text {sort }}\left(r_{1}\right)+T_{\text {sort }}\left(r_{2}\right)  \tag{2}\\
& +T_{\text {intersect }}\left(K^{\prime}, K^{\prime \prime}\right)+T_{\text {sort }}\left(K^{\prime \prime \prime}\right)
\end{align*}
$$

其中$T_{\text {locate }}$是SPTAG ANN质心搜索和术语匹配的成本，$T_{\text {distance }}$是ANN距离计算成本，$T_{b m 25}$是BM25得分计算成本，$T_{\text {sort }}(x)$是对$x$进行排序的成本，$T_{\text {intersect }}(x, y)$是$x$和$y$进行交集的成本。

---

图4(b)展示了OneSparse的稀疏和密集混合搜索计算流程图。首先，OneSparse像传统方法一样定位相同的$n_{1}$个SPANN posting列表和$n_{2}$个倒排posting列表。然后，它通过3.2节介绍的快速多路合并算法从$n_{1}+n_{2}$个posting列表中筛选出$m$个高质量向量候选者。接着，它计算这$m$个候选者的ANN距离和BM25得分以供最终排名阶段使用，返回最终的$K$个结果。如果采用了3.3节介绍的压缩优化，则由于在通过SPTAG定位最近质心时已经计算了查询与质心之间的距离，因此ANN距离计算的数量将进一步减少到零。上述过程的计算成本如公式3所示。

$$
\begin{aligned}
t_2= & T_{\text {locate }}+T_{\text {multi-way-merge }}\left(r_1, r_2\right) \\
& +m \times T_{\text {bm } 25}+T_{\text {sort }}(m)
\end{aligned}
$$

其中$T_{\text {multi-way-merge }}\left(r_{1}, r_{2}\right)$是$r_{1}$和$r_{2}$的快速多路合并算法的成本。

---

由于高维度导致ANN距离和BM25得分计算成本高昂，我们可以忽略便宜的交集成本。此外，通过交集下推预过滤低质量数据后，根据我们的实验，OneSparse将需要进行ANN距离和BM25得分计算的候选者数量最多减少了99%，即$r_{1} \gg m, r_{2} \gg m$。因此，我们有：
$$
\left\{\begin{array}{l}
T_{\text {sort }}\left(r_{1}\right)+T_{\text {sort }}\left(r_{2}\right)+T_{\text {sort }}\left(K^{\prime \prime \prime}\right) \gg T_{\text {sort }}(m)  \tag{4}\\
r_{1} \times T_{\text {distance }}+r_{2} \times T_{\text {bm } 25} \gg m \times T_{\text {bm } 25}
\end{array}\right.
$$

因此，$t_{2} \ll t_{1}$，这证明了OneSparse在多索引搜索性能上优于传统独立方法。

# 4 实现

我们在内部系统和一个开源系统（如Elasticsearch）中实现了OneSparse。

## 4.1 索引构建

对于稀疏文本数据，我们在分词后首先执行一系列操作，例如去除标点符号、转为小写、词干提取和停用词移除。这些预处理操作提高了倒排索引的质量和效率。之后，这些标记像Lucene [16]那样依次插入到倒排索引中。OneSparse支持两种稀疏向量的相似度函数：BM25和IDFSum（即IDF之和）。当选择BM25作为相似度函数时，我们需要在倒排列表中存储标记的词频。然而，当选择IDFSum得分时，则无需存储词频，从而减少了磁盘消耗。同时，与BM25得分相比，IDFSum得分还减少了评分计算过程中的乘法次数，导致搜索延迟略有改善。

---

对于密集数据，应用SPANN [8]将向量聚类成若干个posting列表。然后，我们解析原始的SPANN posting列表，并按ID对每个posting列表中的元素进行排序。如果启用了压缩，原始向量将被丢弃。此外，在构建SPANN索引过程中维护内存中的SPTAG索引，以加速最近posting列表的搜索。

## 4.2 查询处理

查询过程可以分为两个步骤。首先，通过后缀树搜索匹配术语以及通过SPTAG找到最近质心来缩小到最近的posting列表范围。然后，在候选posting列表的细粒度遍历过程中，将执行快速多路合并算法。由于OneSparse中的SPANN posting列表格式与倒排列表相同，联合和交集过程可以通过原生支持的AND/OR运算符实现。在此阶段，出现在倒排列表和posting列表中的候选者将根据给定的聚合函数进行评分，并根据其聚合分数推入堆中。一旦交集过程完成，最终的TopK结果将从堆中弹出。这种方法不仅简化了索引结构，还优化了查询处理流程，使得整个系统的性能得到了提升。

## 4.3 在Elasticsearch中的实现

我们还在Elasticsearch [14]中实现了OneSparse的压缩版本，Elasticsearch是一个广泛使用的文本搜索引擎库，利用倒排索引来服务于文档，它构建于Lucene [16]之上。

---

对于索引构建，Elasticsearch原生支持通过倒排索引处理稀疏数据，因此我们需要做的就是将密集数据转换为posting列表，以便我们可以使用倒排索引来服务这些数据。我们首先应用SPANN将密集向量聚类成若干个posting列表，获得每个密集向量所属的簇ID。然后，我们将此簇信息与相应的稀疏文本数据一起插入到Elasticsearch中，在那里它们可以使用倒排索引进行索引。

---

在搜索过程中，我们最初利用内存中的SPTAG索引来识别几个最近的簇。这一步骤包括检索簇ID，并计算簇质心与查询密集向量之间的ANN距离。随后，我们生成一个布尔查询，考虑从上一步获取的信息以及稀疏约束。这个查询结合了相关的簇ID、对应的ANN距离和文本数据，以进一步细化搜索结果。附录A展示了布尔查询的示例代码。这样的布尔查询模拟了OneSparse的索内联合和索间交集方式。执行后，我们可以从Elasticsearch得到最终的Top $K$结果。

# 5 评估

在本节中，我们将在MS MARCO [3]和Natural Questions (NQ) [21]数据集的基础上，将OneSparse与最先进的ANN搜索算法及混合搜索系统进行比较评估，并展示OneSparse在稀疏和密集混合查询方面具有卓越性能。通过这种评估方法，我们可以全面了解OneSparse相对于现有技术的优势，特别是在处理复杂混合查询时的效率和准确性。

## 5.1 实验设置

### 5.1.1 评估平台

所有实验均在运行Microsoft Windows Server 2019数据中心版的Windows服务器上进行，该服务器配备了一颗主频为2400 MHz的Intel Xeon E5-2673 v3 CPU，总共拥有16个CPU核心、128 GB内存和1.74 TB HDD。

### 5.1.2 数据集

我们使用了两个不同的数据集：

- MS MARCO [3]，这是一个包含总计8,841,823段落的段落排名数据集，我们选择评估数据作为测试数据，共有6,98/XMLSchema第一段落描述了实验的整体环境配置，包括硬件和操作系统信息。接下来的部分将详细介绍使用的数据集、评估指标以及比较的系统等细节。

- Natural Questions (NQ) [21]，这是一个包含总计152,027篇文档的问题回答数据集，我们同样选择评估数据作为测试数据，共有7,830个查询。

我们使用coCondensor [17]提取稀疏文本数据的语义信息并生成密集向量。然后，按照[2]的方法对从coCondensor提取的原始向量进行保序转换，通过增加一个维度以满足三角不等式的方式将其转换到欧几里得距离空间。因此，每个密集向量的最终维度是769。查询的真实结果由数据集本身提供，这些标签是由人工标注的相关段落。对于每个查询，我们从每个测试算法中返回Top-100的结果。

### 5.1.3 评估指标

我们评估搜索的准确性和性能。召回率是衡量查询结果相对于真实结果准确性的一个常用指标。给定真实结果集$S$和查询结果$S^{\prime}$，召回率定义为$\frac{\left|S \cap S^{\prime}\right|}{|S|}$。它广泛应用于稀疏和密集向量搜索系统中。我们在所有实验中报告recall@100。为了评估搜索性能，我们测量每次执行测试算法的平均延迟、第50百分位数、第90百分位数和第99百分位数的延迟。

### 5.1.4 评估系统

我们将OneSparse与两种系统进行比较：我们自己的内部系统和开源系统Elasticsearch 8.7.0 [14]。在我们的内部系统中，我们评估了倒排索引、SPANN、不同$K^{\prime}$和$K^{\prime \prime}$下的倒排索引+SPANN以及启用或未启用压缩的OneSparse，还包括使用BM25或IDFSum的情况。内部系统的所有算法都是用C++编写的。在Elasticsearch中，我们评估了倒排索引、HNSW及不同$K^{\prime}$下的倒排索引+HNSW，这些都是Elasticsearch原生支持的。此外，我们还测试了如第4.3节所述的Elasticsearch中的OneSparse压缩版本。所有混合搜索的聚合函数为：
$$
\begin{equation*}
\text { score }=\lambda \times \frac{1}{1+\text{l2-distance}^{2}}+\text{bm25-score} \tag{5}
\end{equation*}
$$
其中我们设定$\lambda=15,000$。各算法设置的更多细节见附录B。

## 5.2 实验结果

表2和表3展示了不同算法在MS MARCO和NQ数据集上的结果。

**混合搜索 vs 单一索引搜索。** 与单一索引检索的结果相比，通过同时利用稀疏和密集表示通常可以提升召回率。这是因为稀疏特征有助于弥补由神经模型损失导致的密集向量与真实语义之间的差距。有趣的是，我们发现了一个例外：在MS MARCO上，SPANN + 倒排索引的召回率比单独的SPANN要差。这是因为一些真实结果具有相对较低的BM25得分，而且由于MS MARCO数据集很大，从倒排索引中检索20000个候选者不足以召回这些结果。相比之下，Elasticsearch中的HNSW + 倒排索引和OneSparse能够返回所有匹配查询关键字的段落，因此它们能够实现更高的搜索准确性。至于搜索速度，传统的独立方法通常比单一索引搜索要慢得多。额外的时间消耗来自两部分：由于需要返回更多结果导致的更长遍历时间，以及额外的交集和排序时间。然而，我们观察到，在Elasticsearch中，对于MS MARCO，HNSW + 倒排索引的执行速度比仅使用倒排索引更快。这种速度提升可以归因于从HNSW检索到的候选者，这些候选者在倒排索引搜索过程中帮助过滤掉了低质量的文档。通过采用如弱AND算法等技术，可以显著减少BM25得分计算的数量，从而带来更快的搜索性能。然而，对于较小的数据集如NQ，这种优化效果可能不那么显著。因此，在这种情况下，HNSW + 倒排索引相对于仅使用倒排索引可能不会有明显的速度优势。 

---

**传统独立搜索 vs OneSparse。** 我们可以看到，在所有情况下，OneSparse比独立算法（HNSW + 倒排索引和SPANN + 倒排索引）快得多，同时在我们的实验中保持了相似甚至更高的召回率。例如，在内部系统中，未压缩的OneSparse在MS MARCO上比SPANN + 倒排索引快超过4倍，在NQ上快2倍。性能优越的主要原因是通过提前进行交集操作，我们在执行ANN距离和BM25得分计算之前过滤掉了平均超过99%的低质量候选者。当应用压缩优化时，我们可以在不损失太多准确性的前提下进一步减少搜索延迟。这主要是因为OneSparse SPANN posting列表中的密集向量足够接近，质心已经能够代表查询向量与原始密集向量之间的相关性。反过来，压缩可以减少计算ANN距离和磁盘I/O的大量成本，从而带来更好的搜索性能。在Elasticsearch中，OneSparse的压缩版本在MS MARCO和NQ上比HNSW + 倒排索引大约快20%。同时，在内部系统中，压缩后，OneSparse在MS MARCO上比SPANN + 倒排索引快超过6倍，在NQ上快3倍，比压缩前快30%。我们还可以看到，使用IDFSum得分对搜索准确性几乎没有影响。因此，在实际应用场景中，我们选择用IDFSum替代BM25，因为后者消耗更少的内存和磁盘，并且由于减少了乘法次数而有助于略微降低搜索延迟。

---

$K^{\prime}$的选择问题。OneSparse的设计也消除了$K^{\prime}$的选择问题。对于传统的独立方法，选择较大的$K^{\prime}$会导致更高的召回率，但也会增加搜索延迟，就像HNSW + 倒排索引在两个不同的$K^{\prime}$设置下的实验结果那样。即使我们可以手动找到一个平衡特定数据集搜索准确性和性能的良好$K^{\prime}$，改变数据集也可能导致最佳$K^{\prime}$的变化。例如，对于NQ数据集，在SPANN + 倒排索引中设置$K^{\prime}=1000$和$K^{\prime \prime}=10000$已经可以确保比单一索引搜索更高的召回率，同时控制延迟。然而，对于MS MARCO，这样的设置不再适用，因为数据集规模远大于NQ，我们需要从两个独立的索引中检索更多的中间结果以获得更好的搜索准确性。相比之下，OneSparse不需要选择$K^{\prime}$，并且在所有情况下都能保持高召回率和低延迟。

## 6 应用

OneSparse统一索引和检索系统已成功部署在微软Bing网页搜索和赞助搜索中，作为一个混合检索通道，同时满足Term-Match和Embedding-Match的需求，并通过混合重排序提高召回质量和性能。

---

对于赞助搜索场景，OneSparse已被集成到检索系统中超过2年，成为不可或缺的组成部分。每千次搜索请求收入（Revenue Per Mille, RPM）和不良比率（Bad Ratio）被选作衡量标准，分别评估在线A/B测试飞行中的收入增长和搜索广告质量。具体来说，RPM指的是每千次搜索请求获得的收入，这是赞助搜索场景中的核心KPI，而Bad Ratio指的是由人类专家标记为无关广告展示的比例，作为质量指标。在线A/B测试显示，OneSparse实现了+2.0%的RPM增长和-3.84%的Bad Ratio改进，这非常显著，因为原生产系统已经非常强大，集成了许多其他先进技术，例如Uni-retriever [34]、TextGNN [36]等。这些指标每小时跟踪一次，并应用统计显著性测试以确保所观察到的改进的可靠性。

---

对于网页搜索场景，在部署OneSparse解决方案后，我们获得了比传统独立搜索解决方案5倍以上的在线延迟增益，且结果质量相当。

## 7 结论

本文介绍了OneSparse，一个专为高效执行多索引向量搜索设计的新型统一索引系统。它将SPANN posting列表和倒排posting列表统一在一起，支持多索引查询和多模型集成查询。通过跨所有索引推送交集，OneSparse可以预过滤超过99%的低质量候选者并减少不必要的计算。此外，如SPANN posting列表压缩等优化进一步减少了磁盘I/O并加速了搜索过程。我们在内部系统中实现了OneSparse，并将其与Elasticsearch集成。通过对涉及稀疏和密集混合查询的两个数据集进行评估，我们展示了相比独立方法超过6倍的性能提升。OneSparse还被集成到微软在线网页搜索和广告系统中，为Bing网页搜索带来5倍以上的延迟增益，以及为Bing赞助搜索带来2.0%的每千次搜索请求收入（RPM）增长。我们希望OneSparse能够使更多的检索系统更加实用地处理多模态混合数据集。

## B 评估系统的详细信息

我们描述了第5.1.4节中介绍的每个评估算法的设置。

Elasticsearch [14]。我们在Elasticsearch 8.7.0上进行所有实验，并将所有数据插入到一个分片中。为了获得更好的搜索性能，在插入数据后，我们通过force_merge API将所有索引合并为一个段。

- 倒排索引。我们应用Elasticsearch对稀疏文本数据建立倒排索引，并通过BM25得分对文档进行排名。BM25得分的超参数采用默认值。我们选择它作为仅利用稀疏数据的基线。
- HNSW。Elasticsearch支持使用层次可导航小世界图（HNSW）[24]作为索引和搜索密集向量的算法。我们选择它作为基于图的密集数据搜索的基线。在构建索引时设置$m=16$，ef_construction $=100$，在查询搜索时设置num_candidates $=500$。
- 倒排索引 + HNSW。Elasticsearch也支持通过独立搜索实现多索引混合检索。首先从HNSW中检索出Top $K^{\prime}$候选者，并用它们来过滤来自倒排索引的匹配项，那些未出现在HNSW的Top $K^{\prime}$结果中的将跳过BM25得分计算。之后，根据其欧几里得距离和BM25得分通过聚合方程5对候选者进行评分，返回最终的Top100结果。在搜索过程中，设置$K^{\prime}=1000,2000$。
- OneSparse。我们在Elasticsearch中实现了OneSparse的压缩版本，如第4.3节所述。簇信息是由SPANN生成的。正如第3.3节所介绍的，我们将复制计数设置为1，并选择50%的数据作为头部以保持质心的代表性。此外，设置TPTNumber $=128$和CEF $=2000$以获得更好的HeadIndex质量。在搜索过程中，首先通过SPTAG搜索256个最近的posting质心。为了获得更好的聚类搜索结果，设置EnableBfs $=3$和NumberOfInitialDynamicPivots $=100$。获取256个最近的posting质心ID后，生成一个布尔查询，如第4.3节所述。最后，将其发送给Elasticsearch并得到最终的Top100结果。布尔查询中的最终得分函数与方程5相同。 

---

内部系统。为了消除不同近似最近邻（ANN）搜索算法的影响，我们也在自己的系统中进行了实验。为了确保公平性，该系统中的所有算法都是用C++编写的。

- 倒排索引。我们在自己的C++版本中重新测试了仅针对稀疏数据搜索的倒排索引。
- SPANN。这是OneSparse的基础算法之一。我们对其进行评估，以展示在不考虑ANN算法影响的情况下，通过同时利用稀疏和密集特征如何实现更好的搜索准确性。我们使用了SPANN论文[8]中报告的超参数设置，除了将posting页面限制扩展到96，并将要搜索的最近posting数量设置为64。
- 倒排索引 + SPANN。我们首先从SPANN检索Top $K^{\prime}$候选者（使用与上述仅SPANN搜索相同的设置），然后将它们与从倒排索引检索出的Top $K^{\prime \prime}$候选者进行交集操作来实现这个独立算法。合并候选者之后，我们通过与方程5相同的聚合函数对候选者进行重新排名，返回Top100的结果。这里，我们设置$K^{\prime}=1000,2000$和$K^{\prime \prime}=10000,20000$。
- OneSparse。这里使用的SPANN设置与Elasticsearch中的OneSparse相同。此外，最终的聚合函数也与方程5相同，只不过我们测试了bm25_score和idf_sum作为稀疏数据的相似度函数。

我们排除了向量融合解决方案，因为它只支持如内积这样的可分解相似度函数，这限制了它在实际应用中的使用。 


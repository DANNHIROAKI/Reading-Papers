# Understanding the Multi-vector Dense Retrieval Models

# 理解多向量密集检索模型

Qi Liu

刘奇

liuqi_67@ruc.edu.cn

Renmin University of China

中国人民大学

Beijing, China

中国北京

Jiaxin Mao*

毛佳欣*

maojiaxin@gmail.com

Renmin University of China

中国人民大学

Beijing, China

中国北京

## ABSTRACT

## 摘要

While dense retrieval has become a promising alternative to the traditional text retrieval models, such as BM25, some recent studies show that multi-vector dense retrieval models are more effective than the single-vector method in retrieval tasks. However, due to a lack of interpretability, why the multi-vector method outperforms its single-vector counterpart has not been fully studied. To fill this research gap, in this work, we investigate and compare the behaviors of single-vector and multi-vector models in retrieval. Specifically, we analyze the vocabulary distribution of dense representations by mapping them back to the sparse, vocabulary space. Our empirical findings show that the multi-vector representation has more lexical overlaps between queries and passages. Additionally, we show that this feature of multi-vector representation can enhance its ranking performance when a given passage can fulfill different information needs and thus can be retrieved by different queries. These results shed light on the internal mechanisms of multi-vector representation and may provide new perspectives for future research.

虽然密集检索已成为传统文本检索模型（如BM25）的一种有前景的替代方案，但最近的一些研究表明，多向量密集检索模型在检索任务中比单向量方法更有效。然而，由于缺乏可解释性，多向量方法为何优于单向量方法尚未得到充分研究。为了填补这一研究空白，在这项工作中，我们研究并比较了单向量和多向量模型在检索中的表现。具体来说，我们通过将密集表示映射回稀疏的词汇空间来分析其词汇分布。我们的实证研究结果表明，多向量表示在查询和段落之间有更多的词汇重叠。此外，我们还表明，当给定的段落能够满足不同的信息需求，从而可以被不同的查询检索到时，多向量表示的这一特征可以提高其排序性能。这些结果揭示了多向量表示的内部机制，并可能为未来的研究提供新的视角。

## CCS CONCEPTS

## 计算机协会概念分类

- Information systems $\rightarrow$ Language models.

- 信息系统 $\rightarrow$ 语言模型。

## KEYWORDS

## 关键词

document retrieval, dense retrieval, explainability

文档检索，密集检索，可解释性

## ACM Reference Format:

## ACM引用格式：

Qi Liu and Jiaxin Mao. 2023. Understanding the Multi-vector Dense Retrieval Models. In Proceedings of the 32nd ACM International Conference on Information and Knowledge Management (CIKM '23), October 21-25, 2023, Birmingham, United Kingdom. ACM, New York, NY, USA, 5 pages. https://doi.org/10.1145/3583780.3615282

刘奇和毛佳欣。2023年。理解多向量密集检索模型。见第32届ACM国际信息与知识管理会议（CIKM '23）论文集，2023年10月21 - 25日，英国伯明翰。美国纽约州纽约市ACM，5页。https://doi.org/10.1145/3583780.3615282

## 1 INTRODUCTION

## 1 引言

With the recent rapid development of pre-trained language models (PLMs), such as BERT [1], dense retrieval has become popular in the information retrieval community and achieved state-of-the-art ranking performance on multiple benchmarks [5, 6, 15]. Typically, these models leverage PLMs to encode queries and passages into

随着预训练语言模型（PLMs），如BERT [1] 的近期快速发展，密集检索在信息检索领域变得流行起来，并在多个基准测试中取得了最先进的排名性能 [5, 6, 15]。通常，这些模型利用预训练语言模型将查询和段落编码为

Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than the author(s) must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org.CIKM '23, October 21-25, 2023, Birmingham, United Kingdom © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM. ACM ISBN 979-8-4007-0124-5/23/10...\$15.00

允许个人或课堂使用本作品的全部或部分内容制作数字或硬拷贝，无需付费，但前提是这些拷贝不得用于盈利或商业目的，并且拷贝必须带有此声明和第一页的完整引用信息。必须尊重本作品中除作者之外其他人拥有的版权组件。允许进行带引用的摘要。否则，如需复制、重新发布、上传到服务器或分发给列表，则需要事先获得特定许可和/或支付费用。请向permissions@acm.org请求许可。CIKM '23，2023年10月21 - 25日，英国伯明翰 © 2023 版权归所有者/作者所有。出版权授权给美国计算机协会（ACM）。ACM ISBN 979 - 8 - 4007 - 0124 - 5/23/10... 15.00美元

https://doi.org/10.1145/3583780.3615282 one or more low-dimensional, dense vectors and use the vector similarity between the query and document vectors to measure the semantic relevance. Previous studies have demonstrated that these dense retrieval models substantially outperform traditional retrieval techniques such as BM25 in ranking effectiveness. Because the vector representations of passages and queries can be computed independently, efficient retrieval can be achieved by encoding the passage collection offline and using approximate nearest neighbor (ANN) search techniques to reduce the online retrieval latency.

https://doi.org/10.1145/3583780.3615282 一个或多个低维密集向量，并使用查询向量和文档向量之间的向量相似度来衡量语义相关性。先前的研究表明，这些密集检索模型在排名效果上显著优于传统检索技术，如BM25。由于段落和查询的向量表示可以独立计算，因此可以通过离线编码段落集合并使用近似最近邻（ANN）搜索技术来减少在线检索延迟，从而实现高效检索。

One commonly used technique for dense retrieval is utilizing a single vector, usually the embedding of the [CLS] token or the average-pooled embeddings of all tokens, to represent a passage or query [5]. However, Luan et al. [8] argued that single-vector representations are information bottlenecks. Therefore, more sophisticated training strategies are needed to improve the expressive power of vectors and remedy the information bottleneck $\left\lbrack  {2,{15}}\right\rbrack$ . Other researchers have proposed methods to use multiple vectors to represent queries and passages. For example, the ColBERT model represents each token in the query and passage as a vector and adopts the sum-of-max function to compute the ranking score [6]. Other approaches, such as MEBERT [8] and MVR [16], represent the query as a single vector, and the passage as a fixed number of vectors. Both of these methods can improve the ranking performance at the expense of some additional computational cost.

密集检索常用的一种技术是使用单个向量，通常是[CLS]标记的嵌入或所有标记的平均池化嵌入，来表示一个段落或查询 [5]。然而，Luan等人 [8] 认为单向量表示存在信息瓶颈。因此，需要更复杂的训练策略来提高向量的表达能力并弥补信息瓶颈 $\left\lbrack  {2,{15}}\right\rbrack$。其他研究人员提出了使用多个向量来表示查询和段落的方法。例如，ColBERT模型将查询和段落中的每个标记表示为一个向量，并采用最大和函数来计算排名分数 [6]。其他方法，如MEBERT [8] 和MVR [16]，将查询表示为单个向量，将段落表示为固定数量的向量。这两种方法都可以在牺牲一些额外计算成本的情况下提高排名性能。

However, as the multi-vector approaches are usually complex and harder to interpret than single-vector methods, the behaviors and mechanisms of multi-vector representation have not been fully studied. Specifically, we still do not know why and how the multi-vector representation outperforms the single-vector representation. In brief, we aim to investigate the following research questions:

然而，由于多向量方法通常比单向量方法更复杂且更难解释，多向量表示的行为和机制尚未得到充分研究。具体来说，我们仍然不知道多向量表示为何以及如何优于单向量表示。简而言之，我们旨在研究以下研究问题：

- RQ1: What are the differences in expressiveness between multi-vector and single-vector representations?

- RQ1：多向量表示和单向量表示在表达能力上有哪些差异？

- RQ2: When can multi-vector representations perform better than single-vector representations?

- RQ2：多向量表示何时能比单向量表示表现更好？

To address these questions, we propose a working hypothesis: there exists a mapping between dense, semantic representations and the sparse, lexical space, and multi-vector representations are more capable to capture the lexical features of queries, originated from different informational needs, after being projected into the vocabulary space.

为了解决这些问题，我们提出一个工作假设：密集语义表示和稀疏词汇空间之间存在一种映射关系，并且多向量表示在投影到词汇空间后，更能够捕捉源自不同信息需求的查询的词汇特征。

Based on this hypothesis, for RQ1, we conduct a series of experiments to assess the expressiveness of the single-vector and multi-vector representation by mapping the corresponding dense vectors to the lexical space and investigating the exact matching and weight distribution of vocabulary [11]. Our findings demonstrate that the lexical overlap in the vocabulary projection between passages and queries is more evident in multi-vector representation in comparison to single-vector representation. For RQ2, we analyze the ranking performance of different methods on the test collections in which a passage is relevant to multiple queries. We find that multi-vector representation can achieve better performance than single-vector representation when a given passage is required to serve different information needs and be retrieved by different queries. Our findings help to understand the expressiveness of multi-vector representation, and it may also offer new perspectives for future research on building multi-vector dense retrieval models.

基于这一假设，对于RQ1，我们进行了一系列实验，通过将相应的密集向量映射到词汇空间并研究词汇的精确匹配和权重分布，来评估单向量和多向量表示的表达能力 [11]。我们的研究结果表明，与单向量表示相比，多向量表示中段落和查询在词汇投影上的词汇重叠更为明显。对于RQ2，我们分析了不同方法在一个段落与多个查询相关的测试集上的排名性能。我们发现，当一个给定段落需要满足不同的信息需求并被不同的查询检索到时，多向量表示可以比单向量表示取得更好的性能。我们的研究结果有助于理解多向量表示的表达能力，也可能为未来构建多向量密集检索模型的研究提供新的视角。

---

<!-- Footnote -->

*Corresponding author.

*通讯作者。

<!-- Footnote -->

---

## 2 RELATED WORK

## 2 相关工作

The interpretability of neural IR models has been widely studied. MacAvaney et al. [9] and Wallat et al. [13] analyzed neural retrieval models via probing tasks and study their characteristics. Ram et al. [11] employed the technique of vocabulary projection to demonstrate that the representations generated by the dense retrieval model can be intuitively reflected in the lexical space. However, the behaviors and mechanisms of multi-vector dense retrieval models have not been explored in the existing work. Some researchers argued that modeling passages that contain multiple meanings as multi-vector representations can make it easier for queries from different information needs to retrieve them $\left\lbrack  {{14},{16}}\right\rbrack$ ,but they have not investigated the differences between multi-vector representations and single-vector representations in detail, nor have they analyzed whether multi-vector models do perform better in this special scenario.

神经信息检索（IR）模型的可解释性已得到广泛研究。MacAvaney等人[9]和Wallat等人[13]通过探测任务分析了神经检索模型并研究了它们的特征。Ram等人[11]采用词汇投影技术证明了密集检索模型生成的表示可以直观地反映在词汇空间中。然而，多向量密集检索模型的行为和机制在现有工作中尚未得到探索。一些研究人员认为，将包含多种含义的段落建模为多向量表示可以使来自不同信息需求的查询更容易检索到它们$\left\lbrack  {{14},{16}}\right\rbrack$，但他们没有详细研究多向量表示和单向量表示之间的差异，也没有分析多向量模型在这种特殊场景下是否确实表现更好。

In this work, we conduct a comprehensive analysis to investigate why and how multi-vector dense retrieval models outperform single-vector models and fill this research gap.

在这项工作中，我们进行了全面分析，以研究多向量密集检索模型为何以及如何优于单向量模型，并填补这一研究空白。

## 3 PRELIMINARY

## 3 预备知识

In this section, we briefly introduce the passage retrieval task and the fine-tuning process of PLMs for retrieval. Given a query $q$ and a large-scale passage collection $\mathcal{P}$ ,the task of passage retrieval is to retrieve a set of passages that are most relevant to the query $q$ from $\mathcal{P}$ . To achieve this,we first use fine-tuned PLMs to encode the query and each passage into low-dimensional dense vector representations:

在本节中，我们简要介绍段落检索任务以及预训练语言模型（PLMs）用于检索的微调过程。给定一个查询$q$和一个大规模段落集合$\mathcal{P}$，段落检索任务是从$\mathcal{P}$中检索出与查询$q$最相关的一组段落。为了实现这一目标，我们首先使用微调后的PLMs将查询和每个段落编码为低维密集向量表示：

$$
{\mathbf{e}}_{q} = {\operatorname{Enc}}_{Q}\left( q\right)  \in  {\mathbb{R}}^{d} \tag{1}
$$

$$
{\left\{  {\mathbf{e}}_{p}^{\left( i\right) }\right\}  }_{i = 1}^{m} = {\operatorname{Enc}}_{P}\left( p\right)  \in  {\mathbb{R}}^{d}.
$$

Note that the query $q$ is usually represented as a single dense vector as it can be implemented efficiently with standard ANN search, while the passage $p$ can be encoded to one or more vectors concerning different models $\left\lbrack  {5,8,{16}}\right\rbrack$ . For single-vector representation,the embedding of the [CLS] token is commonly used as the representation and $m = 1$ ,while for multi-vector representations,there are often heuristic methods employed to select $m$ embeddings. Then the similarity score $s\left( {q,p}\right)$ is calculated as follows:

请注意，查询$q$通常表示为单个密集向量，因为它可以通过标准的近似最近邻（ANN）搜索高效实现，而段落$p$可以根据不同的模型$\left\lbrack  {5,8,{16}}\right\rbrack$编码为一个或多个向量。对于单向量表示，通常使用[CLS]标记的嵌入作为表示，即$m = 1$；而对于多向量表示，通常采用启发式方法来选择$m$个嵌入。然后，相似度得分$s\left( {q,p}\right)$的计算如下：

$$
s\left( {q,p}\right)  = \mathop{\max }\limits_{{i = 1}}^{m}{\mathbf{e}}_{q}^{T}{\mathbf{e}}_{p}^{\left( i\right) }. \tag{2}
$$

To adapt the PLMs to downstream retrieval tasks, the model must be fine-tuned on large labeled retrieval datasets, and the following loss as negative log likelihood of the positive passage is commonly used to optimize the model [5]:

为了使PLMs适应下游检索任务，必须在大型有标签的检索数据集上对模型进行微调，并且通常使用以下作为正段落负对数似然的损失来优化模型[5]：

$$
\mathcal{L} =  - \log \frac{\exp \left( {s\left( {q,{p}^{ + }}\right) }\right) }{\exp \left( {s\left( {q,{p}^{ + }}\right) }\right)  + \mathop{\sum }\limits_{{{p}^{ - } \in  {\mathcal{P}}^{ - }}}\exp \left( {s\left( {q,{p}^{ - }}\right) }\right) }, \tag{3}
$$

where ${p}^{ + }$ is the positive passage that is relevant to the query,and ${\mathcal{P}}^{ - }$ is the set of irrelevant negative passages sampled from the passage collection.

其中${p}^{ + }$是与查询相关的正段落，${\mathcal{P}}^{ - }$是从段落集合中采样的不相关负段落集合。

## 4 METHODOLOGY

## 4 方法

We describe the experimental setup in Section 4.1 and the overall performance of different models in Section 4.2. Then we elaborate on the analysis methods and results in Section 4.3 and 4.4.

我们在4.1节描述实验设置，在4.2节描述不同模型的整体性能。然后在4.3节和4.4节详细阐述分析方法和结果。

### 4.1 Experimental Setup

### 4.1 实验设置

Dataset. We conduct all experiments in three widely used open-domain question-answering datasets: Nature Questions (NQ) [7], TriviaQA [4], and SQuAD [10]. These three datasets all employ the Wikipedia corpus as their passage collection. Following Karpukhin et al. [5], we use the preprocessed collection where each article is split into multiple, distinct paragraphs. The preprocessed collection includes about 21 million passages in all. We evaluate the retrieval performance of different models on the official test set of the three datasets and utilize the development sets for analysis.

数据集。我们在三个广泛使用的开放域问答数据集中进行了所有实验：自然问题（NQ）[7]、TriviaQA[4]和SQuAD[10]。这三个数据集都使用维基百科语料库作为它们的段落集合。遵循Karpukhin等人[5]的方法，我们使用预处理后的集合，其中每篇文章被拆分为多个不同的段落。预处理后的集合总共包含约2100万个段落。我们在这三个数据集的官方测试集上评估不同模型的检索性能，并利用开发集进行分析。

Models. We compare and analyze four retrieval models, namely BM25, DPR, MEBERT, and MVR. BM25 [12] is a traditional sparse retrieval model using exact match algorithms. DPR [5] is a representative single-vector dense retrieval model. MEBERT [8] and MVR [16] are multi-vector dense retrieval models. In MEBERT, the entire passage is represented by the embeddings of the first $m$ tokens. And MVR employs the addition of multiple special tokens to represent the passage,utilizing the embeddings of $m$ different special tokens. In both cases, a single vector is utilized to represent the query.

模型。我们比较和分析了四种检索模型，即BM25、DPR、MEBERT和MVR。BM25[12]是一种使用精确匹配算法的传统稀疏检索模型。DPR[5]是一种具有代表性的单向量密集检索模型。MEBERT[8]和MVR[16]是多向量密集检索模型。在MEBERT中，整个段落由前$m$个标记的嵌入表示。而MVR采用多个特殊标记的相加来表示段落，利用$m$个不同特殊标记的嵌入。在这两种情况下，都使用单个向量来表示查询。

Implementation Details. To make a fair comparison, we refine-tuned all models. Our code is based on the Tevatron toolkit [3]. We initialize all models with the weights of pre-trained BERT and fine-tune them following the training settings and hyperparameters of DPR [5]. Different from the original DPR using individual query encoder and passage encoder, for all models in our experiments, the dual encoder shares its weights. The $m$ in MEBERT and MVR is set to 4 as a good compromise between efficiency and effectiveness. Notice that we do not adopt mined hard negatives and warm-up pretraining strategies which are widely used in recent works $\left\lbrack  {2,{15},{16}}\right\rbrack$ .

实现细节。为了进行公平比较，我们对所有模型进行了微调。我们的代码基于Tevatron工具包[3]。我们使用预训练BERT的权重初始化所有模型，并按照DPR[5]的训练设置和超参数对它们进行微调。与原始DPR使用单独的查询编码器和段落编码器不同，在我们的实验中，所有模型的双编码器共享其权重。MEBERT和MVR中的$m$设置为4，以在效率和有效性之间取得良好的平衡。请注意，我们没有采用近期工作中广泛使用的挖掘难负样本和预热预训练策略$\left\lbrack  {2,{15},{16}}\right\rbrack$。

### 4.2 Overall Performance

### 4.2 整体性能

Table 1 reports the retrieval performance of four different models on the three datasets from our reproduction. As we expected, both the single-vector and the multi-vector dense retrieval model significantly outperform traditional BM25 in NQ and TriviaQA, indicating the effectiveness of neural dense retrieval models.

表1展示了我们复现的四种不同模型在三个数据集上的检索性能。正如我们所预期的，单向量和多向量密集检索模型在自然问答（NQ）和琐事问答（TriviaQA）数据集上的表现均显著优于传统的BM25算法，这表明了神经密集检索模型的有效性。

The results on the SQuAD dataset present an exceptional case that does not align with our initial expectations. As discussed in [5], the relatively low performance of dense retrieval models is caused by a significant lexical overlap between the questions and paragraphs when constructing the dataset. Therefore, the BM25 algorithm based on exact matching may perform better. ${}^{1}$

斯坦福问答数据集（SQuAD）上的结果是一个例外，与我们最初的预期不符。正如文献[5]中所讨论的，密集检索模型性能相对较低是由于在构建数据集时问题和段落之间存在大量的词汇重叠。因此，基于精确匹配的BM25算法可能表现更好。${}^{1}$

<!-- Media -->

Table 1: Retrieval performance of different models on the test set of Natural Questions, TriviaQA, and SQuAD.

表1：不同模型在自然问答（Natural Questions）、琐事问答（TriviaQA）和斯坦福问答（SQuAD）测试集上的检索性能。

<table><tr><td rowspan="2">Model</td><td colspan="3">NQ</td><td colspan="3">TriviaQA</td><td colspan="3">SQuAD</td></tr><tr><td>R@5</td><td>R@20</td><td>R@100</td><td>R@5</td><td>R@20</td><td>R@100</td><td>R@5</td><td>R@20</td><td>R@100</td></tr><tr><td>BM25 [12]</td><td>-</td><td>59.1</td><td>73.7</td><td>-</td><td>66.9</td><td>76.7</td><td>-</td><td>68.8</td><td>80.0</td></tr><tr><td>DPR [5]</td><td>66.7</td><td>79.2</td><td>86.3</td><td>70.7</td><td>79.7</td><td>85.3</td><td>33.9</td><td>52.4</td><td>71.5</td></tr><tr><td>MEBERT [8]</td><td>68.0</td><td>79.5</td><td>86.5</td><td>71.7</td><td>79.8</td><td>85.4</td><td>34.3</td><td>52.8</td><td>71.5</td></tr><tr><td>MVR [16]</td><td>67.7</td><td>79.3</td><td>86.5</td><td>71.9</td><td>79.8</td><td>85.3</td><td>34.4</td><td>52.9</td><td>71.3</td></tr></table>

<table><tbody><tr><td rowspan="2">模型</td><td colspan="3">NQ（自然问答，Natural Questions）</td><td colspan="3">常识问答（TriviaQA）</td><td colspan="3">斯坦福问答数据集（SQuAD，Stanford Question Answering Dataset）</td></tr><tr><td>R@5</td><td>R@20</td><td>R@100</td><td>R@5</td><td>R@20</td><td>R@100</td><td>R@5</td><td>R@20</td><td>R@100</td></tr><tr><td>BM25算法 [12]（Best Matching 25）</td><td>-</td><td>59.1</td><td>73.7</td><td>-</td><td>66.9</td><td>76.7</td><td>-</td><td>68.8</td><td>80.0</td></tr><tr><td>密集段落检索器 [5]（DPR，Dense Passage Retrieval）</td><td>66.7</td><td>79.2</td><td>86.3</td><td>70.7</td><td>79.7</td><td>85.3</td><td>33.9</td><td>52.4</td><td>71.5</td></tr><tr><td>多编码器BERT [8]（MEBERT，Multi-Encoder BERT）</td><td>68.0</td><td>79.5</td><td>86.5</td><td>71.7</td><td>79.8</td><td>85.4</td><td>34.3</td><td>52.8</td><td>71.5</td></tr><tr><td>最大方差缩减 [16]（MVR，Maximum Variance Reduction）</td><td>67.7</td><td>79.3</td><td>86.5</td><td>71.9</td><td>79.8</td><td>85.3</td><td>34.4</td><td>52.9</td><td>71.3</td></tr></tbody></table>

<!-- figureText: NQ SQuAD MVR 0.16 0.14 0.12 0.26 Jaccard Index 0.24 0.20 0.22 0.18 0.20 0.18 0.16 0.14 . -->

<img src="https://cdn.noedgeai.com/0195aee9-fd35-77e9-94af-bd352f141faf_2.jpg?x=152&y=566&w=718&h=248&r=0"/>

Figure 1: Jaccard index of different models on three datasets.

图1：不同模型在三个数据集上的杰卡德指数（Jaccard index）。

<!-- Media -->

Meanwhile, compared with the single-vector retrieval model, the multi-vector retrieval model achieves better performance on all three datasets. This result is consistent with the findings of previous works $\left\lbrack  {8,{16}}\right\rbrack$ . We believe that the multi-vector retrieval model can better capture the semantic information of the passage and the query, which is beneficial to retrieval, and we will discuss this in more detail later in Section 4.3 and 4.4.

同时，与单向量检索模型相比，多向量检索模型在所有三个数据集上都取得了更好的性能。这一结果与先前的研究结果一致 $\left\lbrack  {8,{16}}\right\rbrack$ 。我们认为，多向量检索模型能够更好地捕捉段落和查询的语义信息，这有利于检索，我们将在后面的4.3节和4.4节中更详细地讨论这一点。

### 4.3 Vocabulary Projection

### 4.3 词汇投影

The first analysis we conduct is to project the dense, semantic representations of queries and paragraphs onto the sparse, lexical space, using the masked language modeling (MLM) head of PLMs:

我们进行的第一项分析是使用预训练语言模型（PLMs）的掩码语言建模（MLM）头，将查询和段落的密集语义表示投影到稀疏的词汇空间中：

$$
Q = \operatorname{MLM-Head}\left( {\mathbf{e}}_{q}\right)  \in  {\mathbb{R}}^{\left| V\right| }
$$

$$
{P}^{\left( i\right) } = \operatorname{MLM-Head}\left( {\mathbf{e}}_{p}^{\left( i\right) }\right)  \in  {\mathbb{R}}^{\left| V\right| }, \tag{4}
$$

where $\left| V\right|$ is the size of the vocabulary.

其中 $\left| V\right|$ 是词汇表的大小。

Intuitively, we assume there exists a mapping between dense representations and the lexical space, so projecting the dense vectors onto the lexical space can help us analyze the semantic information learned by the dense representation and the difference between single-vector representations and multi-vector representations. To be more specific, as the MLM head is typically used in the MLM task to predict the masked tokens during pre-training, we can assume it had learned the mapping from dense representation to the lexical space. Therefore,the $\left| V\right|$ -dimension output of the MLM head can be regarded as the probability distribution over the vocabulary.

直观地说，我们假设密集表示和词汇空间之间存在一种映射关系，因此将密集向量投影到词汇空间可以帮助我们分析密集表示所学习到的语义信息，以及单向量表示和多向量表示之间的差异。更具体地说，由于MLM头通常在MLM任务的预训练过程中用于预测掩码标记，我们可以假设它已经学习到了从密集表示到词汇空间的映射。因此，MLM头的 $\left| V\right|$ 维输出可以被视为词汇表上的概率分布。

Lexical Overlap. We analyze the lexical overlap between the query and the passage. Specifically,we select the tokens with top- $k$ probability in $Q$ and ${P}^{\left( i\right) }$ ,denoted as ${Q}_{k}$ and ${P}_{k}^{\left( i\right) }$ respectively,and

词汇重叠。我们分析查询和段落之间的词汇重叠情况。具体来说，我们分别选择 $Q$ 和 ${P}^{\left( i\right) }$ 中概率最高的前 $k$ 个标记，分别记为 ${Q}_{k}$ 和 ${P}_{k}^{\left( i\right) }$ ，并且

Table 2: The occurrence of a passage as a positive appears in 1 , 2, or $\geq$ 3 queries. Because only the first positive passage of one query will be selected during training though there may be multiple positives, the statistic of the training set follows the same rule. But for the dev set, we select all positive passages since all positives that include answers will be a concern while evaluating.

表2：一个段落作为正例出现在1、2或 $\geq$ 3个查询中的情况。由于在训练过程中，尽管一个查询可能有多个正例，但只会选择第一个正例段落，因此训练集的统计遵循相同的规则。但对于验证集，我们选择所有正例段落，因为在评估时，所有包含答案的正例都会被考虑在内。

<!-- Media -->

<table><tr><td rowspan="2"/><td colspan="3">Train</td><td colspan="3">$\mathbf{{Dev}}$</td></tr><tr><td>1</td><td>2</td><td>≥3</td><td>1</td><td>2</td><td>≥3</td></tr><tr><td>NQ</td><td>32030</td><td>4944</td><td>3526</td><td>42290</td><td>2398</td><td>470</td></tr><tr><td>TriviaQA</td><td>43325</td><td>5306</td><td>1782</td><td>73161</td><td>3602</td><td>418</td></tr><tr><td>SQuAD</td><td>8473</td><td>6064</td><td>11772</td><td>37761</td><td>1848</td><td>240</td></tr></table>

<table><tbody><tr><td rowspan="2"></td><td colspan="3">训练</td><td colspan="3">$\mathbf{{Dev}}$</td></tr><tr><td>1</td><td>2</td><td>≥3</td><td>1</td><td>2</td><td>≥3</td></tr><tr><td>自然问题（Natural Questions，NQ）</td><td>32030</td><td>4944</td><td>3526</td><td>42290</td><td>2398</td><td>470</td></tr><tr><td>琐事问答数据集（TriviaQA）</td><td>43325</td><td>5306</td><td>1782</td><td>73161</td><td>3602</td><td>418</td></tr><tr><td>斯坦福问答数据集（Stanford Question Answering Dataset，SQuAD）</td><td>8473</td><td>6064</td><td>11772</td><td>37761</td><td>1848</td><td>240</td></tr></tbody></table>

<!-- Media -->

compute the Jaccard index to measure the lexical overlap between these two sets. For multi-vector representation, since we determine the similarity between a query vector and multiple passage vectors by computing the maximum similarity score, we also utilize the maximum value as a measure in this case. The Jaccard index is defined as:

计算杰卡德指数（Jaccard index）以衡量这两个集合之间的词汇重叠度。对于多向量表示，由于我们通过计算最大相似度得分来确定查询向量与多个段落向量之间的相似度，因此在这种情况下，我们也使用最大值作为衡量标准。杰卡德指数的定义如下：

$$
\operatorname{Jaccard}\left( {q,p,k}\right)  = \mathop{\max }\limits_{i}^{m}\frac{\left| {Q}_{k} \cap  {P}_{k}^{\left( i\right) }\right| }{\left| {Q}_{k} \cup  {P}_{k}^{\left( i\right) }\right| }. \tag{5}
$$

The results on the development sets are shown in Figure 1. We can see that the Jaccard index of the multi-vector retrieval model is higher than that of the single-vector retrieval model on all three datasets. This indicates that the multi-vector retrieval model can better capture the lexical overlap between the query and the passage, which is beneficial to retrieval.

开发集上的结果如图1所示。我们可以看到，在所有三个数据集上，多向量检索模型的杰卡德指数都高于单向量检索模型。这表明多向量检索模型能够更好地捕捉查询与段落之间的词汇重叠，这对检索是有益的。

### 4.4 Passages Retrieved by Multiple Queries

### 4.4 多查询检索的段落

To further investigate in what situation the multi-vector dense retrieval model outperforms the single-vector model, we create a specialized dataset based on the development set, in which each paragraph is relevant to multiple queries. We analyze the retrieval performance of different models on this dataset.

为了进一步研究多向量密集检索模型在何种情况下优于单向量模型，我们基于开发集创建了一个专门的数据集，其中每个段落与多个查询相关。我们分析了不同模型在该数据集上的检索性能。

We first analyze the relationship between the number of passages and the number of queries in the datasets. To be more specific, we focus on the number of queries that can retrieve the same passage. Table 2 presents the number of queries corresponding to each passage in the training and development sets across different datasets. It is evident from Table 2 that each of the three datasets presents an issue where many passages are repeated as positive passages for multiple queries from different information needs. Moreover, we believe that the single-vector retrieval model may have limitations when retrieving these passages. To verify our assumption, we select the passages that have more than or equal to 3 queries in the development set to conduct a new subset and use it for evaluation.

我们首先分析数据集中段落数量与查询数量之间的关系。更具体地说，我们关注能够检索到同一段落的查询数量。表2展示了不同数据集的训练集和开发集中每个段落对应的查询数量。从表2中可以明显看出，三个数据集中的每一个都存在一个问题，即许多段落作为来自不同信息需求的多个查询的正例段落被重复使用。此外，我们认为单向量检索模型在检索这些段落时可能存在局限性。为了验证我们的假设，我们选择开发集中有3个或更多查询的段落组成一个新的子集，并用于评估。

---

<!-- Footnote -->

${}^{1}$ We can’t reproduce the original results of DPR. The paper by Wu et al. [14] also reports similar results and our reproduced results align with theirs. For a fair comparison, we only report the results based on our reproduction.

${}^{1}$ 我们无法复现DPR的原始结果。Wu等人的论文[14]也报告了类似的结果，并且我们的复现结果与他们的一致。为了进行公平比较，我们仅报告基于我们复现的结果。

<!-- Footnote -->

---

<!-- Media -->

Table 3: Retrieval performances on the conducted test set. The absolute difference between the multi-vector dense retrieval model and DPR is indicated in parentheses.

表3：在进行的测试集上的检索性能。多向量密集检索模型与DPR之间的绝对差异在括号中表示。

<table><tr><td rowspan="2">Model</td><td colspan="3">$\mathbf{{NQ}}$</td><td colspan="3">TriviaQA</td><td colspan="3">SQuAD</td></tr><tr><td>MRR@1</td><td>MRR@20</td><td>R@20</td><td>MRR@1</td><td>MRR@20</td><td>R@20</td><td>MRR@1</td><td>MRR@20</td><td>R@20</td></tr><tr><td>DPR</td><td>13.1</td><td>20.3</td><td>40.3</td><td>6.1</td><td>12.7</td><td>38.8</td><td>30.6</td><td>41.3</td><td>68.2</td></tr><tr><td>MEBERT</td><td>13.0 (-0.1)</td><td>20.2 (-0.1)</td><td>40.6 (+0.3)</td><td>${6.1}\left( {+{0.0}}\right)$</td><td>12.8 (+0.1)</td><td>38.7 (-0.1)</td><td>31.0 (+0.4)</td><td>41.3 (+0.0)</td><td>68.1 (-0.1)</td></tr><tr><td>MVR</td><td>13.4 (+0.3)</td><td>20.4 (+0.1)</td><td>40.8 (+0.5)</td><td>${6.7}\left( {+{0.6}}\right)$</td><td>13.6 (+0.9)</td><td>39.8 (+1.0)</td><td>31.0 (+0.4)</td><td>41.6 (+0.3)</td><td>69.5 (+1.3)</td></tr></table>

<table><tbody><tr><td rowspan="2">模型</td><td colspan="3">$\mathbf{{NQ}}$</td><td colspan="3">琐事问答数据集（TriviaQA）</td><td colspan="3">斯坦福问答数据集（SQuAD）</td></tr><tr><td>前1名平均倒数排名（MRR@1）</td><td>前20名平均倒数排名（MRR@20）</td><td>R@20</td><td>前1名平均倒数排名（MRR@1）</td><td>前20名平均倒数排名（MRR@20）</td><td>R@20</td><td>前1名平均倒数排名（MRR@1）</td><td>前20名平均倒数排名（MRR@20）</td><td>R@20</td></tr><tr><td>密集段落检索器（DPR）</td><td>13.1</td><td>20.3</td><td>40.3</td><td>6.1</td><td>12.7</td><td>38.8</td><td>30.6</td><td>41.3</td><td>68.2</td></tr><tr><td>多编码器BERT（MEBERT）</td><td>13.0 (-0.1)</td><td>20.2 (-0.1)</td><td>40.6 (+0.3)</td><td>${6.1}\left( {+{0.0}}\right)$</td><td>12.8 (+0.1)</td><td>38.7 (-0.1)</td><td>31.0 (+0.4)</td><td>41.3 (+0.0)</td><td>68.1 (-0.1)</td></tr><tr><td>多向量检索（MVR）</td><td>13.4 (+0.3)</td><td>20.4 (+0.1)</td><td>40.8 (+0.5)</td><td>${6.7}\left( {+{0.6}}\right)$</td><td>13.6 (+0.9)</td><td>39.8 (+1.0)</td><td>31.0 (+0.4)</td><td>41.6 (+0.3)</td><td>69.5 (+1.3)</td></tr></tbody></table>

<!-- figureText: NQ TriviaQA SQuAD DPR MEBERT 0.24 0.20 0.16 10 20 0.28 0.26 Jaccard Index 0.24 0.22 0.18 0.18 0.16 0.16 10 20 -->

<img src="https://cdn.noedgeai.com/0195aee9-fd35-77e9-94af-bd352f141faf_3.jpg?x=155&y=575&w=715&h=246&r=0"/>

Figure 2: Jaccard index on the conducted test set.

图2：在进行的测试集上的杰卡德指数（Jaccard index）。

<!-- Media -->

The results are shown in Table 3. In order to demonstrate the effectiveness of multi-vector retrieval in this scenario in terms of positioning relevant documents at the forefront, we also report the MRR as a reference. We can observe that the two multi-vector dense retrieval models exhibit different performances. MEBERT demonstrates only a slight performance improvement even worse compared to the single-vector model DPR, while MVR's performance is better than DPR across all different datasets. Based on these experimental results, we conjecture that MEBERT's multi-vector representation is constructed by selecting the embeddings of the top $m$ tokens,which,while overcoming the information bottleneck through multiple vector representations, fails to capture the information of multiple semantics. Therefore, it still performs poorly when faced with different queries. In contrast, MVR encodes multiple vectors by introducing multiple special tokens of equal status, so MVR can better learn to model different semantic aspects of a single passage with multi-vector representations.

结果如表3所示。为了证明多向量检索在将相关文档置于前列方面在该场景中的有效性，我们还报告了平均倒数排名（MRR）作为参考。我们可以观察到，两种多向量密集检索模型表现出不同的性能。多嵌入BERT（MEBERT）与单向量模型密集段落检索器（DPR）相比，仅表现出轻微的性能提升，甚至更差，而多向量检索器（MVR）在所有不同的数据集上的性能都优于DPR。基于这些实验结果，我们推测MEBERT的多向量表示是通过选择前$m$个标记的嵌入来构建的，虽然它通过多向量表示克服了信息瓶颈，但未能捕捉到多种语义的信息。因此，当面对不同的查询时，它的表现仍然不佳。相比之下，MVR通过引入多个地位相等的特殊标记来编码多个向量，因此MVR可以更好地学习用多向量表示对单个段落的不同语义方面进行建模。

To further analyze the reason for the performance difference between MEBERT and MVR, We also analyze the lexical overlap between the query and the passage on this new dataset. The results are shown in Figure 2. We can observe that the Jaccard index of the multi-vector representation is still higher than that of the DPR. Moreover, in the new test set with multiple queries, the Jaccard index of the MVR model has significantly increased compared to the original development set, while the performance of MEBERT remains relatively stable. This confirms that MVR is indeed more adept at handling scenarios with multiple queries.

为了进一步分析MEBERT和MVR性能差异的原因，我们还分析了在这个新数据集上查询和段落之间的词汇重叠情况。结果如图2所示。我们可以观察到，多向量表示的杰卡德指数仍然高于DPR。此外，在具有多个查询的新测试集中，MVR模型的杰卡德指数与原始开发集相比显著增加，而MEBERT的性能保持相对稳定。这证实了MVR确实更擅长处理具有多个查询的场景。

## 5 DISCUSSION

## 5 讨论

In this section, we discuss the results presented in Section 4 and respond to the research questions we posed in the introduction.

在本节中，我们讨论第4节中呈现的结果，并回应我们在引言中提出的研究问题。

For $\mathbf{{RQ1}}$ ,the retrieval performance of multi-vector dense retrieval models can be explained through the method of vocabulary projection. Our findings demonstrate that multi-vector representation has higher lexical overlap than single-vector after projection.

对于$\mathbf{{RQ1}}$，多向量密集检索模型的检索性能可以通过词汇投影的方法来解释。我们的研究结果表明，投影后多向量表示比单向量具有更高的词汇重叠。

However, the higher lexical overlap between queries and passages in different multi-vector dense retrieval models may stem from different reasons. Concerning MEBERT, we posit that it is essentially an enhancement of the embedding of [CLS] token, resulting in increased lexical overlap and improved retrieval performance. As for the other vectors, we believe that their roles are more evident in training rather than retrieval, which is proven in our prior experiments. But for MVR, we believe that its higher lexical overlap stems from modeling different semantic aspects of passages across various vectors since these vectors all have equal status and tend to become more diverse during training [16].

然而，不同多向量密集检索模型中查询和段落之间较高的词汇重叠可能源于不同的原因。关于MEBERT，我们认为它本质上是对[CLS]标记嵌入的增强，从而导致词汇重叠增加和检索性能提高。至于其他向量，我们认为它们的作用在训练中比在检索中更明显，这在我们之前的实验中得到了证明。但对于MVR，我们认为其较高的词汇重叠源于通过各种向量对段落的不同语义方面进行建模，因为这些向量地位相等，并且在训练过程中趋于更加多样化[16]。

The difference also leads to various performances of these two multi-vector dense retrieval models in retrieval, which contributes to the understanding of RQ2. Our experimental results demonstrate that the advantage of a multi-vector dense retrieval model such as MVR, becomes more pronounced when a passage will be retrieved by different queries. This is because its diverse multi-vector representation can better capture various semantic information in the passage, enabling it to be retrieved by different queries. In contrast, MEBERT or a single-vector dense retrieval model may encounter difficulties in this situation.

这种差异也导致了这两种多向量密集检索模型在检索中的不同表现，这有助于理解研究问题2（RQ2）。我们的实验结果表明，像MVR这样的多向量密集检索模型的优势在一个段落需要被不同查询检索时变得更加明显。这是因为其多样化的多向量表示可以更好地捕捉段落中的各种语义信息，使其能够被不同的查询检索到。相比之下，MEBERT或单向量密集检索模型在这种情况下可能会遇到困难。

Our results suggest the need for training dense retrieval models that can represent the diverse information of each passage and fulfill queries originated from different information needs. It is necessary to benchmark dense retrieval models in this more realistic and challenging scenario and build more stable and powerful multi-vector models to further improve the retrieval performance.

我们的结果表明，需要训练能够表示每个段落的多样化信息并满足源自不同信息需求的查询的密集检索模型。有必要在这个更现实和更具挑战性的场景中对密集检索模型进行基准测试，并构建更稳定、更强大的多向量模型，以进一步提高检索性能。

## 6 CONCLUSION

## 6 结论

In this paper, we investigate the behaviors and mechanisms of multi-vector dense retrieval models. Our analysis results show that the multi-vector dense retrieval model has more lexical overlaps between queries and passages when the dense, semantic vectors are projected to lexical, sparse vocabulary space. Moreover, we find that the multi-vector model's ranking performance is better when a passage needs to fulfill different information needs. These results may provide new perspectives for future research.

在本文中，我们研究了多向量密集检索模型的行为和机制。我们的分析结果表明，当将密集的语义向量投影到词汇稀疏的词汇空间时，多向量密集检索模型在查询和段落之间具有更多的词汇重叠。此外，我们发现当一个段落需要满足不同的信息需求时，多向量模型的排序性能更好。这些结果可能为未来的研究提供新的视角。

## ACKNOWLEDGMENTS

## 致谢

This research was supported by the Natural Science Foundation of China (61902209), the Fundamental Research Funds for the Central Universities, and the Research Funds of Renmin University of China (22XNKJ15).

本研究得到了国家自然科学基金（61902209）、中央高校基本科研业务费专项资金以及中国人民大学科研基金（22XNKJ15）的资助。

## REFERENCES

## 参考文献

[1] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. 2019. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. In Proceedings of NAACL-HLT. 4171-4186.

[1] 雅各布·德夫林（Jacob Devlin）、张明伟（Ming-Wei Chang）、肯顿·李（Kenton Lee）和克里斯蒂娜·图托纳娃（Kristina Toutanova）。2019年。BERT：用于语言理解的深度双向变换器的预训练。《北美计算语言学协会人类语言技术会议论文集》。4171 - 4186。

[2] Luyu Gao and Jamie Callan. 2021. Condenser: a Pre-training Architecture for Dense Retrieval. In Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing. 981-993.

[2] 高璐宇（Luyu Gao）和杰米·卡兰（Jamie Callan）。2021年。凝聚器（Condenser）：一种用于密集检索的预训练架构。《2021年自然语言处理经验方法会议论文集》。981 - 993。

[3] Luyu Gao, Xueguang Ma, Jimmy J. Lin, and Jamie Callan. 2022. Tevatron: An Efficient and Flexible Toolkit for Dense Retrieval. ArXiv abs/2203.05765 (2022).

[3] 高璐宇、马学光、吉米·J·林和杰米·卡兰。2022 年。Tevatron：一个高效且灵活的密集检索工具包。预印本 arXiv:2203.05765 (2022)。

[4] Mandar Joshi, Eunsol Choi, Daniel S Weld, and Luke Zettlemoyer. 2017. TriviaQA: A Large Scale Distantly Supervised Challenge Dataset for Reading Comprehension. In Proceedings of the 55th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1601-1611.

[4] 曼达尔·乔希、崔恩索尔、丹尼尔·S·韦尔德和卢克·泽特勒莫耶。2017 年。TriviaQA：一个用于阅读理解的大规模远程监督挑战数据集。见《第 55 届计算语言学协会年会论文集（第 1 卷：长论文）》。1601 - 1611。

[5] Vladimir Karpukhin, Barlas Oguz, Sewon Min, Patrick Lewis, Ledell Wu, Sergey Edunov, Danqi Chen, and Wen-tau Yih. 2020. Dense Passage Retrieval for Open-Domain Question Answering. In Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP). 6769-6781.

[5] 弗拉基米尔·卡尔普欣、巴拉斯·奥古兹、闵世元、帕特里克·刘易斯、莱德尔·吴、谢尔盖·叶杜诺夫、陈丹琦和易文涛。2020 年。用于开放域问答的密集段落检索。见《2020 年自然语言处理经验方法会议（EMNLP）论文集》。6769 - 6781。

[6] Omar Khattab and Matei Zaharia. 2020. ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. In Proceedings of the 43rd International ACM SIGIR conference on research and development in Information Retrieval. 39-48.

[6] 奥马尔·哈塔卜和马特·扎哈里亚。2020 年。ColBERT：通过基于 BERT 的上下文后期交互实现高效有效的段落搜索。见《第 43 届 ACM SIGIR 信息检索研究与发展国际会议论文集》。39 - 48。

[7] Tom Kwiatkowski, Jennimaria Palomaki, Olivia Redfield, Michael Collins, Ankur Parikh, Chris Alberti, Danielle Epstein, Illia Polosukhin, Jacob Devlin, Kenton Lee, et al. 2019. Natural Questions: A Benchmark for Question Answering Research. Transactions of the Association for Computational Linguistics 7 (2019), 452-466.

[7] 汤姆·夸特科夫斯基、珍妮玛丽亚·帕洛马基、奥利维亚·雷德菲尔德、迈克尔·柯林斯、安库尔·帕里克、克里斯·阿尔贝蒂、丹妮尔·爱泼斯坦、伊利亚·波洛苏金、雅各布·德夫林、肯顿·李等。2019 年。自然问题：一个问答研究基准。《计算语言学协会汇刊》7 (2019)，452 - 466。

[8] Yi Luan, Jacob Eisenstein, Kristina Toutanova, and Michael Collins. 2021. Sparse, Dense, and Attentional Representations for Text Retrieval. Transactions of the Association for Computational Linguistics 9 (2021), 329-345.

[8] 栾义、雅各布·艾森斯坦、克里斯蒂娜·图托纳娃和迈克尔·柯林斯。2021 年。用于文本检索的稀疏、密集和注意力表示。《计算语言学协会汇刊》9 (2021)，329 - 345。

[9] Sean MacAvaney, Sergey Feldman, Nazli Goharian, Doug Downey, and Arman Cohan. 2022. ABNIRML: Analyzing the Behavior of Neural IR Models. Transactions of the Association for Computational Linguistics 10 (2022), 224-239.

[9] 肖恩·麦卡瓦尼、谢尔盖·费尔德曼、纳兹利·戈哈瑞安、道格·唐尼和阿曼·科汉。2022 年。ABNIRML：分析神经信息检索模型的行为。《计算语言学协会汇刊》10 (2022)，224 - 239。

[10] Pranav Rajpurkar, Jian Zhang, Konstantin Lopyrev, and Percy Liang. 2016. SQuAD: 100,000+ Questions for Machine Comprehension of Text. In Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing. 2383-2392.

[10] 普拉纳夫·拉朱帕尔卡、张健、康斯坦丁·洛皮列夫和梁佩诗。2016 年。SQuAD：用于机器文本理解的 100000 多个问题。见《2016 年自然语言处理经验方法会议论文集》。2383 - 2392。

[11] Ori Ram, Liat Bezalel, Adi Zicher, Yonatan Belinkov, Jonathan Berant, and Amir Globerson. 2022. What Are You Token About? Dense Retrieval as Distributions Over the Vocabulary. arXiv preprint arXiv:2212.10380 (2022).

[11] 奥里·拉姆、利亚特·贝扎莱尔、阿迪·齐彻、约纳坦·贝林科夫、乔纳森·贝兰特和阿米尔·格洛伯森。2022 年。你在说什么 Token？将密集检索视为词汇上的分布。预印本 arXiv:2212.10380 (2022)。

[12] Stephen Robertson, Hugo Zaragoza, et al. 2009. The probabilistic relevance framework: BM25 and beyond. Foundations and Trends® in Information Retrieval 3, 4 (2009), 333-389.

[12] 斯蒂芬·罗伯逊、雨果·萨拉萨尔等。2009 年。概率相关性框架：BM25 及其他。《信息检索基础与趋势》3, 4 (2009)，333 - 389。

[13] Jonas Wallat, Fabian Beringer, Abhijit Anand, and Avishek Anand. 2023. Probing BERT for ranking abilities. In Advances in Information Retrieval: 45th European Conference on Information Retrieval, ECIR 2023, Dublin, Ireland, April 2-6, 2023, Proceedings, Part II. Springer, 255-273.

[13] 乔纳斯·瓦拉特、法比安·贝林格、阿比吉特·阿南德和阿维谢克·阿南德。2023 年。探究 BERT 的排序能力。见《信息检索进展：第 45 届欧洲信息检索会议，ECIR 2023，爱尔兰都柏林，2023 年 4 月 2 - 6 日，会议录，第二部分》。施普林格出版社，255 - 273。

[14] Bohong Wu, Zhuosheng Zhang, Jinyuan Wang, and Hai Zhao. 2022. Sentence-aware contrastive learning for open-domain passage retrieval. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 1062-1074.

[14] 吴伯鸿、张卓生、王锦源和赵海。2022 年。用于开放域段落检索的句子感知对比学习。见《第 60 届计算语言学协会年会论文集（第 1 卷：长论文）》。1062 - 1074。

[15] Lee Xiong, Chenyan Xiong, Ye Li, Kwok-Fung Tang, Jialin Liu, Paul N Bennett, Junaid Ahmed, and Arnold Overwijk. 2020. Approximate Nearest Neighbor Negative Contrastive Learning for Dense Text Retrieval. In International Conference on Learning Representations.

[15] 熊磊、熊晨彦、李烨、邓国峰、刘佳琳、保罗·N·贝内特、朱奈德·艾哈迈德和阿诺德·奥弗维克。2020 年。用于密集文本检索的近似最近邻负对比学习。见《国际学习表征会议》。

[16] Shunyu Zhang, Yaobo Liang, Ming Gong, Daxin Jiang, and Nan Duan. 2022. MultiView Document Representation Learning for Open-Domain Dense Retrieval. In Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers). 5990-6000.

[16] 张顺宇、梁耀波、龚明、蒋大新和段楠。2022 年。用于开放域密集检索的多视图文档表示学习。见《第 60 届计算语言学协会年会论文集（第 1 卷：长论文）》。5990 - 6000。
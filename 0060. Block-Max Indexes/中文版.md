### 基于块最大索引的快速Top-k文档检索

#### 摘要

大型搜索引擎每秒处理数千个查询，涉及数十亿个文档，这使得查询处理成为主要的性能瓶颈。一类重要的优化技术称为早期终止，通过避免对不太可能进入前几名结果的文档进行评分，从而实现更快的查询处理。我们研究了新的早期终止算法，这些算法优于之前的方法。特别是，我们专注于处理析取查询的安全技术，这些技术返回的结果与对查询项的析取进行详尽评估的结果相同。当前最先进的方法，如Broder等人提出的WAND算法[11]以及Strohman和Croft的方法[30]，虽然取得了很大的效果，但在析取查询和（即使是未进行早期终止的）合取查询之间仍然存在较大的性能差距。

---

我们提出了一组新算法，通过引入一种称为块最大索引的简单增强倒排索引结构。本质上，这是一种将压缩倒排列表中每个块的最大影响分数以未压缩形式存储的结构，从而使我们能够跳过列表的大部分内容。我们展示了如何将这种结构集成到WAND方法中，从而实现显著的性能提升。然后，我们描述了扩展到分层索引组织以及重新分配文档ID的索引的扩展，这些扩展进一步缩小了析取和合取Top-k查询处理之间的差距。


## 1. 引言

由于互联网的快速增长，越来越多的人依赖搜索引擎来查找有用信息。因此，全球计算资源中越来越多的部分被用于与搜索相关的任务。当前的大规模搜索引擎必须能够每天处理数亿个查询，涉及数百亿个网页。因此，需要高度优化的方法来高效处理所有这些查询。

---

查询处理中的一个主要瓶颈是倒排列表索引结构的长度（在下一节中描述），对于常见术语，这些结构很容易增长到数百MB甚至GB（大致与数据集的大小呈线性关系）。鉴于搜索引擎需要在几分之一秒内回答用户查询，天真的遍历这种基本索引结构是不可接受的，因为对于常见术语，这可能需要数百毫秒甚至更长时间。

---

这个基本问题早已被研究人员认识到，并激发了大量关于优化技术的研究，包括分布式计算[29, 5, 24]、索引压缩[37]、缓存[7, 22]以及早期终止[31, 12]（也称为剪枝或优化Top-k处理）。在本文中，我们专注于早期终止，简而言之，这意味着在不详尽遍历相关索引结构的情况下返回最佳$k=10$或100个结果。特别是，我们建议通过添加额外信息来增强索引。本质上，我们在倒排列表的每个压缩块中添加一个值，即最大影响分数。虽然这是一个简单的想法，但我们不知道有任何先前的工作存储了此类信息以改善查询处理。我们称这种修改后的索引结构为块最大索引。我们还提出了一组基于WAND方法[11]的新算法，用于使用我们的块最大索引结构进行安全的早期终止（返回的结果与朴素基线完全相同）。我们的算法的一个有趣特性是它们执行文档逐次（DAAT）索引遍历，基于文档排序或影响分层的索引结构。

## 2. 背景

在本节中，我们介绍倒排索引结构、查询处理和早期终止的背景知识。

### 2.1 倒排索引与索引压缩

当前的搜索引擎基于倒排索引执行查询处理，倒排索引是一种简单高效的数据结构，允许我们找到包含特定术语的文档[37]。给定一个包含$N$个文档的集合，我们假设每个文档由一个唯一的文档ID（docID）标识，范围在0到$N-1$之间。倒排索引由许多倒排列表组成，其中每个倒排列表$L_{w}$是一个描述术语$w$在集合中所有出现位置的列表。更准确地说，每个条目包含包含术语$w$的文档的docID、术语$w$在文档中出现的次数（称为频率），有时还包括这些出现的确切位置（称为位置），以及其他可能的上下文信息（如字体大小等）。倒排列表中的条目通常按docID排序，有时也按其他度量标准排序（稍后描述）。因此，在我们存储docID和频率的情况下，每个条目的形式为$\left(d_{i}, f_{i}\right)$。本文主要关注这种情况，但我们的技术同样适用于存储位置、上下文信息或预计算量化影响分数的情况。

---

常见查询术语的倒排列表可能包含数百万甚至数十亿个条目。为了更快地访问磁盘上的列表并限制所需的内存，搜索引擎使用复杂的压缩技术来显著减小每个倒排列表的大小[37]。压缩对搜索引擎性能至关重要$[14,36]$，文献中有许多压缩技术；参见[36, 35, 27]。在本文中，我们使用New-PFD压缩方法，该方法在[35]中表现良好，但我们的想法也适用于其他压缩技术。

---

由于常见术语的列表可能非常长，我们希望能够在查询处理过程中跳过列表的大部分内容。为此，倒排列表通常被分割为块，例如每块包含64或128个docID，以便每个块可以单独解压缩。为此，我们有一个额外的表，其中存储每个块的未压缩最大（或最小）docID以及块大小。与倒排索引的大小相比，这个额外表的大小很小。因此，64或128个条目被分组为一个块，其中存储64或128个压缩的docID，随后是对应的压缩频率。

### 2.2 查询处理

基于上述倒排索引结构，最基本的查询处理形式称为布尔查询处理。例如，查询“(apple AND orange) OR pear”可以首先对包含单词apple和orange的文档的docID进行交集操作，然后将结果与包含单词pear的倒排列表进行合并。

---

搜索引擎使用排序查询处理，其中通过一个排序函数为通过简单布尔过滤器的每个文档计算一个分数，最终返回得分最高的$k$个文档。该排序函数应能够从倒排列表中的信息（即频率，可能还包括位置）以及存储在倒排索引之外的有限数量的其他统计信息（例如文档长度或全局分数，如Pagerank）高效计算。许多类似于BM25或余弦相似度的函数已被研究；详见[6]。

---

当前的网页搜索引擎使用基于数百个特征的排序函数。这些函数相当复杂，关于如何在大规模集合上高效执行它们的公开信息较少。一种“民间”方法将排序分为两个阶段。在第一阶段，使用简单且快速的排序函数（如BM25）获取前100或1000个文档。然后在第二阶段，对第一阶段返回的顶部文档应用包含数百个特征的更复杂的排序函数。由于第二阶段仅检查少量候选文档，大部分计算时间仍然花在第一阶段。本文专注于执行这种简单的第一阶段函数，例如BM25，这一问题在文献中已被广泛研究。

---

回顾一下，排序查询处理包括一个布尔过滤器，然后对通过该过滤器的文档进行评分和排序。最常用的布尔过滤器是合取（AND）和析取（OR）。一般来说，析取查询在信息检索（IR）社区中传统上被使用，而网页搜索引擎通常尽可能使用合取查询。一个原因是析取查询通常比合取查询昂贵得多（对于详尽查询处理来说，大约相差一个数量级），因为它们需要评估更多的文档。

---

为了遍历索引结构，有两种基本技术：逐文档（Document-At-A-Time, DAAT）和逐词项（Term-At-A-Time, TAAT）[32]：对于合取查询，通常首选DAAT，而许多针对析取查询的优化方法使用TAAT。

### 2.3 早期终止算法

如前所述，查询处理的一个瓶颈是倒排列表的长度。早期终止是解决这一问题的重要技术之一。如果一个查询处理算法完全评估了所有满足布尔过滤器条件的文档，我们称其为**穷举算法**。任何非穷举算法都被视为使用了早期终止（$E T$）。早期终止通常通过以下四种方式实现：

- **提前停止**：在这种情况下，条目通常被排列为最有希望的文档出现在前面。一旦我们（可能）获得了前$k$个结果，就停止遍历索引。著名的例子包括Fagin的TA、FA和NRA算法[21]；参见[8]对这些算法的高度优化实现。

- **在列表内跳过**：当每个列表中的条目按docID排序时，有希望的文档分散在倒排列表中，因此“提前停止”的标准直觉不适用。在这种情况下，关于早期终止技术的公开研究较少。一个例外是[11]中的WAND算法，它使用了一种智能指针移动技术，跳过许多会被穷举算法评估的文档。更多细节将在下文提供。

- **忽略列表**：如果查询术语的一个或多个列表对最终结果影响不大，则完全忽略它们。

- **部分评分**：我们通过仅计算某些术语分数或计算近似分数来部分评估文档。当我们发现文档不可能进入前几名结果时，停止评估；例如[33]。

---

需要注意的是，我们对$E T$的定义非常广泛，包括其他技术，如静态剪枝[10,19]和分层[16]。在本文中，我们专注于**安全早期终止**[30]，这意味着我们希望获得与朴素基线完全相同的结果，即相同的文档集、相同的顺序和相同的分数。我们将忽略其他技术，这些技术试图返回某种相似或质量相似的搜索结果。此外，我们专注于基于内存的索引，例如[30, 17]中考虑的情况，或者至少磁盘不是主要瓶颈的情况。

### 2.4 索引组织

来自数据库和信息检索社区的许多现有早期终止技术基于重新组织倒排索引的思想，使得最有希望的文档出现在倒排列表的前面。这可以通过重新排序每个列表中的条目或将索引划分为多个层或层级来实现。特别是，我们可以区分以下广泛使用的索引组织：

- **文档排序索引**：这是基本穷举查询处理的标准方法，其中每个倒排列表中的条目按文档ID排序。

- **影响排序索引**：每个列表中的条目按其影响排序，即它们对文档分数的贡献。具有相同影响的条目按文档ID排序。需要注意的是，这假设排序函数是可分解的（即每个术语分数的总和或其他简单组合），这在余弦相似度、BM25和文献中的许多其他函数中成立。

- **影响分层索引**：我们将每个列表中的条目划分为若干层，使得第$i$层中的所有条目的影响高于第$i+1$层中的条目，然后按docID对每层中的条目进行排序。

---

影响排序和影响分层索引是早期终止技术中非常流行的索引组织，因为它们将最有希望的条目放置在列表的前面[25, 21, 3, $4,8,30,23,32]$。影响排序索引的一个问题是，由于倒排列表中docID的间隔可能非常大，压缩效果可能会受到影响。在这种情况下，使用少量适当选择层的影响分层索引可能提供更好的替代方案。然而，当不同影响分数的数量较少或频率被用作影响的代理时，影响排序索引是有用的。

相比之下，文档排序索引在早期终止技术中较少被研究，只有少数算法使用它们（例如[11]）。

### 2.5 索引遍历技术

在索引遍历中，最常用的两种技术是：

- **逐文档（Document-At-A-Time, DAAT）**：在DAAT查询处理中，每个列表都有一个指针，指向列表中的“当前”条目。所有指针在查询处理过程中并行向前移动。

- **逐词项（Term-At-A-Time, TAAT）**：在TAAT查询处理中，我们首先访问一个词项或一个词项的某一层，然后移动到下一个词项或同一词项或不同词项的下一层。我们使用一个临时数据结构来跟踪当前活跃的前$k$个候选文档。

---

需要注意的是，TAAT需要额外的数据结构来存储在某些但并非所有列表中看到的有希望的候选文档；这是与DAAT的主要区别之一。在本文中，我们使用TAAT来指代任何使用非平凡数据结构来跟踪有希望候选文档的技术（超出用于当前前$k$结果的简单堆结构），因此这包括原始的逐词项技术[13]以及[3]中的逐分数技术。

---

对于合取和穷举查询执行，DAAT非常快，并且被认为是当前的最新技术（至少对于具有中等数量查询术语的查询而言），而TAAT类型的方法通常受限于非平凡的数据结构。然而，对于析取查询，很难将早期终止与分层索引与DAAT结合起来。因此，对于这种情况，文献中的大多数早期终止算法都基于使用影响排序或分层索引的TAAT。在本文中，我们挑战这一假设，并提出即使在析取查询的情况下，DAAT算法实际上可能更适合早期终止。我们注意到，DAAT确实具有显著的优势，因为它没有任何昂贵的临时数据结构。

### 2.6 两种最先进的技术

对于析取查询，现有最快的安全早期终止技术似乎是Strohman和Croft（SC）在[30]中提出的方法（基于[3, 2]中的早期工作），以及Broder等人提出的WAND方法[11]。这两种方法都是安全的，因为它们返回的前$k$结果与基线完全相同，顺序和分数都一致（实际上，原始的SC算法可能不会返回相同的分数，但可以轻松扩展以实现这一点）。

---

Strohman和Croft（SC）的方法使用影响排序索引，并假设了[3]中提出的排序函数，其中所有影响值有8个不同的值；然而，它可以通过使用影响分层索引组织扩展到诸如BM25的排序函数。该方法使用了一种逐词项（TAAT）查询处理的变体，我们首先访问列表的较高层，然后移动到具有较小影响分数的较低层；当我们确定已经包含前$k$结果的集合时，我们将从OR模式切换到AND模式，仅搜索存储在结构中的docID在剩余层中的最终正确结果。图1显示了SC的索引布局示例，其中各层大小相等。需要注意的是，原始的SC应用了不同的排序技术，因此每层的大小各不相同。我们对此进行了探索，发现使用可变大小层或等大小层并没有太大区别；我们将在下面进一步解释这一点。在SC中，使用一个排序数组来跟踪在某些但并非所有词项列表中看到的候选文档。在处理每一层后，使用一个额外的阶段来“过滤掉”无法进入前$k$的候选文档。因此，这种方法需要临时数据结构（数组）来跟踪有希望的候选文档。

- **图1**：SC的索引布局。各层按其最大影响分数降序处理。在每一层内，条目按docID排序。

---

另一方面，WAND方法使用标准的文档排序索引，因此可以采用**逐文档（Document-At-A-Time, DAAT）**方法，不需要额外的临时数据结构（除了所有方法都使用的小型前$k$堆）。其缺点是，有希望的文档分散在倒排列表中，因此早期终止的标准直觉不适用。相反，WAND使用了一种基于**枢轴（pivoting）**的巧妙指针移动策略，使其能够跳过许多会被穷举算法评估的文档。更准确地说，在DAAT查询处理中，每个列表都有一个指针，指向列表中的“当前”条目，并在查询处理过程中向前移动。因此，指针左侧的所有条目都已被处理。在整个算法中，WAND保持术语按当前docID递增的顺序排序。假设在处理查询“dog, cat, kangaroo, monkey”期间的某个时刻，当前docID分别为609、273、9007和4866，如图2所示，其中列表从上到下按这些docID排列。假设我们还知道每个列表的最大影响分数，并且要进入当前前$k$结果，文档的总分数至少需要6.8（阈值）。现在，我们从上到下累加列表的最大分数，直到达到不小于6.8的分数。在图2中，这发生在从上数第三个列表$(2.3+1.8+3.3>6.8)$。现在我们可以断言，能够进入前$k$的最小docID是4866。因此，我们可以将前两个指针向前移动到其列表中第一个docID至少为4866的条目，从而跳过这些列表中的部分条目。如果docID 4866同时出现在前两个列表中，则我们评估此docID。否则，我们根据当前docID对列表重新排序并再次枢轴。因此，WAND通过跳过无法进入前几名的条目来实现早期终止。对于阈值，我们使用包含迄今为止找到的前$k$结果的堆中的最低分数。需要注意的是，WAND还为每个列表存储一个最大影响分数，这些分数可以保存在索引的术语字典中。

- **图2**：在处理一个4术语查询的场景中，当前指针指向docID 273、609、4866和9007。WAND选择第三个列表作为枢轴，并将前面的指针移动到docID 4866。然后所有列表根据其当前docID重新排序。

---

这两种方法在索引组织和索引遍历选择上有显著不同：WAND使用文档排序索引和DAAT作为索引遍历技术，而SC使用影响排序或分层索引和TAAT，并使用额外的数据结构来保存候选文档。对于析取查询，SC似乎优于WAND，尽管我们报告的SC数据不如[30]中的速度快，因为我们使用BM25作为排序函数，并且保留了停用词并删除了单术语查询。WAND对我们来说很有意义，因为它将构成我们改进方法的基础。

## 3. 我们的贡献

在本文中，我们通过在WAND方法[11]的基础上提出了新的早期终止算法。回顾一下，WAND存储了每个倒排列表的最大影响分数。我们的初始洞察是，WAND中的跳过是有限的，因为它使用了整个列表的最大影响分数，这可能远高于平均值。回顾一下，我们有一个额外的表来存储允许我们跳过块的信息。我们建议通过在这个表中存储每个块的最大影响值来增强索引结构。我们称这种索引为**块最大索引（Block-Max Index）**。通过这种方式，我们获得了列表中影响分数的分段上界近似，如图3所示。这种近似隐藏了详细分数，图3显示了袋鼠列表中一个块的详细分数，这些分数只能通过解压缩块来获得。这个想法非常简单且易于实现。正如我们将在后面看到的，这提供了许多优化机会，并带来了显著的性能提升。

- **图3**：三个倒排列表，其中列表通过每个块中的最大分数进行分段上界近似。如底部列表中的一个块所示，在每个块内部，我们有各种值，包括许多（隐含的）零值，这些值可以通过解压缩块来检索。

---

在对索引结构进行这一微小改动后，索引大小仅略有增加，我们必须调整WAND算法以使其适用于这种结构。一个显而易见的想法是，在枢轴阶段仅使用当前块的局部最大值，而不是全局最大值。不幸的是，这并不能保证正确性。为了理解这一点，让我们看一下图4中的示例。仅查看包含当前指针的块的最大分数（即第一个列表的分数2.3，依此类推），我们无法得出4866是可以进入前$k$的最小docID的结论，因为第一个列表中docID 273之后的下一块（但docID小于4866）可能具有更高的最大影响分数。因此，直接应用局部最大值是行不通的。我们将在后面的章节中描述如何修改算法。

---

总的来说，我们在本文中做出了以下主要贡献：

1. 我们提出了一种改进的索引结构，即**块最大索引**，它仅略微增加了索引大小。然后，我们研究了基于该索引结构和[11]中的WAND方法的改进安全早期终止技术。

2. 我们展示了如何将我们的技术扩展到分层索引、重新排序的索引以及合取查询处理。

3. 我们在包含2520万份文档的TREC GOV2集合上评估了我们的技术，并展示了与最先进技术相比的显著改进。

4. 我们讨论了从我们的工作中产生的一些有趣的开放问题。

## 4. 相关工作

关于早期终止（ET）技术的先前工作可以分为两个相对独立的文献领域。在信息检索（IR）社区中，研究人员自20世纪80年代以来一直在研究用于快速评估向量空间查询的ET技术；一些早期工作出现在[13, 32, 33]中。近年来，有许多相关论文。与我们最相关的是，最近的几篇论文专注于如何使用影响排序索引[2, 3, 30]进行早期终止，从而为析取查询提供了高效的方法。

---

在数据库社区中，也有大量关于早期终止的研究；参见[21]的综述和[20]的正式分析。用IR术语来说，这些算法也假设倒排列表中的条目按其贡献排序并按排序顺序访问。然而，应用场景有所不同，许多（但不是所有）算法假设一旦在某个倒排列表中找到文档，我们可以通过在其他倒排列表中执行查找来高效评估它。这种随机查找在大多数IR场景中是非常不受欢迎的。

---

早期终止技术在结果质量的假设上也存在差异。我们可以区分返回与基线完全相同的前$k$结果的安全（或可靠）早期终止技术[30,20]，返回大部分相同结果的技术，以及仅返回由适当IR度量确定的同等质量结果的技术。我们专注于析取查询的安全早期终止，其中最相关的先前技术是Strohman和Croft的方法[30]以及Broder等人在[11]中提出的WAND方法。

---

IR查询处理中的另外两个最新想法也与我们的工作相关。首先，最近的几篇论文展示了如何通过优化文档ID的分配来减少倒排索引大小和查询处理成本[26, 9]。直观地说，如果我们为非常相似的页面分配连续的docID，例如通过URL排序[28]或文本相似性聚类，我们可以获得小docID间隔的运行，从而使用适当的技术实现更好的索引压缩。此外，如[35]所示，重新排序显著提高了合取查询的速度。我们的工作表明，重新排序对析取查询的帮助甚至更大，这让我们感到有些意外。

---

第二个相关想法是[1]中提出的两级索引。其思想是通过相似性对文档进行聚类，然后在第一级仅索引聚类（即聚类是否包含术语），而第二级说明聚类中哪些文档实际包含该术语。因此，第一级基本上近似整体索引，类似于我们使用每个块中的最大影响分数来近似列表中影响分数的分布。

---

最后，我们注意到，最近并且独立于我们的工作，Kaushik等人[15]提出了一种与本文中的块最大索引非常相似的索引结构，该结构也存储块的最大影响信息。他们的析取查询算法首先执行预处理，将块拆分为具有对齐边界的区间，并丢弃不能包含任何顶部结果的区间。然后对剩余区间应用maxScore技术[32]的版本。虽然他们的算法与我们的算法不同，但它们都基于相似的底层思想实现了显著的性能改进。

## 5. 块最大WAND算法

在本节中，我们介绍了我们的基本算法——**块最大WAND（Block-Max WAND, BMW）**，它是WAND算法在块最大索引上的扩展。

### 5.1 基本思想

如第2节所述，在“枢轴”阶段天真地使用每个块的最大影响分数是行不通的，因此我们需要添加一些额外的想法。在传统的逐文档（DAAT）查询处理中，一个核心函数称为$\operatorname{Next}(d, l i s t(i))$或$\operatorname{NextGEQ}(d, l i s t(i))$[11]；该函数接收一个docID $d$和一个倒排列表$l i s t(i)$作为输入，并返回$l i s t(i)$中当前docID之后第一个等于或大于$d$的docID。调用此特定函数通常涉及解压缩$l i s t(i)$中的一个块。我们称之为**深度指针移动**，因为它通常涉及块解压缩。由于我们拥有每个块的最大分数，我们设计了另一个函数$\operatorname{NextShallow}(d, l i s t(i))$，它仅将当前指针移动到相应的块而不进行解压缩（使用$d$和表中关于块边界的信息）。我们称之为**浅层指针移动**。我们在改进的算法中使用了两个主要思想：（i）我们使用全局最大分数来确定候选枢轴，如WAND中那样，但随后使用块最大分数来检查候选枢轴是否是一个真正的枢轴；（ii）我们尽可能使用浅层指针移动而不是深度指针移动。

### 5.2 算法

详细算法如算法1所示，我们称之为**块最大WAND（BMW）**。请注意，在BMW中，我们仍然像WAND一样保留整个列表的最大分数。

---

如算法1所示，与WAND的主要区别在于，在评估一个docID之前，我们将首先移动浅层指针，根据块的最大分数检查是否确实需要评估此docID。通过这样做，我们过滤掉了大多数候选文档，从而实现了更快的查询处理。此外，当检查失败时，我们可以使用$\operatorname{GetNewCandidate}()$进一步跳过，稍后将详细描述。

---

算法1中使用的两个函数$\operatorname{NextShallow}()$和$\operatorname{CheckBlockMax}()$分别在算法2和算法3中列出。它们的逻辑在上下文中相当明显。在$\operatorname{EvaluatePartial}()$中，我们通过累加从$l i s t[0]$到$l i s t[pivot +1]$的分数来评估文档。一旦我们发现文档无法进入前几名结果，我们就停止评估。

---

另一个重要的改进发生在$\operatorname{CheckBlockMax}()$返回false时，这意味着当前文档$d$无法进入前几名结果。我们不会选择其中一个列表（通常是具有最大IDF的列表）并将其移动到至少$d+1$，而是使用$\operatorname{GetNewCandidate}()$返回的$d^{\prime}$。原因是，由于当前文档基于块最大值被排除，我们应该至少跳过当前块之一的末尾。$\operatorname{GetNewCandidate}()$背后的思想如图5所示。假设docID 266是枢轴；当它未能通过$\operatorname{CheckBlockMax}()$检查时，我们不会将前三个列表之一移动到$266+1$，而是将其移动到$d^{\prime}=\min (d 1, d 2, d 3, d 4)$，其中$d 1, d 2, d 3$是前三个列表的块边界加一，$d 4$是第四个列表中的当前docID（在本例中为1807）。通过这样做，与使用$d+1$相比，跳过的效率大大提高，同时仍然保证安全的结果。证明应该是显而易见的。

- **图5**：展示$\operatorname{GetNewCandidate}()$工作原理的示例。假设266是枢轴，但它未能进入前几名结果。在这种情况下，我们通过选择$\min (d 1, d 2, d 3, d 4)$作为下一个可能的候选文档，而不是$266+1$，从而实现更好的跳过。

## 6. 实验

在本节中，我们提供了第一组实验结果。

### 6.1 实验设置

我们在TREC GOV2集合上评估我们的方法。GOV2集合包含从.gov互联网域名抓取的2520万个网页。这些网页的未压缩大小为426 GB。我们使用[35]中描述的PForDelta的NewPFD版本压缩倒排索引，每个块包含64个docID和频率（我们还尝试了其他块大小，但此块大小效果最佳）。压缩后的索引占用8759 MB，块最大索引的额外信息（每个块的最大分数）增加了约400 MB（尽管每个分数使用32位，但可以减少）。

---

我们从TREC 2006 Efficiency查询中随机选取1000个查询，并从TREC 2005 Efficiency查询中随机选取1000个查询作为我们的测试集。使用2006年和2005年集合的每个查询的平均条目数分别为4.67 M和6.07 M。我们使用BM25作为我们的排序函数。在所有运行中，我们将倒排索引完全加载到主内存中。除非另有说明，我们返回前10个结果。运行在2.27 GHz Intel(R) Xeon CPU的单核上进行。所有代码可通过联系第一作者获取。

### 6.2 结果

在本节中，我们将我们的算法BMW与穷举OR（使用DAAT）、WAND和SC在析取查询上进行比较。我们通过三个标准衡量性能——时间（每个查询的平均时间，单位为ms）、每个查询解码的整数数量以及每个查询评估的docID数量（完全针对所有查询术语评分的docID）。这些标准也在之前的工作中使用[30, 11]。

---

我们基于http://repo.or.cz/w/galago.git上提供的代码重新实现了SC算法，使用BM25作为排序函数。原始SC有四个阶段——OR、AND、Refine和Ignore。在本文中，我们专注于获得安全结果；因此，在我们的实现中没有Ignore阶段（因为我们需要确切的分数）。大部分时间花在$O R$阶段，因此这不会显著改变查询处理时间。

---

我们将每个列表划分为8个大小相等的层。请注意，在[30]中的原始SC算法中，使用了一种不同的排序函数，该函数只有8个不同的影响分数，每个层处理一个分数，因此层的大小不同。我们还尝试了不同组合的可变大小层。我们发现，大小相等的层通常至少与其他启发式方法表现相当，尽管原则上仍有改进空间。我们的解释是，在SC中，存在一个“切换点”，在此点我们保证至少在一个列表中遇到了所有正确的前$k$结果的docID。此时，我们可以在开始下一层之前从OR模式（TAAT）切换到AND模式。SC中的大部分计算时间花在OR模式中，之后速度会显著加快。虽然这个“切换点”取决于我们如何将列表划分为层，但切换点不能在Fagin的著名TA算法中满足阈值条件之前发生。最佳划分将在满足查询的阈值条件后立即进行切割，但由于这取决于查询，一个不错的选择是均匀分布切割，使得下一个切割不会太远。

---

我们还尝试了不同数量的层。图6显示了SC在不同数量层下的性能，证明了使用8层的合理性。

---

表1显示了使用不同算法的查询处理时间。本文中的所有运行都排除了单术语查询，并且没有删除停用词（改变这些假设将导致更好的时间）。我们观察到，对于TREC 2006，删除单术语查询的影响较小，而对于TREC 2005，差异显著，因为日志中有许多此类查询。（但请注意，在真实搜索引擎中，大多数单术语查询通过结果缓存解决。）

- **表1**：在TREC 2006和2005查询日志上使用不同算法的不同查询术语数量的平均查询处理时间（单位为ms）。穷举OR、WAND、SC和BMW用于析取查询，而穷举AND用于合取查询。

---

从表1中可以看出，我们的$B M W$算法提高了查询处理性能。这主要是由于DAAT索引遍历优于TAAT以及大量的跳过。此外，我们的SC实现不如[30]中报告的数字快，尤其是在TREC 2005查询日志上。这是因为我们删除了单术语查询但没有像[30]那样删除停用词，并且由于我们使用BM25作为排序函数。尽管如此，SC仍然优于基本的WAND，正如之前的工作中所报告的那样。总体而言，我们的基本$B M W$算法实现了更快的查询处理，但仍然比使用标准DAAT的穷举$A N D$慢得多。

---

表2显示了在TREC 2006查询日志上不同方法的另外两个标准（由于空间限制，我们省略了2005年的数据）。我们还包括了深度指针移动和浅层指针移动的次数。由于这些度量仅对DAAT索引遍历有意义，我们忽略了使用TAAT遍历的SC的数字。请注意，我们没有包括SC在评估docID方面的数字，主要是因为SC采用类似TAAT的查询处理，评估docID的定义会误导。此外，在BMW中，每次部分评估都被计为一个评估的docID，无论它是否提前停止。

- **表2**：在TREC 2006查询日志上不同方法的平均评估docID数量、解码整数数量、深度指针移动（dpm）和浅层指针移动（spm）。穷举OR、WAND、SC和BMW用于析取查询，而穷举AND用于合取查询。

---

从表2中，我们看到所有技术都比穷举OR有显著改进。与穷举OR相比，WAND仅评估了$4.6 \%$的docID，这与[11]中的数字大致匹配。BMW评估的docID更少。这意味着当我们有一个比BM25更昂贵的评分函数时，如[11]中提到的函数，BMW应该表现得更好。另一个有趣的点是，与最快的方法BMW相比，SC解码的整数更少，这意味着将有希望的docID分配到第一层确实有很大帮助。然而，SC使用额外的数据结构来临时存储候选文档，这是SC和许多其他基于TAAT的技术的主要缺点。

### 6.3 文档ID重新分配

在本节中，我们展示了文档ID重新分配后的结果。文档ID重新分配的思想是为文档分配docID，以便相似的页面具有接近的ID。这一思想在$[28,35,18]$中被广泛探讨，并且已经证明，在重新分配后，穷举AND下的压缩索引大小和查询处理速度都得到了显著改善。

---

一个自然的问题是，重新分配是否也有助于析取查询的处理速度。对于穷举OR，直觉上改进应该很小，因为无论如何分配docID，我们都会完全评估所有列表中的文档。对于SC，改进也应该适中，因为在SC中，我们将分配条目，使得具有较高影响分数的条目出现在列表的前面。然而，对于WAND和BMW，docID的重新分配可能会带来一些好处，因为每个块内的影响值分布应该变得更加均匀，从而帮助WAND和BMW。

---

表3显示了在docID重新分配后不同技术的查询处理时间。特别是，我们根据[28, 35]中使用的字母顺序分配docID。从表中可以看出，WAND的查询处理性能得到了显著改善，尤其是BMW。事实上，析取查询和合取查询之间的差距显著缩小。这意味着重新分配成功地使块内的分数更加平滑，从而改善了跳过。

- **表3**：在TREC 2006和2005查询日志上，docID重新分配后不同查询术语数量的平均查询处理时间（单位为ms）。

---

穷举OR的查询处理性能也有所改善。这主要是因为重新分配减少了倒排索引的压缩大小，从而减少了主内存访问的成本；参见[14]对此问题的更多讨论。

---

表4显示了在TREC 2006查询日志上，docID重新分配后评估的docID数量和解码整数数量的相应结果。我们观察到与查询处理时间相似的趋势，WAND和BMW的数值显著减少。

- **表4**：在TREC 2006查询日志上，docID重新分配后不同方法的平均评估docID数量、平均解码整数数量、深度指针移动（dpm）和浅层指针移动（spm）。

## 7. 扩展

在本节中，我们介绍了BMW算法的一些扩展。

### 7.1 分层版本的BMW

如前一节所示，BMW在析取查询中实现了最佳的查询处理性能，并显著缩小了析取查询与合取查询之间的性能差距。BMW的主要优势似乎在于它使用DAAT索引遍历，因此不必使用昂贵的数据结构来跟踪有希望的候选文档。

---

另一方面，SC通过使用影响分层索引并将最有希望的文档分配到第一层，实现了相当好的早期终止性能（注意，从上一节中可以看出，SC实际上解码的整数比其他算法更少）。这意味着SC的直觉，即将高评分文档放在列表的前面以提前停止，确实有很多优点。一个自然的问题是，我们是否可以将分层索引的思想与我们的BMW算法及其DAAT遍历机制结合起来。我们现在展示如何做到这一点。我们的基本算法非常简单：对于每个倒排列表，我们将其分成N层。然后我们将每一层视为一个单独的术语。在这种情况下，我们直接在影响分层索引上应用BMW算法。

---

这一想法背后的直觉是，在我们从每个列表中挑选出高评分文档后，剩余docID的分数变得更加平滑。因此，当我们存储每个块的最大影响分数时，这个分数不太可能比块中的其他分数大得多。不难理解，这种尖峰值对BMW是不利的：如果两个尖峰值位于两个不同的块中，我们可能必须解码这两个块，但如果它们位于一个块中，我们可能只需要解码和访问那个块。我们称新算法为$N$层$B M W$，其中N是层数。这样做的缺点是，每个查询的术语数量会增加。为了最小化这一缺点，我们只将每个列表分成2层，一个高级层和一个普通层，并且每个列表只有在有超过$\alpha$个条目时才进行分割。我们将每个列表中评分最高的$\beta$个条目放入高级层。经过一些实验，我们设置$\alpha=50 K$和$\beta=2 \%$，这似乎效果很好（获得最佳参数的工作留待未来进行）。

---

因此，在我们的2层$B M W$中，我们只是将来自同一列表的层视为单独的列表，并且同一列表中的不同层不知道彼此的存在。我们还设计了一个版本，其中来自同一列表的层知道彼此的存在。观察到一个文档ID只能存在于同一列表的一个层中（如果有的话）。在这种情况下，在BMW算法的“枢轴”阶段，我们可以通过选择来自同一列表的层的最大分数（而不是分数的总和）来做得更好。我们实验了这一想法，发现它适度减少了指针移动和解码的整数，但由于在枢轴期间跟踪属于同一术语的层的开销，实际运行时间并没有减少。由于篇幅原因，我们省略了这些实验的结果，尽管未来的工作可能会基于这一想法产生更多实用的变体。

---

表5显示了在docID重新分配前后，2层$B M W$的查询处理性能。正如我们所看到的，2层$B M W$在基本BMW的基础上获得了改进的运行时间。我们还在表6中显示了不同术语数量查询的查询处理时间。

- **表5**：在TREC 2006查询日志上，结合分层索引和BMW后，docID重新分配前后的查询处理性能。所有数字均为每查询的平均值。
- **表6**：在TREC 2006查询日志上，docID重新分配前后，BMW和2层BMW的不同术语数量查询的平均查询处理时间（单位为ms）。

### 7.2 增加Top-k

如前所述，当前网页搜索引擎中常用的一种排序技术基于两阶段方法，我们首先根据简单的排序函数（如BM25）获取前1000个文档，然后仅对这些1000个文档根据更复杂的排序函数计算确切分数。[34]中提供了一个使用BM25和位置信息的排序函数的示例。当然，在这些场景中，我们通常需要比$k=10$大得多的$k$值，例如几百或几千个结果。

---

在图7中，我们展示了在增加$k$值并重新分配docID后的性能。我们发现，朴素穷举$O R$算法的性能相当稳定，因为它无论如何都会解码和评估所有条目。对于其他算法，查询处理时间增加。对于SC，我们观察到性能大幅下降。这主要是因为随着存储更多候选文档，临时数据结构的性能越来越差。我们还看到，即使$k$等于1000，$B M W$和2层$B M W$也表现得相当好，并且时间的增加相当适度。

- **图7**：在TREC 2006查询日志上，docID重新分配后不同技术的查询处理时间。$X$轴是$k$的值，$Y$轴是平均处理时间。

### 7.3 块最大AND

BMW的一个优势是，该思想也可以应用于使用标准DAAT索引遍历的合取查询处理。对于合取查询处理，标准AND从最短的列表开始，然后尝试在较长的列表中找到相应的docID。将块最大索引结构集成并添加浅层指针到DAAT中以进行合取查询处理是一个自然的扩展。改进的DAAT算法如算法4所示；它被称为块最大AND（BMA）。

---

正如我们所看到的，我们只需要稍微调整标准AND算法即可获得BMA算法。特别是，我们使用了BMW中的三个例程——NextShallow()、CheckBlockMax()和GetNewCandidate()。BMA的处理成本如表7所示。我们观察到，BMA对于术语数量较少的查询效果更好（否则浅层指针移动将变得昂贵）。因此，我们还提出了一种混合算法：当查询中的术语数量小于$T$时应用BMA；否则使用穷举AND。在本文中，我们使用$T=4$。

- **表7**：在TREC 2006查询日志上，docID重新分配前后，使用穷举AND和BMA的不同术语数量查询的平均查询处理时间（单位为ms）。

---

表8显示了在docID重新分配前后，使用BMA和混合BMA的性能。我们可以看到与穷举AND相比的显著改进。请注意，$B M W$和$B M A$算法使用相同的索引结构；因此，块最大索引可以支持这两种类型的查询。

- **表8**：在TREC 2006查询日志上，docID重新分配前后，合取查询的平均查询处理时间（单位为ms）、每查询评估的docID数量和每查询平均解码整数数量。

## 8. 开放问题

本文的研究结果提出了几个有趣的开放问题。

**更简洁的算法与分析**：虽然所描述的方法已经取得了显著的改进，但我们并不确信已经找到了最优算法。提供一些分析，例如在我们的方法下指针移动和文档评估的最优次数，也会非常有趣。

---

**块最大索引的其他应用**：我们增强索引结构背后的基本思想也可以应用于其他场景。例如，尝试将局部最大分数集成到[1]中的两级索引结构中是很自然的。

---

**估计Top-k阈值**：如果我们能够以某种方式对进入前$k$结果所需的分数有一个良好的先验估计，我们的方法可以进一步改进。目前，我们从零阈值开始，然后在发现结果时更新该值。因此，算法开始时较慢，然后加速。这激发了以下算法问题，该问题在其他应用中也有用，例如在分布式信息检索中：给定一个倒排索引、一个查询和一个数字$k$，我们如何快速估计第$k$个最佳结果的分数（可能使用一些小的辅助结构），或者相反，给定一个阈值$t$，我们如何估计分数高于$t$的结果数量。

---

为了激发兴趣，我们在表9中展示了一个知道第$k$个最佳结果分数的“先知”算法，其查询处理成本大约减少了20%。

- **表9**：在TREC 2006查询日志上，BMW与“先知”BMW的前10个结果的平均查询处理时间（单位为ms）。

---

**使用分数近似的查询处理**：另一个更有趣的普遍问题是如何最好地近似倒排列表中的影响分数，以及如何在查询处理过程中最好地使用这些近似。考虑图3中的场景，我们有一个长的、稀疏的影响值数组，该数组被某些分块近似上界。对于给定的值数组，最好的近似是什么？是否应该有一个多级结构（类似于小波树），在我们下降到较低层级时，为逐渐变小的块大小提供上界？除了最大影响之外，是否有其他统计度量（例如值的偏度）是有用的？

## 9. 结论

在本文中，我们描述并评估了针对析取查询的改进的安全早期终止技术。这是通过一种称为块最大索引的增强索引结构实现的，该结构存储了条目块的最大影响分数。然后，我们展示了如何将这种结构集成到WAND方法中。最后，我们将其扩展到影响分层索引、重新分配docID的索引和合取查询，从而带来了额外的改进。我们的研究结果也为未来的研究提供了许多有趣的机会，如第8节所述。

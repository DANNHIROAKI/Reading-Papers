## 7 实验评估

在本节中，我们评估所提出技术的性能。实验结果验证了我们的方法在多个知名的真实数据集上优于五种当前最新的先进方法。

##### **数据集和查询工作负载**

我们在八个广泛用于近似最近邻（ANN）搜索的真实数据集上进行实验 $[16,17,32,36,53]$。这些数据集涵盖多种应用领域，包括：

- 图像数据集（SIFT [3]、BIGANN [3]、DEEP [32]、DEEP1B [57] 和 GIST [3]）
- 文本数据集（GLOVE [24] 和 CRAWL [5]）
- 音频数据集（MSONG [4]）

表 1 总结了这些数据集的一些特征，包括维度（dimensionality）、数据点数量（# base）、局部内在维度（LID） [1] 和数据类型。

我们观察到这些数据集的 LID 较低。DEEP1B 和 BIGANN 用于实验中与数据集规模相关的评测。

参考文献 [17, 32, 53]，我们还使用了两个合成数据集 RAND 和 GAUSS。

- **RAND**：从超立方体 $[0,1]^{100}$ 中均匀采样生成。
- **GAUSS**：在超立方体 $[0,10]^{100}$ 中随机选择 10 个聚类中心，每个聚类沿各维度服从高斯分布。

真实数据集和合成数据集的查询工作负载分别从数据集本身采样而得。

---

##### **基线方法**

我们将所提出的方法与五种最新的先进方法进行比较：

- **NSG [17]** 和其扩展版本 **NSSG [16]**：最新的基于 RNG（相对邻近图）的方法。
- **HNSW [16]**：最新的基于 NSWG（导航小世界图）的方法。
- **DPG [32]**：最新的基于 kNNG（k 近邻图）的方法。
- **FANNG [20]**：也是基于 RNG 的方法，但目前唯一考虑 $\delta(q, \bar{v})<\tau$ 的方法。

NSG、NSSG、DPG 和 HNSW 的源代码来自在线资源。由于 FANNG 的源代码未发布，我们自行实现了 FANNG。$\tau$-MNG 的代码基于 NSG 的代码进行构建。

---

##### **评测指标**  

评测指标遵循以往研究 [16, 17, 20, 36, 42, 53]：  

1. **搜索准确率**  
   - **Recall@k**（召回率）：衡量搜索结果的准确性。对于查询 $q$，其定义为  

   $$
   \text{recall@}k = \frac{|kANNs \cap kNNs|}{k}
   $$

   其中 $kANNs$ 表示近似 $k$-NN 集合，$kNNs$ 表示真实 $k$-NN 集合。  

   - **相对距离误差 ($rderr$)**：计算近似结果与真实结果的距离误差：  

   $$
   rderr = avg_{i=0}^{k-1}\left(\frac{\delta\left(q, i^{th} ANN\right)}{\delta\left(q, i^{th} NN\right)} - 1\right)
   $$

   其中 $i^{th} ANN$ 和 $i^{th} NN$ 分别表示 $q$ 的第 $i$ 个近似最近邻和真实最近邻。  

   我们报告所有查询的平均 recall@k 和 $rderr$。  

2. **搜索效率**  
   - **QPS（每秒查询数）**：每秒完成的查询数量。  
   - **NDC（距离计算次数）**：评估查询时所需的距离计算次数。  

   实验主要关注高召回率区域的搜索性能。

---

**实验设置**  

实验使用 C++ 在配备四核 AMD Opteron CPU 和 800G 内存的服务器上进行，代码通过 g++ 8.5 编译。

参考文献 [17, 32, 53]，我们使用单线程评估算法性能。

波束大小 $b$ 越大，召回率越高，但查询延迟也越高。参考近期工作 [31,32,53]，我们逐步增加 $b$ 直到达到目标召回率。

实验关注 $k=100$ 的性能表现。

### 7.1 与基线方法的比较

在本实验中，我们将提出的方法与五种基线方法在六个数据集上进行了比较。为了确保公平性，我们将优化技术 QEO 以及两个实现细节 PDP 和 PII 集成到所有基线方法中。结果如图 5 所示。

------

从图 5 中可以观察到，$\tau$-MNG 的性能优于所有基线方法。具体表现如下：

- 在 **DEEP** 数据集上，当 recall@100 为 $0.95$ 时，$\tau$-MNG 的速度比基线方法快约 $1.1$ 到 $1.6$ 倍；当 $rderr$ 为 $0.001$ 时，速度快约 $1.7$ 到 $5.2$ 倍。
- 在 **SIFT** 数据集上，当 recall@100 为 $0.95$ 时，$\tau$-MNG 的速度快约 $1.2$ 到 $2.1$ 倍；当 $rderr$ 为 $0.001$ 时，速度快约 $1.2$ 到 $2.0$ 倍。
- 在 **MSONG** 数据集上，当 recall@100 为 $0.95$ 时，$\tau$-MNG 的速度快约 $1.1$ 到 $1.6$ 倍；当 $rderr$ 为 $0.001$ 时，速度快约 $1.2$ 到 $1.8$ 倍。
- 在 **GIST** 数据集上，当 recall@100 为 $0.95$ 时，$\tau$-MNG 的速度快约 $1.1$ 到 $1.5$ 倍；当 $rderr$ 为 $0.001$ 时，速度快约 $1.2$ 到 $1.7$ 倍。
- 在 **CRAWL** 数据集上，当 recall@100 为 $0.95$ 时，$\tau$-MNG 的速度快约 $1.2$ 到 $2.0$ 倍；当 $rderr$ 为 $0.001$ 时，速度快约 $1.3$ 到 $3.3$ 倍。
- 在 **GLOVE** 数据集上，当 recall@100 为 $0.95$ 时，$\tau$-MNG 的速度快约 $1.2$ 到 $4.1$ 倍；当 $rderr$ 为 $0.001$ 时，速度快约 $1.4$ 到 $5.1$ 倍。

### 7.2 $\tau$ 的影响

在本实验中，我们通过调整 $\tau$ 的值来研究 $\tau$-MNG 的性能表现。为了清晰地观察 $\tau$ 的影响，本实验未使用 QEO、PDP 和 PII 优化技术。

图 6 展示了在六个真实数据集上的实验结果。从图 6 中可以观察到，随着 $\tau$ 的增大，$\tau$-MNG 的性能先提升后下降。这是因为搜索成本主要由搜索过程中的 NDC（距离计算次数）主导，而期望的 NDC 由搜索步数的期望值与 PG 的期望节点度的乘积决定。

- **当 $\tau$ 增大时：**
  $\tau$-MNG 的节点度增加，连接性更好，搜索过程的绕行减少，从而降低 NDC。
- **当 $\tau$ 进一步增大时：**
  节点度变得过大，导致每一步搜索需要计算更多邻居的距离，从而增加 NDC。

由于 NDC 与 $rderr$ 的结果与 QPS 与 recall 的结果一致，后续实验仅展示 QPS 与 recall 的结果，以节省空间。

---

##### **在合成数据集上的实验**

我们进一步在不同点密度和标准偏差（SD）的合成数据集 GAUSS 和 RAND 上进行实验，以研究 $\tau$-MNG 的行为表现。实验结果如图 7 所示：

- 图 7(a)-(c)：GAUSS 数据集的 SD 固定为 5。
- 图 7(d)：调整 SD 值以分析其影响。

---

**从图 7(a)-(c) 可观察到以下结果：**

1. **GAUSS 比 RAND 搜索速度更快。**
   - 这是因为 RAND 的搜索步骤比 GAUSS 多。例如，在 10K 点数据集中，为了达到 recall@100 = 0.95，RAND 上 $0$-MNG 的搜索步数约为 400，而 GAUSS 上 $0$-MNG 的搜索步数约为 90。
2. **$\tau$ 的影响在 GAUSS 上比 RAND 更明显。**
   - 原因在于 RAND 中 $q$ 的 $k$-NN 之间的边更容易被遮挡（occluded），而 GAUSS 中的边不易被遮挡。
   - 因此，随着 $\tau$ 的增加，GAUSS 的搜索步数下降速度比 RAND 更快。例如，在 10K 点数据集中，为了达到 recall@100 = 0.95，RAND 上 $0.2$-MNG 的搜索步数约为 300，而 GAUSS 上 $8$-MNG 的搜索步数约为 50。
3. **导致 $\tau$-MNG 性能趋势从提升转向下降的 $\tau$ 值随着点密度增加而减小。**
   - 原因是，在密集数据集中，随着 $\tau$ 增加，$\tau$-MNG 节点度增长的速度快于搜索步数减少的速度。

---

**图 7(d)：标准偏差（SD）对性能的影响**

图 7(d) 展示了 GAUSS 数据集上 $\tau$-MNG 在不同 SD 值下的加速比（spd）。spd 定义为：
$$
\text{spd} = \frac{\text{QPS of } \tau\text{-MNG}}{\text{QPS of } 0\text{-MNG}}
$$
在 recall@100 = 0.95 时，我们可以观察到：

1. $\tau$-MNG 的性能在每个 SD 值下均表现出先提升后下降的趋势。
2. 导致趋势从提升转向下降的 $\tau$ 值随着 SD 的增大先增加后减小。

**原因分析：**
随着 SD 增大，$\tau$-MNG 的边长（edge length）先增加后减小。例如：

- GAUSS 数据集中，0-MNG 的平均边长在 SD 分别为 3、5、7 和 10 时约为 36、59、82 和 12。

因此，$\tau$-MNG 的性能变化与边长的变化密切相关。

### 7.3 QEO 的性能

在本实验中，我们通过调整 $p$ 的值来研究查询感知边遮挡 (QEO) 的性能。$p^{\prime} %$ 和 $z$ 分别设置为 2 和 $m / 2$。为了专注于 QEO，本实验未使用基于部分距离的剪枝 (PDP) 和前缀内积索引 (PII) 技术。

图 8 展示了六个数据集上的实验结果。

---

从图 8 可以观察到：

- 当 $p$ 减小时，搜索性能先提升后下降（如图 8(b) 和 8(d)-8(f)）或保持稳定（如图 8(a) 和 8(c)）。

**原因分析：**

- 当 $p$ 减小时，每一步搜索会遮挡更多不重要的邻居，从而减少 NDC（距离计算次数）。
- 但如果 $p$ 继续减小，更多有潜力的邻居也会被遮挡，导致搜索过程中需要绕行更多，从而增加 NDC。

### 7.4 PDP 和 PII 的性能

本实验评估了第 6.2.2 节讨论的 PDP 和 PII 技术的性能。由于空间限制，我们仅在图 9 中展示了 SIFT 数据集的结果，其他数据集的趋势类似。

从图 9 可以观察到：

1. **PDP 提升了搜索效率。**
   - 在每一步搜索中，优先队列中的第 $(b-1)$ 个节点可以对当前节点的许多邻居进行剪枝，而无需完全计算它们与 $q$ 的距离。
   - 特别是，当召回率为 0.95 时，$\tau$-MNG + QEO + PDP 的 QPS（每秒查询数）比 $\tau$-MNG + QEO 高出 1.2 倍。
2. **PII 显著提高了搜索吞吐量。**
   - 特别是，当召回率为 0.95 时，$\tau$-MNG + QEO + PDP + PII 的 QPS 比 $\tau$-MNG + QEO 高出 2.1 倍。

### 7.5 索引大小的比较

本实验考察了索引大小，结果如图 10 所示。

从图 10 可以观察到：

1. 使用或不使用 PII 的 $\tau$-MNG 索引大小仅比 NSG、NSSG 和 HNSW 略大，这三者是图 5 中比较的前 3 种基线方法。
2. $\tau$-MNG 的索引大小远小于 FANNG，尤其是在 CRAWL、DEEP 和 GLOVE 数据集上。

**结论：**
$\tau$-MNG 可以轻松存储在主内存中。

### 7.6 数据集规模对性能的影响

在本实验中，我们评估了 $\tau$-MNG 在数据集规模变化下的性能表现，实验基于 DEEP1B 和 BIGANN 数据集。参考文献 $[16,17,43,53]$ 中支持大规模数据集的方法，我们将数据点随机划分为每部分 1000 万个点，并为每个部分构建一个 $\tau$-MNG。

在每个部分执行 $k$-ANN 搜索，并将所有部分的结果合并，取前 $k$ 个作为最终结果。

图 11 展示了实验结果：

- 横坐标表示数据集规模，纵坐标表示每个查询的平均运行时间。

**观察结果：**

- $\tau$-MNG 的查询时间随数据集规模线性增长。
- 从图 11 中还可以观察到，召回率 0.90 和 0.95 的运行时间差距小于召回率 0.95 和 0.98 的差距。

这与之前实验的观察结果一致，即运行时间的增长速度超过召回率增长的线性关系。

## 8 结论

本文提出了一种用于多维数据库中近似最近邻（ANN）搜索的 $\tau$-单调图（$\tau$-MG）。

#### **核心贡献：**

1. **新颖的边遮挡规则：**
   - 当查询点 $q$ 到数据库中最近邻的距离小于常数 $\tau$ 时，基于贪婪路由的 $\tau$-MG 能够保证找到 $q$ 的精确最近邻。
   - 搜索的期望时间复杂度小于所有现有方法。
2. **理论分析：**
   - 严格分析了 $\tau$-MG 中贪婪路由的期望长度和 $\tau$-MG 的期望节点度。这些分析细节提供在补充材料中。
3. **高效索引构建：**
   - 提出了一种 $\tau$-单调邻居图（$\tau$-MNG），它是 $\tau$-MG 的近似变体，用于提高索引构建效率。
4. **优化搜索计算：**
   - 提出了一种优化方法，减少 $\tau$-MNG 搜索中的距离计算次数。

#### **实验结果：**

通过广泛的实验验证，本文提出的方法在真实基准数据集上表现优异，性能优于当前最先进的 ANN 搜索方法。

#### **未来工作：** 

未来，我们计划将分布式和外存 ANN 搜索方法整合到提出的技术框架中，以进一步提升处理更大规模数据集的能力。




## 3 PRELIMINARIES

In this section, we first present the problem setting and then present the proximity graph.

### 3.1 Problem setting

In this paper, we use $E^{m}$ to denote the $m$-dimensional Euclidean space. The $L_{2}$ norm $\delta(u, v)$ of two points $u$ and $v$ is used to measure the distance between $u$ and $v$. The approximate nearest neighbor (ANN) search is defined as follows.

ANN search problem. Given a database $D$ with $n$ data points in $E^{m}$, a query point $q$ in $E^{m}$, and a small constant $\epsilon \geq 0$, we aim to efficiently find a point $p$ in $D$ such that $\delta(p, q) \leq(1+\epsilon) \delta(\bar{v}, q)$, where $\bar{v}$ is the nearest neighbor of $q$ in $D$.

For the convenience of modeling and evaluation, the exact value of $\epsilon$ is usually not used directly, and instead, other measures are used to measure search accuracy [16, 17, 31, 36, 43, 53]. The widely used accuracy measures for ANN search include the rank-based measures [16, 17, 53] and the distance-based measures [32, 42]. The ANN search problem can be naturally generalized to the approximate $k$-nearest neighbor ( $k$-ANN) search problem [16, 17].

In this paper, we use $\operatorname{ball}(u, r)$ to denote an open ball centered at $u$ with radius $r$. We use $\operatorname{ball}(r)$ if the ball center is not interested. We use lune $(u, v)$ to denote the intersection of two balls $\operatorname{ball}(u, \delta(u, v))$ and $\operatorname{ball}(v, \delta(u, v))$.

### 3.2 Proximity graph

A proximity graph (PG) of a database $D$ is a directed graph $G$, where the nodes in $G$ are the points in $D$ and two nodes have an edge if they satisfy some proximity property. For a node $u$ of $G$, we use $N_{G}(u)$ to denote the set of outgoing neighbors of $u$ in $G$ and $N_{G}^{-}(u)$ to denote the nodes in $G$ but not in $N_{G}(u)$. A path $P=\left[u_{0}, u_{1}, \ldots, u_{|P|-1}\right]$ in a PG is a monotonic path for a query $q$ if each step gets closer to $q$, i.e., $\delta\left(u_{i}, q\right)<\delta\left(u_{i-1}, q\right)$, for $i=1, \ldots,|P|-1$.

---

Algorithm 1 presents the search algorithm on a PG, which is a beam search and widely used in existing works (e.g., $[16,17,32,35,45,51,53,59]$ ). Greedy routing is a special case of Algorithm 1 when $b=1$. The larger the beam size, the higher the search accuracy but the slower the search. Algorithm 1 can be easily extended to support $k$-ANN search by setting $b \geq k$ and returning the top- $k$ best nodes in $W$ in Line 13.

#### 3.2.1 Monotonic relative neighborhood graph.

The monotonic relative neighborhood graph (MRNG) [17] is a well-known PG. The core of MRNG is a rule of using shorter edges to occlude longer edges, defined as follows. (This edge occlusion rule is also used in other PG-based methods including NSSG [16], HNSW [36], and FANNG [20].)

Definition 1. (Edge occlusion rule of MRNG) Given three nodes $u, u^{\prime}$, and $v$ in $G$, if $\left(u, u^{\prime}\right) \in G$ and $u^{\prime} \in$ lune $(u, v)$, then $(u, v) \notin G$. Alternatively, we say ( $u, u^{\prime}$ ) occludes $(u, v)$.

Fig. 3(a) illustrates that the edge ( $u, u^{\prime}$ ) occludes the edge ( $u, v$ ). Based on the edge occlusion rule, MRNG is defined as follows.

---

Definition 2. (MRNG) Given a database $D$, a proximity graph $G$ is an MRNG if $G$ has an edge $\left(u, u^{\prime}\right)$ occluding the edge $(u, v)$ for any two nodes $u, v \in G$ satisfying $(u, v) \notin G$.

MRNG has a performance guarantee as follows.

Lemma 1. If $q \in D$, the greedy search on MRNG finds $q$ starting from any node. However, if $q \notin D$, the greedy search on MRNG may not find the nearest neighbor of $q$.

Fig. 3(b) shows an example where the greedy search on MRNG cannot find the NN of $q$. The edge $(u, v)$ is occluded by $\left(u, u^{\prime}\right)$. Suppose that $u$ is the current node of the greedy routing. Since $\delta(q, u)<\delta\left(q, u^{\prime}\right)$, the greedy routing will stop and return $u$. However, $v$ is the NN of $q$.

We remark that although MRNG is designed for the Euclidean space [17], MRNG can still be used in general metric spaces. However, the analysis of MRNG for time and space complexities in [17] does not hold in general metric spaces.

## 4 ANALYSIS OF THE INEFFICIENCY OF EXISTING PROXIMITY GRAPHS

In this section, we analyze the reason for the inefficiency of existing PGs. The time cost of ANN search on a PG is mainly determined by two factors: the routing length (i.e., the number of routing steps) and the node degree. We focus on the first factor in this section, as in many existing PGs, the node degree is bounded by a constant $[16,17,36] .{ }^{2}$

- ${ }^{2}$MRNG [17] and SSG [16] prove their max node degrees are constants. HNSW [36] bounds the node degree by a predefined constant.  

---

Fu et al. [17] analyze the expected length of the greedy routing in the monotonic search network (MSNET). However, the analysis of Fu et al. has two limitations. First, MSNET is a special PG, which requires that for each node $v$, the PG has a monotonic path from any node to $v$. Second, $q$ has to be a point in the database. In contrast, we analyze the expected length of the greedy routing in any PG and $q$ can be any point in $R^{m}$. Our result is more general than that of [17].

---

Theorem 1. Recall the same assumptions from [17] as below.

- Given a database D of n points, the points in D are uniformly distributed in a finite subspace of $E^{m}$ and $m$ is a constant.
- There exists a constant $\psi$, such that $\psi V_{D} \geq \operatorname{Vol}(\operatorname{ball}(R))$, where $V_{D}$ denotes the volume of the minimum convex hull containing $D, R$ denotes the maximum distance between two points in $D$, and $\operatorname{ball}(R)$ denotes a ball with radius $R$.

The point density $g$ can increase with the growth of $n$ and we assume that $g$ is $O(\ln n) .{ }^{3}$ We further assume that the query $q$ has the same distribution as the points in $D$.

---

For any PG G of D, the expected length of the greedy routing for $q$ is $O\left(\frac{1}{\Delta} n^{\frac{1}{m}} \ln n^{\frac{1}{m}}\right)$, where $\Delta$ denotes the smallest distance between any two points in $D$ and $\Delta \leq O\left((1 / n)^{1 / m}\right)$ with probability at least $1-\left(\frac{1}{e}\right)^{\frac{m}{4}\left(1-\frac{3}{e^{2}}\right)}$. Therefore, the expected length of the greedy routing is at least $O\left(n^{\frac{2}{m}} \ln n\right)$ with probability at least $1-\left(\frac{1}{e}\right)^{\frac{m}{4}}\left(1-\frac{3}{e^{2}}\right)$.

---

Proof Sketch. Let $\left[v_{0}, v_{1}, \ldots, v_{x}\right]$ be the path found by the greedy routing. First, we prove the expected length of the path $\mathbb{E}[x]=O\left(\frac{1}{\Delta} n^{\frac{1}{m}} \ln n^{\frac{1}{m}}\right)$, which follows the framework of [17]. Second, we prove $\Delta \leq O\left(\sqrt{m}(m / n)^{1 / m}\right)$ with probability at least $1-\left(\frac{1}{e}\right)^{\frac{m}{4}\left(1-\frac{3}{e^2}\right)}$. The main idea is to prove that the probability that two points are both in a hypercube with volume $O(\mathrm{~m} / \mathrm{n})$ is at least $1-\left(\frac{1}{e}\right)^{\frac{m}{4}\left(1-\frac{3}{e^{2}}\right)}$.

In Theorem 1, we can see that the routing is long on any existing PG. The reason is that each routing step gets closer to $q$ by only $\Delta$ and $\Delta \rightarrow 0$ when $n \rightarrow \infty$.

## 5. $\tau$-MONOTONIC GRAPH ( $\tau$-MG)

To address the limitation of exising PGs (cf. Section 4), this section proposes $\tau$-monotonic graph $(\tau-\mathrm{MG})$. If $\delta(q, \bar{v})<\tau$, each step of the greedy routing, except the last step, gets closer to $q$ by a constant $\tau$. Therefore, the expected length of the greedy routing is reduced to be $O\left(n^{\frac{1}{m}} \ln n\right)$. Moreover, if $\delta(q, \bar{v})<\tau$, the greedy routing on $\tau$-MG must find $\bar{v}$. $\tau$-MG is designed based on a more tighter edge occlusion rule as follows.

---

Definition 3. (Edge occlusion rule of $\tau$-MG) Given three nodes $u, u^{\prime}$, and $v$ in $G$, if $\left(u, u^{\prime}\right) \in G$ and $u^{\prime}$ is in the intersection of ball $(u, \delta(u, v))$ and ball $(v, \delta(u, v)-3 \tau)$, then $(u, v) \notin G$.

Fig. 3(c) illustrates that the edge occlusion rule of $\tau$-MG.

Definition 4. ( $\tau-\mathrm{MG}$ ) Given a constant $\tau \geq 0$, a $\tau$-monotonic graph ( $\tau-\mathrm{MG}$ ) is a directed proximity graph $G=(V, E)$, where for any two nodes $u$ and $v$,

- if $\delta(u, v) \leq 3 \tau,(u, v) \in G$; and
- if $\delta(u, v)>3 \tau$ and $(u, v) \notin G, G$ has an edge ( $u, u^{\prime}$ ) occluding the edge $(u, v)$.

We propose a new concept of $\tau$-monotonic path. A $\tau$-monotonic path ensures getting closer to $q$ by at least $\tau$ in each step except the last step.

Definition 5. ( $\tau$-monotonic path) A path $P=\left[v_{0}, v_{1}, \ldots, v_{x}, v_{x+1}\right]$ on a $P G G$ is a $\tau$-monotonic path for a query $q$ if $\delta\left(v_{i+1}, q\right)<\delta\left(v_{i}, q\right)-\tau$, for $i=0, \ldots, x-1$, and $\delta\left(v_{x+1}, q\right)<\delta\left(v_{x}, q\right)$.

Based on the $\tau$-monotonic path, we define the $\tau$-monotonic property as follows.

Definition 6. ( $\tau$-monotonic property) Given a database $D$ and a constant $\tau>0$, a PG G of $D$ is $\tau$-monotonic if for any query $q$ satisfying $\delta(q, \bar{v})<\tau, G$ has a $\tau$-monotonic path starting from any node in $G$ to the nearest neighbor $\bar{v}$ of $q$ in $D$.

Based on the edge occlusion rule (Definition 3), we can prove that if $\delta(q, \bar{v})<\tau, \tau$-MG must have a $\tau$-monotonic path starting from any node to $\bar{v}$. Therefore, we have the following lemma.

Lemma 2. $A \tau$-MG of $D$ is $\tau$-monotonic.

### 5.1 Construction of $\tau$-MG

The overall idea of $\tau$-MG construction is that we first construct an MRNG and then insert edges to the MRNG to obtain a $\tau$-MG. It is because that by the definitions of MRNG and $\tau$-MG, a $\tau$-MG is an MRNG but an MRNG may lack some edges to satisfy the definition of $\tau$-MG. From the example shown in Fig. 3(c), if $u$ has an outgoing neighbor $u^{\prime \prime}$ in the gray region, $\left(u, u^{\prime \prime}\right)$ can occlude $(u, v)$ in MRNG, whereas ( $u, u^{\prime \prime}$ ) cannot occlude ( $u, v$ ) in $\tau$-MG.

---

Algorithm 2 shows the construction algorithm of $\tau$-MG. Specifically, Line 1 constructs an MRNG. For each node $u$ in the MRNG, Lines 3-4 sort the list $L$ of the nodes that are not outgoing neighbors of $u$ in the ascending order of their distances to $u$. For the $i$-th node $v$ of $L$, Lines 6-10 check Definition 4 to decide whether $(u, v)$ needs to be inserted into the $\tau$-MG.

---

The node degree of $\tau$-MG is analyzed in the following lemma.

Lemma 3. Given a database $D$ ofn points in $E^{m}$ and a constant $\tau>0$, under the assumptions in Theorem 1, the expected node degree of the $\tau-\mathrm{MG} G$ constructed by Algorithm 2 is $O(\ln n)$ and the expected size of $G$ is $O(n \ln n)$.

Proof Sketch. The work [17] has proved that the expected node degree of MRNG is a constant. Hence, we only need to prove that the expected numbers of edges inserted by Line 8 and Line 10 for each node $u$ in $G_{0}$ are both $O(\ln n)$.

---

For Line 8 , since the $n$ points are uniformly distributed and the density is $g$, the number of edges inserted by Line 8 for $u$ is $\operatorname{Vol}(\operatorname{ball}(u, 3 \tau)) \times g$. Since $\tau$ is a constant and $g=O(\ln n)$, $\operatorname{Vol}(\operatorname{ball}(u, 3 \tau)) \times g$ is $O(\ln n)$.

For Line 10 , if Line 10 inserts an edge ( $u, v$ ), $u$ must have a neighbor $u^{\prime \prime}$ in $G_{0}$ s.t. $u^{\prime \prime}$ is in lune $(u, v) \backslash \operatorname{ball}(v, \delta(u, v)-3 \tau)$ (see the gray region in Fig. 3(c)). The probability of inserting ( $u, v$ ) is $\operatorname{Pr}(u, v)=\operatorname{Vol}(\operatorname{lune}(u, v) \backslash \operatorname{ball}(v, \delta(u, v)-3 \tau)) / \operatorname{Vol}(\operatorname{lune}(u, v))$ as the points are uniformly distributed. The expected number of edges inserted by Line 10 is $\sum_{v \in N_{G_{0}}^{-}(u)} \operatorname{Pr}(u, v)$. By applying arithmetic derivation and geometry theorems, we can derive $\left.\sum_{v \in N_{G_{0}}}^{-}(u) \operatorname{Pr}(u, v)\right)=O(\ln n)$.

---

The time complexity for $\tau$-MG construction is analyzed as below.

Lemma 4. Given a database $D$ of $n$ points, the time complexity for $\tau$-MG construction (Algorithm 2) is $O\left(n^{2} \ln n\right)$.

The time complexity of constructing $\tau$-MG is the same as that of MRNG, FANNG, and SSG.

### 5.2 ANN search on $\tau$-MG

In this subsection, we propose a new greedy routing algorithm on $\tau$-MG. The novelty is that each routing step can get closer to $q$ by at least $\tau$, except the last step, such that the expected routing length is $O\left(n^{\frac{1}{m}} \ln n\right)$.

---

The main idea of the greedy routing algorithm is that let $u$ be the current node of the routing. We first try to route to $u$ 's neighbors out of $\operatorname{ball}(u, 3 \tau)$. If all the neighbors out of $\operatorname{ball}(u, 3 \tau)$ are farther from $q$ than $u$, the routing stops and we scan $u$ 's neighbors in $\operatorname{ball}(u, 3 \tau)$ to find the search result. Algorithm 3 presents the detailed routing algorithm on $\tau$-MG. Importantly, the greedy routing is designed based on the following property of $\tau$-MG.

---

Lemma 5. Given a $\tau$-MG $G$ and a query q satisfying $\delta(q, \bar{v})<\tau$, let $u$ be any node in $G$, if all outgoing neighbors of $u$ out of ball $(u, 3 \tau)$ are farther from $q$ than $u$, then $\bar{v}$ is in $\operatorname{ball}(u, 3 \tau)$.

We analyze the length of the routing path on $\tau$-MG as follows.

Theorem 2. Given a database D of n points in $E^{m}$, under the same assumptions as in Theorem 1, for a query $q$ satisfing $\delta(q, \bar{v})<\tau$, where $\tau>0$ is a constant and $\bar{v}$ is the nearest neighbor of $q$ in $D$, the expected length of the routing of Algorithm 3 starting from any node of $G$ to $\bar{v}$ is $O\left(n^{\frac{1}{m}} \ln n\right)$ and the time complexity of Algorithm 3 is $O\left(n^{\frac{1}{m}}(\ln n)^{2}\right)$.

---

Proof Sketch. Let $\left[v_{0}, v_{1}, \ldots, v_{x}\right]$ be the path found by Algorithm 3. Since $\delta(q, \bar{v})<\tau$, we can prove $\mathbb{E}[x] \leq \frac{\mathbb{E}\left[\ln \delta\left(q, v_{x}\right)\right]-\ln (R+\tau)}{\ln R-\ln (R+\tau)}$, where $R$ is the largest distance between any two points in $D$. Since the points are uniformly distributed, we can prove $\frac{\mathbb{E}\left[\ln \delta\left(q, v_{v}\right)\right]-\ln (R+\tau)}{\ln R-\ln (R+\tau)} \leq O\left(\frac{-\ln (r(n)+\tau)}{\ln r(n)-\ln (r(n)+\tau)}\right)$, where $r(n)=\left(\frac{n}{C}\right)^{1 / m}$ and $C$ is a constant. Further, we prove that $\frac{-\ln (r(n)+\tau)}{\ln r(n)-\ln (r(n)+\tau)}$ has the same order of growth rate with $\frac{(r(n)+\tau) \ln (r(n)+\tau)}{\tau}$. Hence, $\mathbb{E}[x] \leq O\left(\frac{(r(n)+\tau) \ln (r(n)+\tau)}{\tau}\right)$. Since $\tau$ is a constant, $\mathbb{E}[x] \leq O\left(n^{\frac{1}{m}}(\ln n)\right)$. Because the expected node degree is $O(\ln n)$ as proved in Lemma 3, the time complexity of Algorithm 3 is $O\left(n^{\frac{1}{m}}(\ln n)^{2}\right)$.

### 5.3 Update of $\tau$-MG

To support updates, we need to reconstruct the $\tau$-MG $G$ periodically. To optimize update cost, we reconstruct $G$ after $O(\ln n)$ updates. Our idea is as follows.

If a node $u$ is inserted to $G$, we first compute the distances from $u$ to all nodes in $G$. Second, we compute the out-going neighbors of $u$ using Lines 3-11 of Algorithm 2. Third, we update the out-going neighbors of all nodes in $G$. Specifically, for each node $v$ in $G$, if no existing out-going edge of $v$ can occlude the edge $(v, u),(v, u)$ is inserted into $G$. The time complexity of insertion is $O(n \ln n)$.

---

If a node $u$ is deleted from $G$, we adopt the masking strategy [56] to preserve the connectivity of $G$. Specifically, $u$ is not deleted from $G$; $u$ can be used in routing; but $u$ is not returned as a query result. The time complexity of deletion is $O(1)$.

The graph $G$ after updates is still a $\tau$-MG by Definition 4. Therefore, Algorithm 3 can find $\bar{v}$ on the updated $G$ if $\delta(q, \bar{v})<\tau$. However, a node in the updated $G$ can have more than $O(\ln n)$ out-going neighbors. To retain the same space complexity of $\tau$-MG and time complexity for searching, we reconstruct $G$ after $O(\ln n)$ updates.

---

As a remark, we can still use $\tau$-MG to find the exact $\mathrm{NN} \bar{v}$ for a query $q$ in general metric spaces if the distance between $q$ and $\bar{v}$ is less than $\tau$. However, it is open whether the time and space complexities of $\tau$-MG proposed in this section hold under this setting.

## 6. $ \tau$-MONOTONIC NEIGHBORHOOD GRAPH ( $\tau$-MNG)

Since constructing a $\tau$-MG takes $O\left(n^{2} \ln n\right)$ time, this section proposes an approximation of $\tau$-MG, namely $\tau$-monotonic neighborhood graph ( $\tau$-MNG), such that $\tau$-MNG can be constructed efficiently and the search on $\tau$-MNG has a high probability of finding $\bar{v}$.

The main idea of $\tau$-MNG is that we only require the neighborhood of each node in a $\tau$-MNG to be $\tau$-monotonic, where the neighborhood of a node $u$ is the subgraph of $G$ induced by the near neighbors of $u$. It is motivated by the recent observation that most routing steps in a proximity graph $G$ are in the neighborhood of the nearest neighbor of $q$ [46,51]. $\tau$-MNG is defined as follows.

---

Definition 7. Given a database $D$ and a constant $\tau>0$, let $H_{v} \subset D$ denote the approximate $h$-nearest neighbors of a point $v \in D$, a $\tau$-monotonic neighborhood graph ( $\tau-\mathrm{MNG})$ is a directed graph $G=(V, E)$, where for any two nodes $v \in G$ and $u \in H_{v}$

- if $\delta(u, v) \leq 3 \tau,(u, v) \in G$; and
- if $\delta(u, v)>3 \tau$ and $(u, v) \notin G, G$ has an edge $\left(u, u^{\prime}\right), u^{\prime} \in H_{v}$, occluding the edge $(u, v)$.


### 6.1 Construction of $\tau$-MNG

Algorithm 4 presents the construction algorithm of $\tau$-MNG. Line 1 constructs a PG, e.g., NSG [17] and HNSW [36]. Then, for each node $u$, Lines $4-5$ find the list $H_{u}$ of the approximate $h$-NNs of $u$. Line 6 sorts the nodes in $H_{u}$ by their distances to $u$. Then, for each node $v$ in $H_{u}$, if $(u, v) \notin G$, we insert ( $u, v$ ) based on Definition 4. The time complexity of Algorithm 4 is analyzed in Lemma 6.

---

Lemma 6. Given a database $D$ of $n$ points in $E^{m}$, a constant $\tau>0$ and constants $h$ and $b$, under the assumptions in Theorem 1, the time complexity to construct a $\tau$-MNG by Algorithm 4 is $O\left(n^{\frac{2+m}{m}} \ln n\right)$ with probability at least $1-(1 / e)^{\frac{m}{4}\left(1-\frac{3}{e^{2}}\right)}$.

By comparing Lemma 6 with Lemma 4, we can see that the time complexity for $\tau$-MNG construction is much lower than that for $\tau$-MG construction.

### 6.2 ANN search on $\tau$-MNG

One may attempt to directly use Algorithm 3 on $\tau$-MNG for ANN search. However, $\tau$-MNG may not have a monotonic path from any node to $\bar{v}$. Therefore, Algorithm 3 on $\tau$-MNG may get stuck in local optima, which reduces search accuracy. To alleviate this problem, we adopt the widely used beam search Algorithm 1 to strike a balance between search accuracy and efficiency. In this subsection, we first analyze the theoretical performance of the beam search on $\tau$-MNG. Then, we propose three optimizations to address the performance bottlenecks of the beam search discovered in our experiments.

---

The accuracy of the result of the beam search depends on if the beam search enters the neighborhood $H_{\bar{v}}$ of $\bar{v}$. We call the beam search enters $H_{\bar{v}}$ if any node in $H_{\bar{v}}$ is added into the priority queue $W$ in Algorithm 1.

Lemma 7. Given a $\tau$-MNG $G$ of $D$ and a constant $\tau>0$, for a query $q$ satisfying $\delta(q, \bar{v})<\tau$, let $H_{\bar{u}}$ be the approximate $h-N N s$ of $q$ and $u$ be the node in $H_{\bar{v}}$ that is the farthest from $q$, if the beam size is larger than $h+h^{\prime}$, where $h$ is the neighborhood size and $h^{\prime}$ is the number of nodes in $G$ closer to $q$ than $u$, the probability that Algorithm 1 finds $\bar{v}$ is no smaller than the probability that the beam search enters $H_{\bar{u}}$.

---

The value of $h^{\prime}$ depends on $q$. While there is no definite expression of $h^{\prime}$, in practice, we can easily use a query workload to determine the optimal value of $h^{\prime}$ w.r.t the accuracy. For example, as observed in our experiments, $h^{\prime}$ can be tuned to obtain a recall higher than 0.95 . This empirical result is consistent with those from the existing works $[46,51]$ that the beam search empirically has a high chance to enter the neighborhood $H_{\bar{v}}$ of $\bar{v}$.

#### 6.2.1 Optimization for the search algorithm. 

We propose a query-aware edge occluding method (QEO) to reduce the number of distance computations in the beam search on $\tau$-MNG.

Line 8 of Algorithm 1 compares the distance between $q$ and each neighbor $v$ of the current node $u$ with the $(b-1)$-th node in $W$. If $\delta(q, v)>\delta(q, W[b-1]), v$ is pruned. In our preliminary experiments, we observe that the farther the current node $u$ from $q$, the higher probability that the neighbors of $u$ can be pruned by the $(b-1)$-th node in $W$. The intuition is that assume the neighbors of $u$ are uniformly distributed in ball $_{u}$ centered at $u$ with $\operatorname{radius~}_{\max _{v \in N_{G}(u)}} \delta(u, v)$. The intersection of $\operatorname{ball}(q, \delta(q, W[b-1]))$ and ball $_{u}$ reduces with the growth of the distance between $q$ and $u$. Fig. 4 illustrates the intuition. $u_{1}$ is close to $q$ and the entire $\operatorname{ball}_{u_{1}}$ is in $\operatorname{ball}(q, \delta(q, W[b-1]))$, i.e., all neighbors of $u_{1}$ cannot be pruned by $W[b-1]$. $u_{2}$ is far from $q$ and ball $_{u_{2}}$ is partially in $\operatorname{ball}(q, \delta(q, W[b-1]))$, i.e., some neighbors of $u_{2}$ can be pruned by $W[b-1]$.

---

Based on this observation, we propose a query-aware edge occluding method. Specifically, if the current node $u$ is not in the top $p \%$ of $W$, for all neighbors of $u$, we compute a lower bound $\delta_{l b}$ of
their distances to $q$ and sort the neighbors by $\delta_{l b}$. Then, we compute $\delta$ for the top $p^{\prime} \%$ neighbors and add them into $W$; the remaining $\left(1-p^{\prime}\right) \%$ neighbors are pruned. If $u$ is in the top $p \%$ of $W$, we compute $\delta$ for all neighbors of $u$ and add them into $W$.

---

$\delta_{l b}$ of a node $v$ and $q$ is defined as $\delta_{l b}(v, q)=\sqrt{\sum_{i=0}^{z}(v[i]-q[i])^{2}}$, where $v[i]$ and $q[i]$ denote the $i$-th dimensions of $v$ and $q$, respectively, and $0<z<m$. To improve the tightness of $\delta_{l b}(v, q)$, we perform an orthogonal transformation to $v$ and $q$, such that the beginning dimensions of $v$ and $q$ have more percentage of their Euclidean distance. Specifically, $\delta_{l b}(v, q)=\sqrt{\sum_{i=0}^{z}((U v)[i]-(U q)[i])^{2}}$, where $U$ is an $m$ by $m$ orthogonal matrix and can be computed by the singular value decomposition (SVD) of $D$. $U v$ can be computed offline for any $v \in D$.

#### 6.2.2 Implementation details. 

We discuss two important implementation details for search efficiency.

**Partial distance-based pruning (PDP).** During the beam search, for a neighbor $v$ of the current node $u$, as long as we can decide $\delta(q, v)>\delta(q, W[b-1])$, we can prune $v$ without exactly computing $\delta(q, v)$. It can save many computation costs and motivates a partial distance-based pruning method. Specifically, in the $m$ iterations for computing the sum $\sum_{i=0}^{m}(v[i]-q[i])^{2}$, if we find $\sum_{i=0}^{j}(v[i]-q[i])^{2}$ at the $j$-th iteration is already larger than $(\delta(q, W[b-1]))^{2}$, we can simply prune $v$.

---

**Prefix inner product index (PII).** The computation of $\delta(q, v)$ can be reformulated as $\langle q, q\rangle+$ $\langle v, v\rangle-2 \times \sum_{i=0}^{m}(v[i] \times q[i])$, where $\langle\cdot, \cdot\rangle$ denotes the inner product. $\langle v, v\rangle$ can be computed offline. We only need to compute $\langle q, q\rangle$ and $v[i] \times q[i]$ online. Since computing $v[i] \times q[i]$ only needs half operations of computing $(v[i]-q[i])^{2}$ and the cost of computing $\langle q, q\rangle$ can be shared by all distance computations in search, approximately half of the total cost of distance computations can be saved. To integrate with the partial distance-based pruning, we divide the vector $v$ into segments and index the inner products for the prefix segments. Specifically, given a segment size parameter $s$, we index inner products $\langle v[0, i \times s], v[0, i \times s]\rangle, 0<i<\lceil m / s\rceil$. We perform partial distance-based pruning segment by segment.

### 6.3 Update of $\tau$-MNG

Similar to Section 5.3, we propose to reconstruct the $\tau$-MNG $G$ periodically after $O(\ln n)$ updates. For insertion, we simply adopt the strategy of HNSW. Specifically, we use a beam search on $G$ to find the $h$-ANNs $H_{u}$ of the node $u$ to-be-inserted. Then, the edge occlusion rule (Definition 3) is used to find the edges between $u$ and the nodes in $H_{u}$. For deletion, the method in Section 5.3 is used.


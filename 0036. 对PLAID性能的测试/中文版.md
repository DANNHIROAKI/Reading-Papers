# A Reproducibility Study of PLAID 


#### Abstract

PLAID(性能优化的延迟交互驱动器)算法是ColBERTv2的一个组件，它使用聚类的词项表示来检索并逐步剪枝文档以进行最终(精确)文档评分。在本文中，我们复现了原始工作并填补了其中的空白。通过研究PLAID引入的参数，我们发现其帕累托前沿是由三个参数之间的精细平衡形成的；超出建议设置的偏差可能会显著增加延迟，但不一定能提高其效果。随后，我们将PLAID与原论文中缺失的一个重要基准进行了比较：对词法系统进行重排序。我们发现，在低延迟设置下，将ColBERTv2作为BM25初始结果池的重排序器提供了更好的效率-效果权衡。然而，由于词法匹配召回率的限制，重排序在较高延迟设置下无法达到峰值效果，并且对穷尽式ColBERTv2搜索提供了较差的近似。我们发现，最近提出的重排序修改方法通过引入top评分文档的邻近文档克服了这一限制，在使用标注完善的数据集评估时，为ColBERTv2在所有操作点上提供了帕累托前沿。为了探究重排序方法为什么能与PLAID高度竞争，我们分析了PLAID用于检索的词元表示聚类，发现大多数聚类主要与单个词元对齐，反之亦然。鉴于重排序基准展现出的竞争性权衡，本工作强调了在评估检索引擎效率时谨慎选择相关基准的重要性。

## 1 INTRODUCTION

相关性排序是信息检索中的核心任务。针对该任务存在多类模型，包括词法[21]、稠密[10]、学习型稀疏[18]和延迟交互[11]模型。虽然词法和学习型稀疏检索系统存在高效的精确top-k检索算法（如BlockMaxWAND[6]），但稠密和延迟交互方法要么需要在整个集合上进行昂贵的穷举评分，要么不得不采用top-k检索的近似方法。对于（单一表示的）稠密模型，存在大量近似k近邻方法（如HNSW[16]）。然而，这些方法通常无法直接应用于延迟交互评分机制，因此针对延迟交互模型提出了定制的检索算法。

---

PLAID（性能优化的延迟交互驱动器）[22]就是这样一种检索算法。它旨在为ColBERTv2[23]（一个重要的延迟交互模型）高效地检索和评分文档。PLAID首先通过将最接近查询词项嵌入的ColBERTv2质心（用于压缩词项嵌入）进行匹配来执行粗粒度检索。然后，它通过对文档最终相关性得分进行更细粒度的估计来逐步过滤候选文档。这些过滤步骤由三个新参数控制，这些参数将在第2节中详细讨论。

---

原始PLAID论文回答了几个重要的研究问题，这些问题涉及与ColBERTv2默认检索器相比的整体效果和效率、各个过滤阶段的影响，以及其可迁移性。然而，它也留下了几个重要的未解答问题。这篇可复现性论文旨在复现该论文的核心结果并回答几个额外问题。首先，我们探索PLAID新参数的影响，以更好地理解在部署PLAID引擎时必须做出的实践决策。然后我们探索并报告了一个重要的缺失基准（对词法检索系统进行重排序），这已被证明是稠密系统的一种高度竞争性方法[12, 14]。在我们的探索过程中，我们还回答了关于PLAID在具有许多已知相关文档的数据集上的表现如何，以及它对穷举式ColBERTv2搜索的近似程度如何等问题。

---

我们发现PLAID的参数需要谨慎地相互协调设置，以避免效果和效率之间的次优权衡。如图1所示，PLAID的帕累托前沿是参数设置的拼接；在不对其他参数进行相应更改的情况下更改一个参数可能会导致检索速度变慢，而效果没有变化。此外，我们发现在低延迟设置下，对词法搜索结果进行重排序提供了比PLAID更好的效率-效果权衡。例如，在单线程设置下，使用重排序可以在低至7 $\mathrm{~ms}$/查询的时间内实现具有竞争力的结果，而PLAID需要73 ms/查询。通过对词元聚类的分析，我们证实了大部分词元主要执行词法匹配，这解释了为什么词法作为第一阶段如此具有竞争力。我们认为我们的研究为那些希望使用ColBERTv2或类似模型（无论是否使用PLAID算法）的人提供了重要的操作建议。

## 2 BACKGROUND AND PRELIMINARIES

排序模型中的延迟交互类在上下文化文本编码器之上应用轻量级的查询词元到文档词元的"交互"运算符，以估计查询和文档之间的相关性。其中最著名的可能是ColBERT模型[11]，它在预训练的基于transformer的语言模型上应用最大相似度运算符——尽管也有其他延迟交互运算符（如[15, 27]）和上下文化策略（如[5, 9]）被提出。由于其评分机制的性质，延迟交互模型在不对所有文档进行穷举扫描的情况下无法高效地识别精确的top-$k$搜索结果$^1$，也无法直接使用已建立的近似最近邻算法。$^2$延迟交互方法的早期工作（如$[5,9,15]$）通过重排序策略克服了这一限制，其中使用BM25[21]等高效的第一阶段词法检索器来识别候选文档集。Khattab和Zaharia[11]指出这种重排序策略可能是次优的，因为（词法匹配的）第一阶段结果可能与模型会高度排序的结果不一致。因此，他们建议使用词元表示的近似$k$近邻搜索来识别需要评分的文档。

---

为了处理存储预计算文档词元表示所需的大量空间，ColBERTv2[23]实现了一个聚类解决方案，用于识别可以用来将文档词元表示分解为质心和量化残差向量之和的文档词元质心，相对于原始ColBERT将存储需求减少了一个数量级。这些聚类质心可以作为文档词元的代理[22, 24, 25]。

---

PLAID[22]进一步基于ColBERTv2的质心来提高检索效率。如图2所示，PLAID通过三个不同的阶段来选择并逐步过滤候选文档。首先，给定编码后的查询词元表示，计算与其最接近的文档词元质心。检索相应的文档标识符并将它们合并到候选集中。每个查询词元要匹配的最近质心数量是一个称为nprobe的超参数。自然地，随着nprobe的增加，初始文档池的大小也会增加。其次，通过移除所有与所有查询词元的最大相似度小于阈值参数$t_{cs}$的质心来剪枝候选质心集。接下来，通过基于在未剪枝质心上计算的延迟交互机制相关性得分选择top ndocs文档，进一步剪枝已剪枝的质心集。然后，通过解压缩词元表示并计算精确的ColBERTv2相关性得分，对top ndocs/4个近似评分的文档进行完整评分。注意，PLAID总共引入了三个超参数，即nprobe、$t_{cs}$和ndocs。虽然原始PLAID论文提供了这些设置的三个建议配置，但它并未探讨它们之间的影响和相互依赖关系。

## 3 CORE RESULT REPRODUCTION

我们首先复现PLAID的核心结果。具体来说，我们测试使用PLAID推荐的操作点进行检索是否能提供原始论文中呈现的绝对效果和相对效率。鉴于原始论文使用稀疏标注评估集的限制，我们测试了一个来自原始论文的稀疏标注数据集和一个具有更完整相关性评估的数据集。我们还添加了一个原始工作中未探索的新测量指标——与穷举式ColBERTv2搜索的排序偏差重叠度(RBO)[26]，以测试PLAID相对于完整搜索的近似程度。

---

根据ACM的定义，我们详述于下一节的实验设置同时包含了可复现性和可重复性的要素$^3$，因为我们是一个使用部分相同工件（代码、模型、数据集等）的不同团队，同时也对实验设置引入了其他改变（增加了评估数据集、新的度量指标等）。

### 3.1 Experimental Setup

模型和代码。 我们从发布的ColBERTv2检查点$^4$和PLAID作者发布的代码库$^5$开始复现PLAID。我们发布了我们修改版本的代码和运行新实验的脚本。

---

**参数。** 我们使用PLAID推荐的nprobe、$t_{cs}$和ndocs参数设置，如表1所示。为简单起见，我们将这些操作设置称为(a)、(b)和(c)，其中每个设置逐步减少过滤的文档数量。PLAID在过程结束时（即在完全评分和排序过滤后的文档后）执行最终的top $k$选择。我们认识到这一步是不必要的，只会限制明显的结果集大小。因此，根据典型的IR实验程序，我们在所有设置中将$k$设为1000。我们还使用了建议的nbits=2和nclusters=$2^{18}$设置。

---

**基准。** 我们直接与原始PLAID论文报告的实验设置结果进行比较（他们论文中的表3）。我们进一步对ColBERTv2$^6$进行了穷举搜索，以更好地理解结果背景并支持排序偏差重叠度的测量（如下所述）。

---

**数据集。** 我们在MS MARCO v1段落开发数据集[3,19]上进行评估，该数据集包含6,980个查询，具有稀疏的相关性评估（每个查询约1.1个）。为了弥补这些评估的局限性，我们还使用更全面的TREC DL 2019数据集[4]进行评估，该数据集包含43个查询，每个查询有215个评估。根据官方任务指南和原始PLAID论文，我们没有用标题[13]来增强MS MARCO段落集合。

---

**测量指标。** 对于MS MARCO Dev，我们使用官方评估指标——深度10的平均倒数排名（RR@10），并使用MS MARCO提供的评估脚本。为了理解系统检索相关段落的整体能力，我们测量深度1000的召回率（$\mathrm{R}@1\mathrm{k}$），这也经常用于Dev的评估。为了测试PLAID对穷举搜索的近似程度，我们测量排序偏差重叠度（RBO）[26]，持续性参数为0.99。我们通过在Dev集上使用单个CPU线程的平均响应时间（每次查询的毫秒数，$\mathrm{ms}/\mathrm{q}$）来测量效率。与原始论文一致，我们只测量检索时间，忽略编码查询所需的时间（这在所有方法中都是相同的）。

对于TREC DL 2019，我们评估官方指标nDCG@10，同时评估nDCG@1k以测试更深层次排名的质量，以及$\mathrm{R}@1\mathrm{k}$以测试算法识别给定主题所有已知相关段落的能力。遵循TREC DL 2019的标准惯例，我们在计算召回率时使用最小相关性得分2。我们使用pytrec_eval[8]来计算这些测量指标。

---

**硬件。** 原始PLAID论文评估了多种硬件配置，包括单CPU、多CPU和GPU设置。考虑到该算法对效率的关注，我们仅使用单线程设置，同时认识到该算法的大部分部分可以在CPU或GPU上进行简单的并行化处理。此外，与原始工作一样，我们将所有嵌入加载到内存中，消除了从磁盘读取的开销。我们使用配备3.4 GHz AMD Ryzen 9 5950X处理器的机器进行实验。（原始论文使用2.6 GHz Intel Xeon Gold 6132处理器。）

### 3.2 Results

表2展示了我们核心复现研究的结果。我们首先考察在MS MARCO Dev上报告的效果。我们看到在精确度导向的RR@10测量指标上，三个操作点之间几乎没有差异。$^7$在效率方面，我们的绝对延迟测量值更低，不过考虑到我们使用的是更快的CPU，这并不令人惊讶。然而，各操作点之间的近似相对差异是相似的，例如，在原始论文和我们的复现中，操作点(b)相比(c)都提供了37%的加速。关于R@1k和RBO，我们看到与RR@10相似的趋势：随着操作设置集体考虑更多文档进行最终评分，这些指标都有所改善。这些结果表明PLAID正如预期工作：当考虑更多文档时，PLAID识别出更多相关文档（R@1k增加），同时也产生了对穷举式ColBERTv2搜索更好的近似（RBO增加）。

---

当考察TREC DL 2019的结果时，我们观察到与Dev结果相似的趋势。精确度聚焦的nDCG@10指标从(a)到(b)略有改善，而由于系统召回率的提高，nDCG@1k和R@1k在各设置间展现出更大的改善。这些结果进一步证明了PLAID在不同评估设置中的稳健性。

---

总的来说，我们能够在单CPU设置下成功复现PLAID的核心结果（在精确度和效率方面）。我们进一步验证了这些趋势在使用面向召回率的指标测量PLAID以及在具有更完整相关性评估的数据集上评估PLAID时仍然成立。然而，原始评估仍然存在几个限制。尽管我们知道PLAID的参数在三种设置中可以协同工作以提供高效检索，但我们不了解每个参数单独的影响。此外，尽管PLAID检索在绝对意义上相当快速（在单个CPU核心上可降至约80 $\mathrm{~ms}$/查询），但我们不知道它与高度竞争的重排序系统相比表现如何。这些限制将在接下来的章节中得到解决。

## 4 PARAMETER STUDY

回顾一下，PLAID引入了三个新参数：nprobe（为每个词元检索的集群数量）、$t_{cs}$（质心剪枝阈值）和ndocs（质心交互剪枝后返回的最大文档数量）。虽然原始论文建议了这些参数的三个设置（见表1），但它并未解释这些参数是如何选择的，或者每个参数最终如何影响检索的效果和效率。在本节中，我们填补这一空白。

### 4.1 Experimental Setup

我们扩展了第3.1节中核心复现研究的实验设置。然后我们对以下参数设置进行了网格搜索：nprobe $\in \{1,2,4,8\}$，$t_{cs} \in \{0.3,0.4,0.45,0.5,0.6\}$，和ndocs $\in \{256,1024,4096,8192\}$。

---

这组参数最初是通过对建议的参数设置进行网格搜索而确定的。考虑到nprobe已经包含最小值1，我们将其扩展到8以检查从第一阶段引入更多候选文档是否有帮助。对于$t_{cs}$，我们在两个方向上扩展了参数搜索：向下到0.3（基于质心得分过滤掉更少的文档）和向上到0.6（过滤掉更多文档）。最后，我们将ndocs扩展到8192，这是基于我们观察到该参数的低值（如256）会显著损害效果。

---

我们还询问了PLAID作者关于是否有其他可以调整的参数来最大化效果或效率。他们告诉我们这三个参数具有最显著的影响。同时，索引时的参数nbits和nclusters也可以影响最终性能。然而，我们将这两个索引参数视为ColBERTv2模型的设置而不是PLAID检索器的设置，所以为了使组合数量保持在可管理的范围内，我们专注于检索器的参数。

### 4.2 Results

图3展示了我们参数研究的结果。该图分解了在平衡检索延迟（$\mathrm{ms}/\mathrm{q}$）与MS MARCO Dev RR@10、Dev RBO或DL19 nDCG@1k时每个参数的影响。每个评估涵盖了PLAID的不同可能目标：找到单个相关段落、模拟穷举搜索，以及对所有已知相关文档进行排序。为了帮助直观地分离每个参数的影响，图中的线条连接了保持其他两个参数不变的点。

---

从图中可以清楚地看出，ndocs始终对效果和效率都有最显著的影响。选择太少的文档进行评分（ndocs=256）会持续降低效果，同时仅节省最小的延迟（与ndocs=1024相比约10 $\mathrm{ms}/\mathrm{q}$）。同时，进一步将ndocs增加到4096并不会提高前10个结果的质量（RR@10）。然而，这一改变在提高排名靠后结果的质量（RBO和nDCG@1k）方面发挥了持续且重要的作用。最后，将ndocs增加到8192在搜索结果质量或对穷举搜索的近似忠实度方面没有提供额外的好处，同时显著增加了延迟。基于这些观察，我们建议设置ndocs $\in[1024,4098]$，因为这个范围之外的值带来的好处很小。

---

第二个最有影响力的参数是nprobe。正如预期的那样，增加每个词元匹配的集群数量会持续增加延迟，因为在整个流程中会产生和处理更多的候选文档。将该值设置得太低（nprobe=1，有时是nprobe=2）通常会显著降低效果，这是因为在这个阶段被过滤掉的文档将没有机会被检索。这一点在Dev RR@10中尤其明显。同时，将这个值设置得太高会降低效率而不会带来任何效果上的提升。

---

最后，$t_{cs}$对检索效果的影响最小，对这个参数的改变通常只会调整检索延迟。这可以从图3中大致水平的线条看出。然而，当这个阈值变得太高时，它可能对效果和效率都产生不稳定的影响。例如，在Dev RR@10中，设置$t_{cs}=0.6$有时会降低效果并增加延迟。因此，我们建议使用$t_{cs} \in[0.4,0.5]$——最好是靠近范围的上限以限制对延迟的影响。

---

我们现在考虑三个参数共同的效果。要达到PLAID的帕累托前沿需要协调调整所有三个参数。例如，最低的检索延迟需要非常低的ndocs值。然而，在不对其他参数做出相应改变的情况下将ndocs从1024降低到256，可能仅会导致效果变差而对延迟没有太大影响。同时，在不调整nprobe的情况下提高ndocs会增加延迟而不会改善效果。图1（在第1页）可能最清楚地展示了这种参数拼接的效果，其中帕累托前沿由nprobe∈{1,2,4,8}、$t_{cs}$ ∈ {0.3,0.45,0.5,0.6}和ndocs∈{256,1024,4096,8192}的各种组合形成。

---

总的来说，PLAID的每个参数都在算法的最终效率-效果权衡中发挥作用。虽然ndocs发挥着最重要的作用，但正确设置nprobe（在较小程度上还有$t_{cs}$）也是达到良好平衡的必要条件。在某些方面，ndocs的重要性并不令人惊讶，因为精确评分的文档越多，可以预期效果越高（直到某个点）。但这引发了一些重要问题：精确评分文档池的来源有什么影响？与更简单和更快的候选生成过程相比，PLAID的渐进式过滤过程是否值得其计算成本？我们将在下一节探索重排序基准时回答这些问题。

---

图3：我们对PLAID参数nprobe、$t_{cs}$和ndocs的研究结果。每一行绘制相同的数据点，颜色代表每个参数值，它们之间的线条显示了在其他两个参数保持不变时的效果。虚线显示了穷举搜索的结果，圆圈标记的点突出显示了原始论文中推荐的三个设置。

## 5 BASELINE STUDY

原始论文将PLAID的效率与三个基准进行了比较：(1) 原版ColBERT(v2)，它按照原始ColBERT(v1)[11]使用的方法为每个词元使用IVF索引进行检索；(2) SPLADEv2[7]，这是一个学习型稀疏检索器[18]；以及(3) BM25[21]，这是一个传统的词法检索模型。在这些基准中，只有原版ColBERT(v2)代表了一个替代检索引擎；SPLADEv2使用其他评分机制并作为参考点。奇怪的是，评估忽略了一种常见的方法：仅对像BM25这样高效但不精确的模型的结果进行重排序。在本节中，我们将PLAID与这个基准进行比较。此外，我们还将这两种方法与词法加速密集检索（LADR）[12]进行比较，后者修改了重排序算法，在重排序时也考虑遇到的得分最高结果的最近邻。

### 5.1 Experimental Setup

我们使用第4节的PLAID实验结果作为基准研究的起点。我们进一步修改PLAID源代码以支持两种新方法：重排序和LADR。

---

**重排序。** 我们使用高效的PISA引擎[17]进行BM25检索，使用默认参数和BlockMaxWAND[6]索引结构。然后使用ColBERTv2的解压缩和评分函数对这些结果进行重排序。鉴于我们发现用于评分的候选文档数量是PLAID最重要的参数，我们将BM25的检索结果数量n变化为以下值：n $\in{200,500,1000,2000,5000,10000}$。注意，由于应用了动态索引剪枝，对于较低的n值，执行初始检索比较高的n值要快得多——这是除了ColBERTv2解压缩和评分成本之外的。

---

**LADR。** 我们使用LADR进一步构建重排序流程。这种方法通过查找ColBERTv2高分结果的最近邻来克服第一阶段检索可能存在的词法不匹配问题。与PLAID的程序一致，我们对初始BM25候选数量n $\in{100,500,1000}$和要查找的最近邻数量k $\in{64,128}$进行网格搜索。我们使用原始LADR论文中基于BM25的预计算最近邻图。通过使用LADR的自适应变体，我们迭代地对前c $\in{10,20,50}$个结果的邻居进行评分，直到它们收敛。

---

**评估。** 我们使用与3.1节相同的数据集和评估指标。与此设置一致，我们将PISA的单线程第一阶段检索延迟包含在两个额外的基准中。在多线程或GPU环境中，我们注意到这个第一阶段检索可以与ColBERTv2查询编码过程并行进行，进一步降低这些基准的成本。然而，考虑到我们评估的单线程性质，我们将其视为额外的延迟。

### 5.2 Results

图4展示了我们基准研究的结果。我们首先关注BM25重排序流程。我们观察到这个流程比最快的PLAID流程检索速度要快得多（在n=200时低至9 $\mathrm{ms}/\mathrm{q}$，相比之下最快的PLAID流程需要73 $\mathrm{ms}/\mathrm{q}$）。虽然这种设置通常会降低结果质量（相比最快的PLAID流程的Dev RR@10、RBO、R@1k和DL19 nDCG@10），但在绝对效果方面仍然remarkably强大。例如，其Dev RR@10为0.373，这比早期的基于BERT的交叉编码器[20]和最近的学习型稀疏检索器[7]都要强。

---

随着BM25重排序流程考虑更多文档，效果逐渐改善。然而，在大多数情况下，它的表现仍然不如PLAID。例如，当通过DL19 nDCG@10和Dev RR@10考虑前10个文档时，重排序流程的帕累托前沿始终低于PLAID。尽管如此，执行词法检索方法的前期成本较低，使得重排序在延迟或计算成本关键时成为一个有吸引力的选择。

---

然而，重排序本质上受限于第一阶段的召回率，当第一阶段只能进行词法匹配时，这可能会大大限制下游的潜在效果。我们观察到LADR作为重排序流程的高效伪相关反馈，可以在很大程度上克服这一限制。在DL19上，LADR的帕累托前沿完全超越了PLAID，无论是在nDCG还是召回率方面。（LADR的非最优操作点也始终具有竞争力。）同时，在Dev上，LADR提供了具有竞争力的——尽管不是总是最优的——效果。考虑到Dev具有稀疏评估而DL19具有密集评估，我们知道LADR正在选择合适的相关文档作为候选，尽管它们不一定是ColBERTv2通过穷举搜索会识别出的文档。Dev上的RBO结果进一步强化了这一点：虽然PLAID可以达到与穷举搜索几乎完美的RBO，但LADR最高只能达到约0.96。

---

总的来说，与PLAID相比，重排序及其变体LADR是极具竞争力的基准，特别是在PLAID所针对的低延迟设置下。虽然它们不一定能识别出与穷举式ColBERTv2搜索相同的文档，但这些基准通常能提供具有高相关性的替代文档。

---

然而，我们注意到重排序也有其缺点。它需要在ColBERT索引之外构建和维护一个词法索引，这会增加检索系统的存储成本、索引时间和整体复杂性。尽管如此，与部署ColBERTv2系统本身的成本相比，这些成本相对较低。例如，MS MARCO v1的ColBERTv2索引消耗约22GB存储空间，而词法PISA索引使用不到1GB。同时，混合检索系统（即那些结合词法和神经模型信号的系统）无论如何都需要承担这些成本。LADR在构建和维护文档邻近图方面增加了额外成本（在MS MARCO上，每个文档有64个邻居的图约需2GB）。

### 5.3 Cluster Analysis

为了探究为何重排序词法系统与PLAID相比具有竞争力，我们对PLAID用于检索的词元表示聚类与词元的词法形式进行了分析。我们使用之前实验中的ColBERTv2 MS MARCO v1段落索引，并修改源代码以记录每个词元的原始词元ID及其聚类ID和残差。然后我们使用这种词元ID和聚类ID之间的映射进行分析。

---

我们首先研究词元聚类的同质性程度。换句话说，我们提出这样一个问题：一个聚类的大多数表示是否来自同一个源词元？我们首先观察到大多数聚类映射到多个词元（一个聚类映射到的词元的中位数是15，而只有2.2%的词元仅映射到单个词元）。然而，这并未讲述完整的故事，因为每个聚类中词元的分布是高度偏斜的。为了克服这一点，我们测量了每个聚类中属于主要（或占多数）词元的比例。图5展示了所有聚类中主要词元比例的分布。我们观察到39%的聚类的主要比例超过0.95（即这些聚类中超过95%的表示来自同一个词元）。同时，所有聚类的中位比例为0.86。只有2.7%的聚类的主要比例低于10%。总的来说，这些结果表明，尽管聚类经常由多个词元形成，但它们通常都由单个词元主导。换句话说，它们在很大程度上执行词法匹配。

---

在一个聚类内，其他匹配的词元究竟是什么？图6为MS MARCO查询"do goldfish grow"提供了示例聚类。一些匹配聚类（48169和225987）在[CLS]和[SEP]词元上执行相当不透明的语义匹配。这些聚类要么匹配其他类似的控制词元，要么（频率低得多）匹配像and、but和the这样的功能词。我们推测这些功能词被用来帮助强调段落的中心点，考虑到它们本身在语义方面通常提供的内容不多。接下来，三个聚类（48169、30151和227745）的主要词元比例都低于或接近中位数。然而，一个聚类内的许多少数派词元只是同一个词的不同形态变化：grow、grows、growing等。换句话说，它们共享一个共同的词干。当合并词干时，这三个聚类的主要词元比例都超过了$95\%$。最后两个聚类（21395和130592）由单个词元主导（主要词元比例$>90\%$）。与控制词元一样，这些聚类捕捉了标点符号词元，我们推测这些词元被用来帮助强调段落中特别显著的词元。这种定性分析表明，尽管一些聚类可能执行语义匹配，图5可能实际上低估了PLAID聚类中词法匹配的整体普遍性。

---

然而，观察到大多数聚类映射到单个源词元只说明了一半的故事。也许PLAID正在有效地执行一种动态剪枝[2]的形式，其中查询词项只匹配某些词法匹配的子集（即语义上最相关的那些），而不是全部。毕竟，图6显示了三个具有相同主要词元（grow）的不同聚类。因此，我们提出了与第一个问题相反的问题：一个词元的大多数表示是否映射到相同的聚类？类似于聚类分析，我们测量每个词元的主要聚类比例，并在图7中绘制其分布。在这里，33%的词元的主要聚类比例大于0.95。与我们在图5中的观察不同，尾部更平坦且更均匀，主要聚类比例的中位数为0.62。这些结果表明，尽管相当数量的词元映射到单个显著聚类，但许多词元分散在许多不同的聚类中。然而，如图6所示，即使一个词元出现在许多不同的聚类中，也不意味着它一定会被完全剪枝掉：包含grow的两个聚类（30151和227745）直接被查询的[PAD]"扩展"词元捕获。

---

这项分析表明，PLAID在识别要评分的文档时执行了大量的词法匹配（尽管不是完全如此）。它还提供了一些见解，解释了为什么重排序与PLAID具有竞争力。

## 6 CONCLUSION

在本文中，我们对PLAID（一个ColBERTv2的高效检索引擎）进行了可复现性研究。我们成功复现了该研究的主要结果，并证明这些结果能够成功推广到具有更完整相关性评估的数据集。我们还证明了PLAID提供了对穷举式ColBERTv2搜索的优秀近似。通过对PLAID参数的深入研究，我们发现这些参数高度相互依赖，且建议的设置不一定是最优的。具体来说，将ndocs增加到超过建议的256几乎总是值得的，因为这种改变对延迟的影响很小，而对效果的提升很大。同时，仅使用ColBERTv2对词法系统进行重排序（及其最近的变体LADR）这一缺失的基准在低延迟操作点上提供了更好的效率和效果权衡。然而，这些基准并未提供对穷举式ColBERTv2搜索同样强的真实近似。最后，分析表明PLAID在文档的初始检索中主要依赖词法匹配。

---

我们的研究为那些希望部署ColBERTv2系统（无论是否使用PLAID引擎）的人提供了重要的操作建议。它还进一步强调了在评估检索算法效率时与多功能重排序系统进行比较的重要性。鉴于PLAID执行第一阶段词法匹配的间接方式，未来的工作可以研究混合PLAID-词法检索的方法。通过依靠PLAID进行语义匹配，使用传统倒排索引进行词法匹配，我们可能能够实现"两全其美"：PLAID的高质量ColBERTv2近似和重排序的高效率。

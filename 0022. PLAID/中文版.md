# 0. Abstract

预训练语言模型在多种信息检索（IR）范式中正变得日益重要。后期交互作为ColBERT模型提出的一种范式，最近在ColBERTv2中得到了进一步优化，并在许多基准测试中保持了最先进的水平。为显著加快后期交互的检索延迟，我们提出了性能优化的==后期交互驱动器==（PLAID）。在不影响质量的前提下，PLAID通过一种新颖的质心交互机制快速剔除低得分的段落，将每个段落视为一个轻量级的质心集合。PLAID在高度优化的引擎中使用质心交互以及质心剪枝（用于稀疏化质心集合的机制），在GPU上将后期交互的检索延迟减少了多达$7 \times$，在CPU上减少了多达$45 \times$，相较于原生的ColBERTv2，同时保持了最先进的检索质量。这使得PLAID引擎与ColBERTv2在大规模场景下，即使在我们评估的最大规模（1.4亿段落）下，也能在GPU上实现数十毫秒的延迟，在CPU上实现数十到几百毫秒的延迟。

# 1. 引言

神经信息检索（IR）的最新进展在检索基准和基于检索的NLP任务上取得了显著的提升。ColBERT [22]中提出的后期交互是一种范式，在许多此类环境中提供了最先进的质量，包括段落排名[14, 42, 48]、开放域问答[21, 24]、会话任务[35, 38]等[20, 54]。ColBERT及其变体将查询和文档编码为词级向量，并通过词级的可扩展但精细的交互来进行评分（图1），缓解了单向量表示的点积瓶颈。最新的ColBERTv2 [42]模型表明，后期交互模型在训练域内外通常显著优于最新的单向量和稀疏表示，多个最新研究也得出相似结论[26, 29, 43, 44, 51, 53]。

---

尽管后期交互具有强大的检索质量，但由于它将每个查询和文档编码为完整矩阵，因此需要专门的基础设施[22, 25]来实现低延迟检索。大多数IR模型将文档表示为单个向量，稀疏（如BM25 [41]；SPLADE [11]）或密集（如DPR [18]；ANCE [49]），因此成熟的稀疏检索策略如WAND [5]或密集kNN方法如HNSW [31]无法直接或最佳地应用于后期交互。尽管最近的研究[28, 42, 45]探讨了优化ColBERT管道的单个组件，但据我们所知，还没有研究过端到端优化引擎。

---

我们研究如何在大规模下优化后期交互搜索延迟，考虑到检索的所有步骤。我们基于最先进的ColBERTv2模型。除了通过去噪监督提高质量，ColBERTv2还积极压缩了后期交互的存储占用。它通过残差表示将索引大小减少了一个数量级（第3.1节）。在这些表示中，每个段落的每个向量使用其最近质心的ID进行编码，以近似其词汇语义——这些质心是通过 $k$-均值聚类获得的数万甚至数十万个质心——以及一个量化的残差向量。

---

我们引入了性能优化的后期交互驱动（PLAID），这是一个高效的检索引擎，与原始的ColBERTv2相比，其在GPU上的后期交互搜索延迟减少了2.5–7倍，在CPU上减少了9–45倍，同时保持了高质量。这使得PLAID ColBERTv2可以在CPU上仅用几十到几百毫秒的延迟，或在GPU上仅用几十毫秒的延迟，在非常大规模（甚至140M段落）下实现检索。关键是，PLAID ColBERTv2在此过程中依然提供最先进的检索质量。

---

为了大幅加速搜索，PLAID利用了ColBERTv2表示中的质心组件，这是每个词的一个紧凑整数ID。PLAID不再对所有通过最近邻搜索找到的段落进行全面评分，而是使用质心来识别高分段落，并在不加载其较大的残差时排除较弱的候选项。我们在多阶段管道中执行此操作，并引入了质心交互，这是一种将每个段落视为质心ID集合的轻量化评分机制。我们展示了这种仅基于质心的多向量搜索在不使用向量残差的情况下表现出高召回率（第3.3节），使我们能将完整评分保留给少量候选段落。由于质心来自固定集合（即，构成离散词汇表），查询向量与所有质心之间的距离可以在搜索期间计算一次，并在所有质心集合的段落表示中重用。这使得我们能够进一步利用质心分数进行质心剪枝，通过跳过所有查询向量距离较远的质心ID来在检索的早期阶段稀疏化质心表示集合。

---

在PLAID引擎中，我们实现了质心交互和质心剪枝，并为ColBERTv2的残差表示中的数据移动、解压缩和评分组件实现了优化但模块化的内核（第4.5节）。我们在训练域内外（在MS MARCO v1 [36]和v2 [6]、Wikipedia和LoTTE [42]上）对PLAID的质量和效率进行了广泛评估，覆盖了广泛的语料库大小（2M–140M段落）、搜索深度（𝑘=10, 100, 1000）和单线程、多线程CPU以及GPU的硬件设置（第5.2节）。我们还进行了详细的消融研究，以了解质心交互、质心剪枝和我们更快的内核在经验上的增益来源（第5.3节）。

---

总结而言，我们做出了以下贡献：

(1) 我们分析了ColBERTv2的仅质心检索，显示了通过剪枝的质心表示可以支持高召回率的候选生成（第3节）。
(2) 我们提出了PLAID，一个检索引擎，提出了质心交互和质心剪枝以及这些技术的优化实现，以显著改善后期交互搜索的延迟（第4节）。
(3) 我们对PLAID进行了广泛评估，并进行了大规模评估，涵盖多达140M段落，据我们所知，这是后期交互检索器中最大的规模（第5节）。

# 2. 相关工作

## 2.1. 神经信息检索（IR）

IR社区引入了许多基于预训练Transformer的神经IR模型。早期的模型主要是跨编码器[27, 37]，共同关注查询和段落，而许多后续模型则通过为查询和段落生成独立表示来提高效率。一些模型生成稀疏词项权重[7, 32]，而其他模型将每个段落或查询编码为单向量[18, 39, 49]或多向量表示（我们研究的类别；[12, 15, 21, 22, 42]）。这些选择在效率和质量上做出了不同的权衡：稀疏词项权重和单向量模型在某些场景中特别轻量，而多向量后期交互[22]通常会显著提高质量和鲁棒性。除了建模查询-文档交互的选择之外，研究人员还通过更难的负样本[21, 49, 52]、蒸馏和去噪[13, 39, 40]等方法改进了神经模型的监督。我们的工作扩展了ColBERTv2 [42]，它结合了后期交互建模、难负样本和去噪监督，在独立检索器中实现了最先进的质量。

## 2.2 稀疏和密集检索的剪枝

对于稀疏检索模型，传统IR领域中有大量关于快速跳过文档以进行top-𝑘搜索的研究。策略通常保留如词项得分上限之类的元数据，以跳过得分较低的候选项，大多数遵循逐文档评分（DAAT）方法[5, 8, 9, 19, 33, 47]。关于最近方法的详细处理，请参考Tonellotto等人[46]。与我们的设置相比，一个关键的不同是这些策略期望一组预先计算的分数（特别是每个词项-文档对的有用上限），而在后期交互中，词项-文档交互（即MaxSim分数）只有在查询时通过矩阵-向量乘积计算得出。我们关于质心加速后期交互的观察成功地使该问题更接近于传统IR，但也带来了查询到质心得分仅在查询时得知的挑战。

---

对于使用单向量表示的密集检索模型，近似𝑘-最近邻（ANN）搜索是一个研究广泛的问题[1, 16, 17, 31]。我们的重点是将此类工作从单个向量扩展到两个矩阵的后期交互。

# 3. ColBERTv2 检索分析

我们首先对ColBERTv2检索的延迟（第3.2节）和评分模式（第3.3节）进行初步研究，以激励我们对PLAID的研究。为了使本节内容完整，第3.1节回顾了ColBERTv2的建模、存储和监督机制。

## 3.1. 建模、存储和检索

PLAID优化了使用ColBERT后期交互架构的模型的检索，包括ColBERTv2、Baleen [20]、Hindsight [38]和DrDecr [24]等系统。如图1所示，Transformer独立地将查询和段落编码为词级向量。为了实现可扩展性，段落表示在离线时预先计算。在搜索时，查询 $q$ 与段落 $d$ 之间的相似性通过"MaxSim"操作的求和计算，即查询矩阵中每个向量与所有段落向量之间的最大余弦相似性：

- $\displaystyle{}S_{q, d}=\sum_{i=1}^{|Q|} \max _{j=1}^{|D|} Q_i \cdot D_j^T$ 

其中 $Q$ 和 $D$ 分别是查询和段落的矩阵表示。通过这种方式，该评分函数将每个查询词项与“最相似”的段落词项对齐，并将相关性估计为这些词项级得分的总和。关于后期交互的更完整讨论，请参考Khattab和Zaharia [22]。

---

在存储段落表示时，我们采用了ColBERTv2的残差压缩策略，该策略将索引大小减少了一个数量级，相较于将后期交互嵌入简单存储为16位浮点数向量。ColBERTv2的压缩策略高效地聚类了所有词级向量，并使用其最近的聚类质心的ID以及量化的残差向量对每个向量进行编码，其中每个维度是质心和原始未压缩向量之间的1或2位差值编码。解压缩一个向量需要定位其质心ID（使用4字节编码）和残差（对于1或2位残差，分别消耗16或32字节，假设默认的128维向量）。

---

尽管我们采用了ColBERTv2的压缩方案，但我们改进了其检索策略。我们将原始检索策略称为“vanilla” ColBERTv2检索。关于ColBERTv2中的压缩和检索细节，请参考Santhanam等人[42]。

## 3.2. ColBERTv2的延迟分解

图2展示了在GPU上MS MARCO Passage Ranking (v1)上的查询延迟分解，比较了原始ColBERTv2（图2a）和新PLAID ColBERTv2（图2b）的结果。延迟分为查询编码、候选生成、索引查找（即，收集候选段落的压缩向量表示）、残差解压缩和最终评分（即最后的MaxSim计算）。

---

对于原始ColBERTv2，索引查找和残差解压缩是主要瓶颈。从索引中收集向量非常昂贵，因为它消耗了大量内存带宽：在此设置中，每个向量使用4位的质心ID和32字节的残差进行编码，每个段落包含数十个向量，且最多可以有2个候选段落。此外，原始ColBERTv2中的索引查找还需要动态构建填充张量，以处理段落长度的可变性。残差解压缩由一些复杂操作组成，例如解包位和计算大量的和，这在ColBERTv2生成大量初始候选集（10-40k段落，例如MS MARCO v1）时可能会非常耗费资源。虽然可以使用较小的候选集，但这样会降低召回率（第5节）。

## 3.3. 仅使用质心即可识别高得分候选项

图2b中的分解显示，对大量候选段落进行全面评分（尤其是收集和解压缩其残差）可能耗费巨大资源。尽管ColBERTv2 [42]利用质心来减少存储占用，我们的工作表明，质心也可以加速搜索，同时保持质量，将其作为段落嵌入的替代。基于此，我们可以跳过低分段落，无需查找或解压其残差，通过增加一些候选生成开销来实现后续阶段的显著节省（图2b）。

---

有效地，我们假设仅质心检索可以找到原始ColBERTv2检索到的高分段落。我们通过将原始ColBERTv2检索的前 $k$ 个段落与仅使用质心进行检索的修改版实现进行比较来测试此假设。我们在图3中展示了结果。对于 $k \in\{10,100,1000\}$，图中绘制了在不同深度下，仅质心的ColBERTv2检索到的段落中包含的原始ColBERTv2前 $k$ 个段落的平均召回率。换句话说，我们报告了原始ColBERTv2的前 $k$ 个段落出现在仅质心ColBERTv2的前 $k^{\prime}$ 个段落中的比例，对于 $k^{\prime} \geq k$。

---

结果支持我们的假设，无论是在MS MARCO v1的数据集内还是在使用LoTTE Pooled (dev)的跨域查询上[42]。例如，如果仅使用质心检索 $10 \cdot k$ 个段落，这些 $10 \cdot k$ 个段落仍然包含了由原始ColBERTv2完整管道检索的前 $k$ 段落中的 $99+\%$。

## 3.4. 并非所有质心对每个查询都重要

我们进一步假设，对于给定查询，段落嵌入簇中的一个小子集往往比其他簇在确定相关性方面更为重要。如果确实如此，那么我们可以优先计算这些高度加权的质心，并舍弃其余的质心，因为我们知道它们对最终排名贡献不大。我们通过随机抽样15个MS MARCO v1查询并绘制所有查询词项中每个质心的最高相关性得分的经验累积分布函数（eCDF），如图4所示，以测试该理论。我们发现有一小部分高度加权的质心，其相关性得分的幅度明显高于所有其他质心。尽管图4中未显示，我们在LoTTE池查询中重复了此实验，发现了非常相似的得分分布。

# 4. PLAID

图5展示了PLAID评分管道，该管道包括多个连续阶段，用于检索、过滤和排序。第一阶段通过计算每个质心相对于查询嵌入的相关性得分来生成初始候选集。在中间阶段，PLAID使用质心交互和质心剪枝的创新技术来积极且有效地过滤候选段落。最后，PLAID使用完全重构的段落嵌入对最终候选集进行排名。以下是对这些模块的详细讨论。

## 4.1. 候选生成

给定查询嵌入矩阵 $Q$ 和索引中的质心向量列表 $C$，PLAID通过矩阵乘法计算词级查询-质心相关性得分 $S_{c, q}$：

- $S_{c, q}=C \cdot Q^T$

然后标识对于每个查询词项“接近”前 $t$ 个质心的段落作为初始候选集。如果段落中的一个或多个词项在索引期间通过 $k$-均值聚类分配到该质心，则视为该段落接近该质心。这个值 $t$ 在原始ColBERTv2中被称为nprobe，我们在PLAID ColBERTv2中保留了这一术语。

---

PLAID ColBERTv2的初始候选生成与对应的原始ColBERTv2阶段在两个关键方面有所不同。首先，虽然原始ColBERTv2保存了一个倒排列表，将质心映射到其对应的嵌入ID，但PLAID ColBERTv2将倒排列表结构化为一个从质心到对应唯一段落ID的映射。与存储嵌入ID相比，存储段落ID更有优势，因为段落数量远少于嵌入数量，意味着倒排列表总体上需要存储更少的信息。这也使PLAID ColBERTv2能够在倒排列表中使用32位整数，而非可能的64位长整型。在实际应用中，这在MS MARCO v2 [6] 倒排列表中带来了$2.7 \times$的空间节省（从71 GB减少到27 GB，拥有1.4亿段落）。

---

其次，如果初始候选集过大（由超参数ncandidates指定），原始ColBERTv2会通过对候选嵌入向量子集（特别是倒排列表中质心ID映射到嵌入ID的嵌入）进行评分和排名来修剪候选集，使用完整的残差解压缩，这在§3.2中已讨论是非常耗费资源的。相比之下，PLAID ColBERTv2不对初始候选集大小施加任何限制，因为后续阶段可以通过质心交互和剪枝来廉价地过滤候选段落。

## 4.2. 质心交互

质心交互通过在标准MaxSim公式中使用每个词的最近质心来廉价地近似每个段落的相关性。通过将质心交互作为额外的过滤阶段，评分管道可以跳过对大量候选段落的昂贵嵌入重构过程，从而显著加速端到端检索。直观地说，质心交互使PLAID能够模拟传统的词袋检索，其中质心相关性得分承担了BM25等系统中词项相关性得分的角色。然而，由于PLAID使用的是向量表示（特别是查询的向量），因此PLAID在查询时计算质心相关性得分，而不是传统的预计算词项相关性得分。

---

该过程如下所示。回想一下公式2中的 $S_{c, q}$ 储存了每个质心相对于查询词项的相关性得分。假设 $I$ 是映射到候选集中每个词项的质心索引列表。此外，设 $S_{c, q}[i]$ 表示 $S_{c, q}$ 的第 $i$ 行。那么PLAID构建基于质心的近似得分 $\tilde{D}$ 如下：

- $\tilde{D}=\left[\begin{array}{c}S_{c, q}\left[I_1\right] \\ S_{c, q}\left[I_2\right] \\ \ldots \\ S_{c, q}\left[I_{|\tilde{D}|}\right]\end{array}\right]$ 

然后，为了使用 $\tilde{D}$ 对候选段落进行排序，PLAID计算 $\operatorname{MaxSim}$ 得分 $S_{\tilde{D}}$ 如下：

- $\displaystyle{}S_{\tilde{D}}=\sum_i^{|Q|} \max _{j=1}^{|\tilde{D}|} \tilde{D}_{i, j}$  

从 $S_{\tilde{D}}$ 中选出的最相关的前 $k$ 个段落构成过滤后的候选段落集。

---

PLAID包含了优化的内核以高效部署质心交互（以及更广泛的MaxSim操作）；我们将在$\S 4.5$中讨论这些内容。

## 4.3. 质心剪枝

作为另一项优化，PLAID利用了$\S 3.3$中的观察，在构建 $\tilde{D}$ 之前首先修剪低幅度的质心得分。在此过滤阶段，PLAID仅对其最大对应质心得分达到给定阈值 $t_{c s}$ 的词项进行评分。具体来说，$\tilde{D}$ 只包含满足以下条件的词项：

- $\displaystyle{}\max _{j=1}^{|Q|} S_{c, q_{i, j}} \geq t_{c s}$ 

---

我们引入超参数ndocs来表示第二阶段选择的候选文档数。我们通过实验发现，从第三阶段选择 $\frac{\text { ndocs }}{4}$ 个候选项可以获得良好的结果；我们在$\S 5$中展示的所有结果均使用了这一启发式方法。

## 4.4. 评分

与原始ColBERTv2一样，PLAID将通过残差解压缩重构最终候选段落集的原始嵌入，并使用MaxSim对这些段落进行排序。设 $D$ 为解压后最终候选集的嵌入向量，那么最终得分 $S_{q, d}$ 按照公式1计算。

第$\S 4.5$节讨论了用于加速MaxSim和解压操作的快速内核。

## 4.5. 快速内核：无填充的MaxSim和优化的解压缩

图2a显示，索引查找操作是原始ColBERTv2的主要开销来源之一。导致这些查找成本高的原因之一是，它们需要通过填充附加的最大段落长度维度来调整2D索引张量的形状，使其成为3D张量，从而在不规则的词项列表上实现批量MaxSim操作。为避免这种填充，我们实现了自定义的C++代码，直接在打包的2D索引张量上计算MaxSim得分（即将不同长度的多个2D子张量沿同一维度连接的张量）。我们的内核遍历每个段落对应的词项向量，以针对每个查询词项计算每段落的最大得分，然后在所有查询词项上汇总每段落的最大得分。这种设计易于在段落间并行化，并且通过为每个查询词项分配一个输出向量来存储最大得分并在原位更新该向量，实现了 $O(|Q|)$ 的每线程内存使用。而基于填充的方法则需要 $O(|D| \cdot |Q|)$ 的空间。我们已将此设计整合进优化的质心交互实现中以及最后的MaxSim操作（图5中的第4阶段）。PLAID仅在CPU上实现了这些内核，对应的GPU内核尚待开发。

---

ColBERTv2的残差解压缩方案计算出一组质心向量，确定来自这些质心的一组 $2^b$ 个可能的增量，然后存储每个嵌入向量对应的增量索引。具体来说，每个压缩的8位值存储 $\frac{8}{b}$ 个范围在 $\left[0,2^b\right)$ 内的索引。ColBERTv2在残差解压缩中产生了显著的开销，如图2a所示。这部分原因是由于解压缩的原始实现比较简单，需从压缩表示中显式解开比特并执行昂贵的位移和求和操作以恢复原始值。为优化此过程，PLAID预先计算出所有可能的 $2^8$ 索引列表，并将这些输出存储在查找表中，使得解压缩函数只需从查找表中检索索引而无需手动解开比特。我们为此查找表解压缩实现了CPU和GPU上的优化。GPU实现使用了自定义CUDA内核，为压缩的残差张量中的每个字节分配一个独立的线程（线程块大小计算为 $\cfrac{b \cdot d}{8}$，对于$d$ 维的嵌入向量）。CPU实现则以单个段落为单位进行并行解压。

# 5. 评估

我们的评估旨在回答以下研究问题：
(1) PLAID如何影响跨IR基准的端到端延迟和检索质量？（§5.2）
(2) PLAID的每项优化对性能提升有多大贡献？（§5.3）
(3) PLAID在语料库大小和并行度方面的扩展性如何？（§5.4）

## 5.1 设置

**PLAID 实现**. PLAID 引擎包括质心交互以及残差解压缩优化。我们以模块化的方式将 PLAID 作为对 ColBERTv2 基于 PyTorch 的实现的扩展，特别是在其搜索组件上。对于 CPU 执行，我们将质心交互和解压缩操作完全实现为多线程 C++ 代码。对于 GPU，我们在 PyTorch 中实现了质心交互，并提供了用于快速解压缩的 CUDA 内核。总体而言，PLAID 包括大约 300 行额外的 Python 代码和 700 行 C++ 代码。

---

**数据集**. 我们的评估包括四个不同的IR基准的数据集，详见表1。我们在 MS MARCO v1 和 Wikipedia Open QA 基准上执行域内评估，这些任务中的检索器经过了专门训练；我们在基于 StackExchange 的 LoTTE (Santhanam等人, 2021) 和 TREC 2021 深度学习赛道 [6] MS MARCO v2 基准上执行域外评估，其中 ColBERTv2 检索器 [42] 在 MS MARCO v1 上训练。对于 Wikipedia 的评估，我们使用 2018 年 12 月的转储 [18] 和 NaturalQuestions (NQ) 数据集 [23] 中的查询。LoTTE [42] 评估使用的是“pooled”开发数据集，带有“search”风格的查询。对于 MS MARCO v2，我们使用数据的增强段落版本 [2]，包含段落标题，但忽略标题内容。由于我们评估了模型的多个配置，因此我们所有的评估都是使用开发集查询进行的。

---

**系统和超参数**. 我们报告了多个系统的端到端结果：原始 ColBERTv2 和 PLAID ColBERTv2 以及 ColBERT (v1) [22]、BM25 [41]、SPLADEv2 [10] 和 DPR [18]。对于原始 ColBERTv2，我们使用 ColBERTv2 论文中针对每个基准数据集报告的特定超参数。在结果表中，我们用 $p$（nprobe）和 $c$（ncandidates）表示这些超参数。对于 PLAID ColBERTv2，我们评估了三种不同的设置： $k=10$、$k=100$ 和 $k=1000$。参数 $k$ 控制最终评分的文档数量以及第4节中描述的检索超参数。表2列出了每个 $k$ 设置的超参数配置。我们通过实验证明，对最终评分阶段的文档进行 $\frac{\text { ndocs }}{4}$ 的排序可产生较强的结果。对于原始 ColBERTv2 和 PLAID ColBERTv2，我们将所有数据集压缩至每维2位，除 MS MARCO v2 外将其压缩至1位。

---

**硬件**. 我们在配置了28个Intel Xeon Gold 6132 2.6 GHz CPU核心（每核2个线程，总计56个线程）和4个NVIDIA TITAN V GPU的服务器上进行所有实验。每台服务器有两个NUMA插槽，具有大约92 ns的插槽内内存延迟、142 ns的跨插槽内存延迟、72 GBps的插槽内内存带宽和33 GBps的跨插槽内存带宽。每个TITAN V GPU具有12 GB的高带宽内存。

---

**延迟测量**. 在测量端到端结果的延迟时，我们计算所有查询的平均延迟（查询总数见表1），并报告三次试验中的最小平均延迟。对于其他结果，我们在相关章节中描述了具体的测量过程。我们丢弃神经模型的查询编码延迟（ColBERTv1 [22]、原始ColBERTv2 [42]、PLAID ColBERTv2 和 SPLADEv2 [10]），遵循 Mackenzie 等人的做法[30]；此前的研究表明，运行BERT模型的成本可以通过量化、蒸馏等标准技术减到可以忽略不计的水平 [4]。我们在其他空闲的机器上测量延迟。我们在命令前添加 numactl --membind 0 以确保插槽内I/O操作。对于 MS MARCO v2，我们未执行此操作，因为其大型索引可能需要使用两个NUMA节点。对于GPU结果，我们允许使用所有56个线程，但对于仅限CPU的结果，我们限制使用 torch.set_num_threads 设置的1或8个线程。对于非ColBERT系统，我们使用 Mackenzie 等人[30] 报告的单线程延迟数值。请注意，这些数值是在不同硬件设置和不同实现上测量的，仅用来展示PLAID ColBERTv2的竞争性能，而非作为绝对比较。

## 5.2. 端到端结果

表3展示了MS MARCO v1基准的数据内结果。在最保守的设置（𝑘 = 1000）下，PLAID ColBERTv2能够匹配原始ColBERTv2的MRR@10和Recall@100，同时在GPU上实现6.8倍的加速，在CPU上达到45倍的加速。对于一些质量的轻微损失，PLAID ColBERTv2进一步将对原始ColBERTv2的加速提升到在GPU上12.9–22.6倍，在CPU上86.4–145倍。PLAID ColBERTv2还实现了与其他系统相当的延迟（在SPLADEv2的1.6倍以内），同时在检索质量上优于它们。

---

在Wikipedia OpenQA基准的域内评估中，我们观察到了类似的趋势，如表4所示。与原始ColBERTv2相比，PLAID ColBERTv2在GPU上实现了3.7倍的加速，在CPU上实现了22倍的加速，且没有质量损失。在最小质量损失的情况下，GPU加速达到7.6–15倍，CPU加速达到42.3–75.7倍。

---

我们还确认了PLAID在域外环境中的良好表现，正如LoTTE“pooled”数据集上的结果所展示的。在表5中，我们可以看到，在𝑘 = 1000时，PLAID ColBERTv2在GPU上比原始ColBERTv2快2.5倍，在CPU上快9.2倍；此外，这一设置下的质量实际上优于原始ColBERTv2。在一定的质量损失下，PLAID ColBERTv2可以实现GPU加速3.8–7.3倍，CPU加速23.2–42.5倍。请注意，由于LoTTE的平均段落长度约为MS MARCO v1的2倍，PLAID ColBERTv2在LoTTE上实现的CPU延迟比在MS MARCO v1上更大。

---

最后，表6显示PLAID ColBERTv2在MS MARCO v2上的有效扩展能力。MS MARCO v2是一个具有138M段落和9.4B词汇的大规模数据集（约为MS MARCO v1的16倍）。延续在其他数据集上观察到的趋势，我们发现PLAID ColBERTv2在CPU上比原始ColBERTv2快20.8倍，而质量在100段落之内没有损失。当𝑘 = 1000时，我们发现原始ColBERTv2和PLAID ColBERTv2在GPU上都出现了内存不足的问题；我们认为可以通过实现自定义的无填充MaxSim内核来解决这一问题，详见§4.5。

## 5.3. 消融分析

图6展示了对PLAID的性能改进进行消融分析的结果，适用于GPU和CPU执行。我们的测量数据来自于对500个MS MARCO v1查询的随机样本的评估（这会导致与表3中报告的绝对数值有些微差异）。我们将原始ColBERTv2视为基线，然后添加不带剪枝的质心交互阶段（图5中的第3阶段），接着是带有质心剪枝的质心交互阶段（图5中的第2阶段），最后是§4.5中描述的优化内核。在适用的情况下，我们使用表2中描述的𝑘 = 1000设置的超参数（即最保守的设置）。

---

我们发现，评分流程的算法改进和实现优化都是PLAID性能的关键。特别是，仅质心交互阶段就在GPU上实现了5.2倍的加速，在CPU上实现了8.6倍的加速，而添加实现优化后，GPU和CPU上分别进一步加速1.3倍和4.9倍。仅在CPU上启用优化的C++内核而不进行质心交互（未在图6中显示）与完整的PLAID相比，只有3倍的端到端加速，而完整PLAID则达到42.4倍的加速。 

## 5.4. 可扩展性

我们评估了PLAID在数据集规模和并行度（CPU上的线程数）方面的可扩展性。

---

首先，图7展示了我们测量的每个基准数据集的端到端PLAID ColBERTv2延迟与数据集大小（按嵌入数量衡量）的关系。尽管不同数据集的延迟不一定具有直接的可比性（例如，由于段落长度不同），但我们仍然试图从图中分析总体趋势。我们发现，通常PLAID ColBERTv2的延迟似乎随着数据集大小的平方根而增长。这可以直观地理解为，ColBERTv2设置质心的数量与嵌入数量的平方根成比例，并且候选生成的开销与分区数量成反比。

---

接下来，图8展示了PLAID ColBERTv2在不同可用CPU线程数下的延迟，并对不同的$k$值$\{10,100,1000\}$进行测试。我们对500个MS MARCO v1查询的随机样本进行了评估以获得延迟测量。我们观察到PLAID能够利用额外的线程；特别是，当$k=1000$时，使用16个线程执行的速度比单线程执行提高了$4.9\times$。尽管PLAID未能实现完美的线性扩展，我们推测可能的解释包括：现有的vanilla ColBERTv2候选生成步骤中仍存在一些效率低下的地方（本工作中我们未对其进行底层优化），或由于段落长度不均匀导致的线程之间负载不平衡。我们将更深入的性能分析和潜在解决方案留待未来研究。

# 6. 结论

在本研究中，我们提出了PLAID，一个高效的晚交互引擎，通过积极且低成本地过滤候选段落来加速检索。我们展示了仅使用ColBERTv2质心的检索在召回率方面几乎可以与vanilla ColBERTv2媲美，并且质心相关性分数的分布偏向于较低的得分。基于这些见解，我们引入了质心交互技术，并将其整合到PLAID ColBERTv2评分流程的多个阶段。我们还描述了PLAID的高度优化实现，其中包括无填充MaxSim和残差解压操作的自定义内核。在多个IR基准上的评估表明，与vanilla ColBERTv2相比，PLAID ColBERTv2在GPU上实现了2.5–6.8×的加速，在CPU上达到了9.2–45×的加速，并且几乎没有质量损失，同时能够有效扩展到包含1.4亿段落的数据集。

## SPLATE: 稀疏延迟交互检索

### 摘要

在神经信息检索领域，ColBERT引入的延迟交互范式在许多基准测试中提供了令人信服的效果与效率的平衡。高效的延迟交互检索基于优化的多步策略，其中近似搜索首先识别出一组候选文档，然后进行精确的重排序。在本工作中，我们介绍了SPLATE，这是ColBERTv2模型的一个简单且轻量级的适配版本，它通过学习一个“MLM适配器”，将其冻结的词嵌入映射到一个稀疏词汇空间，并使用部分学习的SPLADE模块。这使得我们能够在延迟交互管道中使用传统的稀疏检索技术进行候选生成步骤，特别适合在CPU环境中运行ColBERT。我们的SPLATE ColBERTv2管道通过重排序50个文档，实现了与PLAID ColBERTv2引擎相同的效果，这些文档可以在10毫秒内检索到。

# 1 引言

在基于预训练语言模型（PLMs）的神经检索模型领域中，ColBERT模型引入的延迟交互范式在许多基准测试中提供了最先进的结果。ColBERT及其变体[11,12,21,25,33,38,45,48]具有许多良好的特性，从可解释性[8,46]到鲁棒性[10,26,47,49]。基于文档和查询的细粒度交互机制，使用词级别的密集向量表示，缓解了单向量模型（如DPR[15]）的固有局限性。由于其MaxSim公式，延迟交互检索需要一个专门的多步搜索管道。与此同时，学习稀疏检索[30]作为一种新范式出现，旨在将传统搜索基础设施与PLMs相结合。特别是SPLADE模型[6,7,9]展示了强大的领域内和零样本能力，且成本仅为延迟交互方法的一小部分——无论是在内存占用还是搜索延迟方面[18,19,34,35]。

在本工作中，我们在这两条研究线之间进行了类比，并展示了如何简单地通过一个轻量级的SPLADE模块“适配”ColBERTv2的冻结表示，从而有效地将查询和文档映射到稀疏词汇空间。基于这一想法，我们引入了SPLATE——即稀疏延迟交互——作为延迟交互管道的替代近似评分方法。与PLAID[37]等优化引擎不同，我们的方法依赖于传统的稀疏技术，使其特别适合在单CPU环境中运行ColBERT。

# 2 相关工作

**高效的延迟交互检索**  

延迟交互检索是一种强大的范式，但需要复杂的工程来实现高效扩展。具体来说，它采用了一种多步管道，其中基于近似分数检索出初始的候选文档集[16]。虽然它类似于传统的信息检索中的“检索-重排序”管道，但其根本区别在于两个步骤使用相同的（PLM）模型${ }^{1}$。与交叉编码器相比，延迟交互模型的优势在于它们允许离线预计算文档表示，从而在理论上提高了效率。然而，这需要存储大量密集词表示索引作为代价。因此，ColBERT引擎的各种优化方法被提出[5,12,20,23,27,29,33,37,38,41,43]。ColBERTv2[38]通过引入残差压缩来减少延迟交互方法的空间占用，从而改进了原始ColBERT。然而，搜索速度仍然是一个瓶颈，主要是由于需要精确重排序的候选文档数量庞大（> 10k）[27]。Santhanam等人指出了ColBERTv2管道在搜索速度方面的主要瓶颈，并提出了PLAID[37]，这是一种新的优化延迟交互管道，可以在不影响ColBERTv2效果的情况下大幅减少候选段落数量。特别是，PLAID的候选生成基于三个步骤，利用中心点交互和中心点剪枝——模拟传统的词袋（BoW）检索——以及专用的CUDA内核。它减少了需要重排序的候选文档数量，大大减轻了后续步骤（索引查找、解压缩和评分）的负担。

---

**混合模型**  

多项工作已经发现不同神经排序模型学习到的表示之间的相似性。例如，UNIFIER[40]通过共享中间Transformer层，联合学习密集和稀疏的单向量双编码器。同样，BGE-M3嵌入模型[3]可以无差别地执行密集、多向量和稀疏检索。SparseEmbed[17]通过借鉴ColBERT和COIL[11]的思想，将SPLADE扩展到密集上下文嵌入。SLIM[22]对ColBERT进行适配，使其能够在类似SPLADE的表示上执行延迟交互，从而与传统搜索技术完全兼容。Ram等人[36]表明，通过掩码语言建模（MLM）头将密集双编码器的表示映射到词汇空间，也可以用于解释目的。

# 3 方法

SPLATE的灵感来源于两个核心思想：(1) PLAID[37]从传统的词袋（BoW）检索中汲取灵感，以优化延迟交互管道；(2) 密集嵌入似乎可以映射到词汇空间[36]。我们并未提出一种新的独立模型，而是展示了如何通过SPLATE在稀疏和密集模型之间架起桥梁，以近似延迟交互检索中的候选生成步骤。

---

**适配表示**  

SPLATE基于稀疏和密集信息检索（IR）模型学习到的表示之间的相似性。例如，Ram等人[36]表明，通过MLM头将密集双编码器的表示映射到词汇空间可以生成有意义的词袋表示。我们在此基础上进一步假设，可以从冻结的密集IR模型嵌入中以类似SPLADE的方式推导或至少适配出有效的稀疏模型。因此，我们提出在冻结的ColBERT模型之上“分支”一个MLM头。

---

**SPLATE**  

给定输入查询或文档$t$的ColBERT上下文嵌入$\left(h_{i}\right)_{i \in t}$，我们可以通过线性映射变换后的表示回词汇空间来定义一个简单的“适配”MLM头。受适配器模块[14,32]的启发，SPLATE通过学习一个简单的两层MLP来适配冻结的表示$\left(h_{i}\right)_{i \in t}$，其输出在“MLM”词汇投影之前以残差方式重新组合：
$$
\begin{equation*}
w_{i v}=\left(h_{i}+M L P_{\theta}\left(h_{i}\right)\right)^{T} E_{v}+b_{v} \tag{1}
\end{equation*}
$$

其中，$w_{i}$对应于词汇$\mathcal{V}$中词元$t_{i}$的未归一化对数概率分布，$E_{v}$是词元$v$的（Col）BERT输入嵌入，$b_{v}$是词元级别的偏置。残差保证了接近恒等的初始化，从而使训练稳定[14]。然后，我们可以如下推导稀疏的SPLADE向量：

$$
\begin{equation*}
w_{v}=\max _{i \in t} \log \left(1+\operatorname{ReLU}\left(w_{i v}\right)\right), \quad v \in\{1, \ldots,|\mathcal{V}|\} \tag{2}
\end{equation*}
$$

---

我们随后基于推导出的SPLADE向量，通过蒸馏训练MLM头的参数$(\boldsymbol{\theta}, \boldsymbol{b})$，以复现ColBERT的分数——见第4节。我们的方法非常轻量，因为ColBERT骨干模型完全冻结，包括（绑定的）投影层$E$。在我们的默认设置中，MLP首先将表示降维一半，然后将其投影回原始维度。这对应于一个潜在维度为$768 / 2=384$——早期实验表明，这一超参数的选择并不关键——并且仅包含大约0.6M的可训练参数（图1（左）中的黄色块）。

• 图1：（左）SPLATE依赖于相同的表示$\left(h_{i}\right)_{i \in t}$，通过SPLADE学习稀疏词袋（候选生成）并计算延迟交互（重排序）。（右）推理：SPLATE ColBERTv2将查询词元的表示映射到稀疏向量，用于从预计算的稀疏索引中检索$k$个文档（R设置）。在端到端（e2e）设置中，表示从ColBERT索引中收集，以使用MaxSim对候选文档进行精确重排序。

---

**延迟交互的高效候选生成**  
通过使用SPLADE模块适配ColBERT的冻结密集表示，SPLATE旨在通过高效的稀疏点积来近似延迟交互评分。因此，相同的表示$\left(h_{i}\right)_{i \in t}$可以在检索（SPLATE模块）和重排序（ColBERT的MaxSim）场景中发挥作用——在查询和文档端仅需一次Transformer推理步骤。这使得在延迟检索管道（如PLAID）中，可以用传统的稀疏检索替换现有的候选生成步骤，从而高效地为ColBERT提供需要重排序的文档。因此，SPLATE本身并不是一个模型，而是通过架起稀疏和密集模型之间的桥梁，为延迟阶段管道提供了一种替代实现。然而，SPLATE在多个方面与PLAID不同：

- 虽然PLAID通过ColBERTv2的中心点映射隐式推导出稀疏词袋表示，但SPLATE通过将伪MLM头适配到ColBERT的冻结表示，显式地学习这些表示。近似步骤从“工程化”变为监督式学习。
- 候选生成可以受益于倒排索引和查询处理技术（如MaxScore[44]或WAND[2]）的长期效率，使得端到端的ColBERT更加“CPU友好”——见表1。
- 它更具可控性，并可以直接适用于所有最近针对学习稀疏模型的优化[18,19]。
- ColBERT的管道变得更加可解释，因为SPLATE的候选生成直接在词汇空间中操作——而不是将文档表示为轻量级的中心点词袋——见表3中的示例。

---

尽管如此，SPLATE需要对适配器模块的参数进行额外的轻量级训练。它还需要对SPLATE的稀疏文档向量进行索引，因此会增加少量的内存占用开销${ }^{2}$。此外，需要注意的是，像BGE-M3[3]这样的混合方法——可以输出稀疏和多向量表示——理论上可以用于延迟交互管道。然而，SPLATE直接优化以近似ColBERTv2，我们将联合训练候选生成和重排序模块的研究留给未来的工作。

# 4 实验

**设置**  

我们使用ColBERTv2[38]的权重初始化SPLATE，并保持其冻结。我们依赖top$-k_{q, d}$池化来分别获取查询和文档的词袋（BoW）SPLADE表示${ }^{3}$。我们在MS MARCO段落数据集[1]上训练MLM参数$(\boldsymbol{\theta}, \boldsymbol{b})$，同时使用蒸馏和硬负采样。具体来说，我们基于marginMSE[13]和KLDiv[24]损失的加权组合对ColBERTv2的分数进行蒸馏，训练3个epoch。我们将批量大小设置为24，并为每个查询从ColBERTv2的top-1000中选择20个硬负样本。通过将ColBERTv2同时作为教师和硬负样本的来源，SPLATE旨在通过稀疏检索近似延迟交互。SPLATE模型使用SPLADE代码库在2块32GB内存的Tesla V100 GPU上训练，耗时不到两小时${ }^{4}$。SPLATE可以作为独立的稀疏检索器（R）进行评估，但更有趣的是在端到端延迟交互管道（e2e）中进行评估，其中它为ColBERTv2提供候选文档进行重排序（见图1（右）$)^{5}$。对于前者，我们依赖PISA引擎[28]进行带有block-max WAND的稀疏检索，并以平均响应时间（MRT）提供延迟测量，即在使用$\operatorname{Intel}(\mathrm{R}) \mathrm{Xeon}(\mathrm{R})$ Gold 6338 @ 2.00 GHz CPU单核的情况下在MS MARCO数据集上测量的平均搜索延迟。对于后者，我们使用ColBERT库${ }^{6}$进行实时重排序。需要注意的是，与预计算文档词嵌入的管道相比，使用ColBERT进行朴素重排序是次优的。我们将端到端延迟测量留给未来的工作，但我们认为将SPLATE集成到ColBERT的管道（如PLAID）中应该是无缝的，因为它只需要修改候选生成步骤。我们在MS MARCO开发集和TREC DL19查询[4]（领域内）上评估模型，并在13个现成的BEIR数据集[42]以及LoTTE基准[38]的测试池化搜索数据集上提供领域外评估。

---

以下实验研究了三个不同的研究问题：(1) SPLATE向量的稀疏性如何影响延迟和重排序性能？(2) 与ColBERTv2相比，SPLATE候选生成的准确性如何？(3) 在领域内和领域外场景中，它的整体表现如何？

---

**延迟结果**  

表1报告了在MS MARCO数据集上领域内的结果，包括仅检索（R）和端到端（e2e）设置。总体而言，结果表明，可以通过对ColBERTv2的词嵌入进行轻量级的残差适配，将其“转换”为有效的SPLADE模型。我们考虑了使用不同池化大小$\left(k_{q}, k_{d}\right)$训练的多个SPLATE模型——这些参数控制查询和文档表示的大小。我们观察到SPLADE的标准效果-效率权衡，池化大小同时影响性能和平均延迟。这些结果表明，通过选择适当的池化大小，可以轻松控制候选生成步骤的延迟。然而，在使用ColBERTv2进行重排序后，所有模型的表现都相当，这在效率角度上非常有趣，因为可以使用非常轻量级的模型以低成本提供候选文档（例如，低至2.9毫秒的平均响应时间），同时实现与原始ColBERTv2相当的性能（见表2）。作为对比，PLAID[37]报告的端到端延迟（单CPU核心，$k=10$的较不保守设置）在MS MARCO上约为186毫秒。鉴于候选生成占整个管道的约三分之二[37]，SPLATE为在单CPU环境中运行ColBERT提供了一个有趣的替代方案。

- 表2：使用$\left(k_{q}, k_{d}\right)=(10,100)$和$k=50$评估SPLATE。${ }^{\text {abcde }}$表示在配对$t$检验（$p$值$=0.01$）和Bonferroni校正下，相较于对应行的显著改进（MS MARCO开发集和DL19）。PLAID ColBERTv2[37]（$k=1000$）报告了$\operatorname{dev}$ LoTTE* S@5。

---

**近似质量**  

为了评估SPLATE近似的质量，我们将PLAID ColBERTv2检索的top-$k$段落与SPLATE（R）检索的段落进行比较。在图2中，我们报告了在MS MARCO上，SPLATE的top-$k^{\prime}$中同时出现在ColBERTv2的top-$k$文档中的平均比例$R(k)$，其中$k \in\{10,100\}$，$k^{\prime}=i \times k, i \in\{1, \ldots, 5\}$。当$k=10$时，对于所有$\left(k_{q}, k_{d}\right)$水平，SPLATE能够在其top-50（$i=5$）中检索到超过90%的ColBERTv2文档。这解释了SPLATE通过重排序少量文档（例如仅50个）完全恢复ColBERT性能的能力。此外，我们观察到，当$k$较高时，高效模型（即较低的$\left(k_{q}, k_{d}\right)$）的近似质量有所下降。

---

图3进一步报告了SPLATE（e2e）在领域外的性能。我们观察到了类似的趋势，即增加重排序的文档数量$k$以及$\left(k_{q}, k_{d}\right)$可以带来更好的泛化能力。总体而言，仅重排序50个文档在所有设置下都提供了良好的权衡——这与之前的发现[27,37]相呼应。然而，最高效的场景$\left(\left(k_{q}, k_{d}\right)=(5,50), k=10\right)$仍然取得了令人印象深刻的结果：在MS MARCO开发集上达到38.4 MRR@10（未显示），在LoTTE上达到$70.0 S @ 5$（图3中的紫色线）。

---

**总体结果**  
最后，表2将SPLATE ColBERTv2与参考点ColBERTv2[38]和PLAID ColBERTv2（$k=1000$）[37]进行了比较，包括仅检索（R）和端到端（e2e）设置。我们还包含了SPLADE++[7]以及混合方法SparseEmbed[17]和SLIM++[22]的结果——尽管它们与SPLATE并不完全可比。虽然SparseEmbed和SLIM引入了新模型，但SPLATE提出了ColBERT延迟检索管道的替代实现。我们进一步报告了两个基线，分别是用BM25（或SPLADE++）检索文档并用ColBERTv2进行重排序（分别为BM25 $\gg \mathrm{C}$和$\mathrm{S} \gg \mathrm{C}$，$k=50$）。需要注意的是，我们预计SPLATE的表现介于两者之间，因为BM25 $\gg$ C依赖于效果较差的检索器，而$\mathrm{S} \gg \mathrm{C}$与SPLATE有根本区别，因为它基于两个不同的模型。具体来说，它需要在推理时将查询输入到PLM两次。总体而言，SPLATE（R）作为独立的检索器是有效的（例如，在MS MARCO开发集上达到接近37的MRR@10）。另一方面，SPLATE（e2e）在MS MARCO、BEIR和LoTTE上的表现与ColBERTv2和PLAID相当。此外，我们使用RANGER[39]对PLAID在13个BEIR数据集上进行了元分析，发现10个数据集上没有统计差异，1个（或2个）数据集上存在统计改进（或损失）。最后，我们在表3中提供了MS MARCO开发集中查询的预测词袋示例——突出了基于SPLATE的ColBERT管道中检索步骤的可解释性。

# 5 结论

我们提出了SPLATE，一种新的轻量级候选生成技术，简化了ColBERTv2在延迟交互检索中的候选生成。SPLATE通过适配ColBERTv2的冻结嵌入，使用SPLADE进行高效的稀疏检索。在端到端评估中，SPLATE实现的ColBERTv2在多个基准测试中通过重排序少量文档，表现与ColBERTv2和PLAID相当。候选生成步骤基于稀疏词项的特性，使其在单CPU环境中特别具有吸引力。除了优化延迟交互检索外，我们的工作还为深入研究不同架构训练的表示之间的联系开辟了道路。
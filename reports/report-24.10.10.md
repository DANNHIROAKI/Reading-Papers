# 关于最邻近查询

## 1. ANN算法的一个简单分类总结

> ### 1.1. 基于哈希的方法
>
> > 💡基本特征：将数据点转换为低维表示$\to$每个数据点可以用哈希码表示
> >
> > #### 1.1.1. LSH: 与数据无关的哈希方法(有理论保证)
> >
> > > :one:$\text{LSH}$原理
> > >
> > > |            输入点$e_i,e_j$            | $\xrightarrow{局部敏感哈希函数}$ |            映射结果            |
> > > | :-----------------------------------: | :------------------------------: | :----------------------------: |
> > > | 相似度高，即$\text{dist}(e_i,e_j)<r$  | $\xrightarrow{局部敏感哈希函数}$ | 高概率被映射到**相同哈希码**上 |
> > > | 相似度低，即$\text{dist}(e_i,e_j)>cr$ | $\xrightarrow{局部敏感哈希函数}$ | 高概率被映射到**不同哈希码**上 |
> > >
> > > - 需满足假设：对于$e_i,e_j$，哈希函数的选择是**随机**和**独立**的，见[$\text{CIKM'13}$](https://doi.org/10.1145/2505515.2505765)
> > >
> > > :two:$\text{LSH}$函数：影响性能的关键
> > >
> > > 1. 一些常用的$\text{LSH}$函数：
> > >
> > >   - 针对欧几里得空间的：[$\text{SCG'04}$](https://doi.org/10.1145/997817.997857) / [$\text{FOCS'06}$](https://doi.org/10.1109/FOCS.2006.49) / [$\text{SODA'14}$](https://dl.acm.org/doi/abs/10.5555/2634074.2634150) / [$\text{WADS'07}$](https://dl.acm.org/doi/10.5555/2394893.2394899) / [$\text{STOC'15}$](https://doi.org/10.1145/2746539.2746553)
> > >    - 基于随机线性投影的：[$\text{SCG'04}$](https://doi.org/10.1145/997817.997857) / [$\text{VLDB'99}$](https://dl.acm.org/doi/10.5555/645925.671516) / [$\text{SODA'06}$](https://dl.acm.org/doi/10.5555/1109557.1109688) / [$\text{SIGMOD'09}$](https://doi.org/10.1145/1559845.1559905)
> > > 2. $\text{LSH}$函数的连接：
> > >
> > >    - 是啥：将多个哈希函数首尾相连，降低不相似点的碰撞概率
> > >   - 弊端：增加了哈希表数量(时空开销)$+$也可能减少相似点碰撞概率
> > >
> > > :three:$\text{LSH}$函数及$\text{LSH}$方法的研究
> > >
> > > 1. 动态$\text{LSH}$函数
> > >    - 静态$\text{LSH}$原理：处理所有点构建哈希表$\to$哈希表一构建就不变$\to$执行查询
> > >   - 静态$\text{LSH}$弊端：哈希表随机构建，会导致**与查询点很近的点**与**查询点**不碰撞(被忽略)
> > >    - 动态$\text{LSH}$：查询时**动态地**计数和调整碰撞情况，[$\text{VLDB'07}$](https://doi.org/10.14778/3137765.3137836) / [$\text{SIGMOD'07}$](https://doi.org/10.1145/2213836.2213898) / [$\text{SIGMOD'16}$](https://doi.org/10.1145/2882903.2882930)  
> > > 2. 启发式寻桶
> > >    - 咋办：通过启发式方法(靠直觉)检查查询点附近的其它桶，[$\text{VLDB'07}$](https://dl.acm.org/doi/10.5555/1325851.1325958) / [$\text{MM'08}$](https://doi.org/10.1145/1459359.1459388) / [$\text{VLDB'07}$](https://doi.org/10.14778/3137765.3137836) 
> > >   - 好处：提高搜索质量同时，不增加哈希表数量(相比连接$\text{LSH}$函数) 
> >
> > #### 1.1.2. L2H: 数据分布$\xrightarrow{生成}$特定哈希(无理论保证)
> >
> > > :one:原理：
> > >
> > > 1. 学习原有数据的分布从而构建哈希函数
> > >    - 大多哈希方法要求：哈希码平衡(每个桶均匀分布)$+$无相关性(不同哈希码间无依赖)
> > > 2. 经过哈希后，原始空间中点的近似关系，在哈希编码空间得到最大程度保留
> > >
> > > :two:类型：
> > >
> > > | $\textbf{Type}$  | $\textbf{Pub.}$                                              |
> > > | :--------------: | ------------------------------------------------------------ |
> > > | 成对相似性保持类 | [$\text{ICML'11}$]( https://dl.acm.org/doi/10.5555/3104482.3104483) / [$\text{NIPS'08}$]( https://dl.acm.org/doi/10.5555/2981780.2981999) / [$\text{NIPS'14}$](https://dl.acm.org/doi/10.5555/2969033.2969208) / [$\text{KDD'10}$](https://doi.org/10.1145/1835804.1835946) / [$\text{CVPR'13}$](https://doi.org/10.1109/CVPR.2013.64) |
> > > | 多重相似性保持类 | [$\text{ICCV'13}$]( https://doi.org/10.1109/ICCV.2013.377) / [$\text{MM'13}$](https://doi.org/10.1145/2502081.2502100) |
> > > | 隐式相似性保持类 | [$\text{CVPR'11}$]( https://doi.org/10.1109/CVPR.2011.5995709) / [$\text{ICCV'13}$]( https://doi.org/10.1109/ICCV.2013.377) |
> > > |      量化类      | [$\text{TPAMI'11}$](https://doi.org/10.1109/TPAMI.2010.57) / [$\text{TPAMI'13}$](https://doi.org/10.1109/TPAMI.2012.193) / [$\text{NIPS'12}$](https://dl.acm.org/doi/10.5555/2999134.2999318) |
> > >
> > > :three:关于量化类方法：最有效的$\text{L2H}$方法
> > >
> > > 1. 核心：最小化量化失真 (及 $\min\displaystyle\sum$ 每个数据点$\xleftrightarrow{ }$其最邻近指的差)
> > >
> > > 2. $\text{PQ(Product Quantization)}$算法，[$\text{TPAMI'11}$](https://doi.org/10.1109/TPAMI.2010.57) / [$\text{TIT'06}$](https://doi.org/10.1109/18.720541)($\text{Quantization}$) 
> > >
> > >    - 原理：$\text{M}$维原始向量$\xrightarrow{分割}$$\text{N}$个$\cfrac{\text{M}}{\text{N}}$维子向量$\xrightarrow[(寻求每个子向量最近的质心\text{Index})]{向量量化}$$\text{N}$维短代码(向量)
> > >
> > >    - 改善途径：
> > >
> > >      |      $\textbf{Type}$      | $\textbf{Pub.}$                                              |
> > >      | :-----------------------: | ------------------------------------------------------------ |
> > >      | 改善$\text{PQ}$的索引步骤 | [$\text{TPAMI'13}$](https://doi.org/10.1109/TPAMI.2013.240) / [$\text{CVPR'13}$](https://doi.org/10.1109/CVPR.2013.388) / [$\text{CVPR'15}$](https://doi.org/10.1109/CVPR.2015.7299052) / [$\text{ICCV'13}$](https://doi.org/10.1109/ICCV.2013.424) / [$\text{CVPR'14}$](https://doi.org/10.1109/CVPR.2014.298) |
> > >      | 改善$\text{PQ}$的搜索步骤 | [$\text{CVPR'14}$](https://doi.org/10.1109/CVPR.2014.298) / [$\text{CVPR'12}$](https://doi.org/10.1109/CVPR.2012.6248038) / [$\text{ICASSP'11}$](https://doi.org/10.48550/arXiv.1102.3828) / [$\text{CVPR'16}$](https://doi.org/10.1109/CVPR.2016.221) |
> > >
> > >    - 扩展$\text{PQ}$算法：优化$\text{PQ}$([$\text{CVPR'14}$](https://doi.org/10.1109/CVPR.2014.298))，加性量化([$\text{CVPR'14}$](https://doi.org/10.1109/CVPR.2014.124))，复合量化([$\text{ICML'14}$](https://dl.acm.org/doi/abs/10.5555/3044805.3044986))
> > >
> > > :four:基于神经网络的(无监督)哈希方法
> > >
> > > 1. Semantic哈希：
> > >
> > >    - 原理：构建多层$\text{RBM(Restricted Boltzmann Machines)}$
> > >    - 目标：为文本(文档)学习紧凑的二进制代码
> > >
> > > 2. 如何学习二进制代码
> > >
> > >    - 通过生成二进制代码：
> > >
> > >      |   $\textbf{Type}$    | $\textbf{Pub.}$                                              |
> > >      | :------------------: | ------------------------------------------------------------ |
> > >      |   设计符号激活层以   | [$\text{CVPR'16}$](https://doi.org/10.1109/CVPR.2016.133) / [$\text{CVPR'15}$](https://doi.org/10.1109/CVPR.2015.7298862) / [$\text{IJCAI'17}$](https://doi.org/10.24963/ijcai.2017/429) / [$\text{TIP'17}$](https://doi.org/10.1109/TIP.2017.2678163) |
> > >      | 提出了约束倒数第二层 | [$\text{ECCV'16}$](https://doi.org/10.48550/arXiv.1607.05140) |
> > >
> > >    - 通过重构数据：使用自编码器作为隐藏层，[$\text{CVPR'15}$](https://doi.org/10.48550/arXiv.1501.00756) / [$\text{IPTA'17}$](https://doi.org/10.1109/IPTA.2016.7821007) 
> > >
> > > 3. 二进制约束的优化问题
> > >
> > >    - 成因：必须从哈希函数的输出获得二进制代码，是一个$\text{NP-Hard}$问题
> > >    - 优化：由$\text{relaxation+rounding}$法使二进制代码次优，如离散优化[$\text{NIPS'14}$](https://dl.acm.org/doi/10.5555/2969033.2969208) / [$\text{TPAMI'18}$](https://doi.org/10.1109/TPAMI.2018.2789887) 
> > >
>
> ### 1.2. 基于划分的方法
>
> > 原理：将整个高维空间划分为多个不相交的区域，且默认查询点的最邻近在其所属**相同/相邻**区域
>
> ### 1.3. 基于图的方法
>
> > 原理：构建邻近图(数据结点/边对应邻近关系)，默认邻居的邻居也是邻居，迭代邻居以求最邻近

## 2. 关于LLM的一些想法

> :one:$\text{Text-to-SQL}$
>
> :two:利用$\text{

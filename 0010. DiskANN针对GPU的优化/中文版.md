### BANG: Billion-Scale Approximate Nearest Neighbor Search using a Single GPU  

# 0. Abstract

近似最近邻搜索（ANNS）是信息检索、模式识别、数据挖掘、图像处理等算法中常用的一个子程序。最近的研究表明，==基于图的ANNS算法在大数据集上比文献中提出的其他方法在实际应用中效率更高==。随着数据量和维度的不断增长，设计==可扩展的ANNS==技术变得越来越重要。为此，已有研究探索了利用GPU的高计算能力和能源效率来并行化基于图的ANNS。当前最先进的基于GPU的ANNS算法通常有两种方式：(i) 需要将索引图和数据完全存储在GPU内存中，或 (ii) 将数据划分为多个独立的小片段，每个片段可以放入GPU内存，并在GPU上对这些片段进行搜索。第一种方法由于GPU内存有限，无法处理大规模数据集，而第二种方法在处理大规模数据集时表现不佳，原因是低带宽的PCIe总线导致数据传输量过大。

---

在本文中，我们介绍了BANG，这是首个能够在==无法完全放入GPU内存的==十亿级数据集上高效运行的基于GPU的ANNS方法。BANG通过在GPU上使用压缩数据进行距离计算，同时将图保存在CPU上，从而在有限的GPU内存中实现对大规模图的高效ANNS。BANG结合了高度优化的GPU内核，并以并行的方式在GPU和CPU上分阶段运行，充分利用了它们各自的架构特点。此外，它通过重叠通信与计算，减少了通过PCIe总线在CPU和GPU之间的数据传输。我们在一台NVIDIA Ampere A100 GPU上，使用十个流行的ANN基准数据集对BANG进行了评估。BANG在大多数情况下都优于现有的最先进方法。特别是在十亿级数据集上，我们比竞争对手快得多，达到了比竞争方法高40到200倍的吞吐量，并在高召回率0.9的情况下实现了这一结果。我们将公开所有代码。

# 1. INTRODUCTION  

$k$最近邻搜索问题是要在多维数据集中找到与给定查询点最近的$k$个数据点。随着维度的增加，精确搜索方法变得越来越低效。为了在具有$n$个数据点、$d$维的数据集中评估查询点的精确$k$个最近邻，由于维度灾难的影响，必须检查所有$n$个数据点，这需要$O(n d)$的时间【25】。因此，在寻找最近邻时，通常使用==近似最近邻（ANN）搜索==，以减轻维度灾难，==牺牲少量的准确性来换取速度==。ANN搜索作为子程序被广泛应用于计算机视觉、文档检索和推荐系统等领域。这些应用需要在嵌入于多维空间的巨大数据集中进行搜索，数据集可能包含单词、图像和文档，其搜索查询通常是批处理的，因此需要高吞吐量。与传统的CPU相比，==GPU的大规模并行处理能力可以显著提高ANN搜索算法的吞吐量==。

基于图的ANNS算法【18, 26, 33】已被证明在处理大规模数据集时通常在实际应用中更为高效。然而，这些算法的GPU实现【22, 35, 47】要求==将图数据结构存储在GPU内存中==，这限制了它们处理大规模数据集的能力。即使是最新的GPU，如NVIDIA Ampere A100，拥有80GB的设备内存，也无法容纳所有的输入数据（包括图和数据点）。现有的解决方案，如通过GGNN【22】有效实现的==分片方法==，导致了高内存传输成本。此外，哈希和压缩技术，如SONG【47】和FAISS【28】展示的技术，通过降低数据维度或压缩向量，可以在单个GPU上管理大规模数据。然而，这些方法在处理大规模数据集并达到高召回率时可能存在局限性。此外，多GPU配置，如GGNN【22】使用八个GPU的实现，和其他需要多CPU的解决方案【14】，虽然可以提供解决方案，但伴随着巨大的硬件成本。因此，本文探讨了一个重要问题：==我们能否在不降低召回率的情况下，通过使用单个GPU来提高ANN搜索查询的吞吐量？==
## 2. The model

To describe the model, we adopt the terminology used in the literature. We assume that attributes are real valued; an example is a point in $\boldsymbol{R}^{n}$; a concept is a subset of $\boldsymbol{R}^{n}$. An example that belongs to a concept is labelled positive for the concept, and an example that lies outside the concept is labelled a negative example.

---

Given a set of labelled examples drawn from an unknown distribution $\mathcal{D}$ in $\boldsymbol{R}^{n}$, and labelled according to an unknown target concept the learning task is to find a hypothesis with low error. A hypothesis is a polynomial-time computable function. The error of a hypothesis $h$ with respect to the target concept is the probability that $h$ disagrees with the target function on a random example drawn from $\mathcal{D}$. Thus, if $h$ has error $\epsilon$, then the probability for a random $x$ that $h(x)$ disagrees with the target concept is at most $\epsilon$. So, given an error parameter $\epsilon$ and a confidence parameter $\delta$, with probability at least $1-\delta$, the algorithm has to find a concept that has error at most $\epsilon$ on $\mathcal{D}$ (Valiant, 1984).

---

The basic insight of the new model is the idea of robustness (implicit in earlier work). Intuitively, a concept is "robust" if it is immune to attribute noise. That is, modifying the attributes of an example by some bounded amount does not change its label. Another interpretation is that points with different labels are far apart. This is formalized below:

Definition 1. For any real number $\ell>0$, a concept $C$ in conjunction with a distribution $\mathcal{D}$ in $\boldsymbol{R}^{n}$, is said to be $\ell$-robust, if

$$
\mathrm{P}_{\mathcal{D}}(x \mid \exists y: \operatorname{label}(x) \neq \operatorname{label}(y),\|x-y\| \leq \ell)=0
$$

The norm $\|x-y\|$ is the Euclidean distance between $x$ and $y$. This can be replaced by other norms, but we use the Euclidean norm in this paper. The probability is over all points $x$ with the property that there is some point $y$ with a different label within a distance $\ell$. In other words, a concept is $\ell$-robust if there is zero probability of points being within $\ell$ of the boundary of the concept. The definition could be weakened by requiring only that the above probability should be negligible (e.g. $1 / 2^{n}$ ). When $\mathcal{D}$ is over a discrete subset of $\boldsymbol{R}^{n}$, then this has a simple interpretation. A ball of radius $\ell$ around any point $x$ of non-zero probability lies entirely on one side of the concept, i.e., every point in the ball has the same label as $x$. To avoid scaling issues, we usually consider only distributions whose support is (a subset of) the unit ball in $\boldsymbol{R}^{n}$, i.e., all examples given to the algorithm will have length at most 1 (alternatively, one could incorporate normalize the distance between examples by their length, but we find our definition more convenient). Given access to examples from a robust concept, and parameters $\epsilon, \delta$, a learning algorithm succeeds and is said to $(\epsilon, \delta)$-learn if, with probability at least $1-\delta$, it produces a hypothesis that is consistent with at least $1-\epsilon$ of the example distribution. Note that strictly speaking this is not PAC-learning since robustness restricts the example distribution.

---

In what follows, we present tools and algorithms for learning robust concepts. It is worth noting that "robustness" refers only to the target concept; it is not required of all concepts in the class.

### 2.1. Connection to existing models

The model is closely related to large margin classifiers used in Support Vector Machines (Bartlett \& Shawe-Taylor, 1998). Indeed, for the concept class of half-spaces, the robustness as defined here is exactly the largest possible margin of a correctly classifying half-space (with the normalization that all the examples are from the unit ball). In general, however, there is a subtle but important difference. Whereas in SVM's the margin is measured in the "lifted" space where concepts have been transformed to half-spaces, in our model we measure robustness in the space in which examples are presented to us (and hence the natural relationship with attribute noise). The robustness is also closely related to the parameter $\gamma$ used in the definition of the fat-shattering dimension (Kearns \& Schapire, 1994; Bartlett \& Shawe-Taylor, 1998), and once again coincides (up to a scaling factor) in the case of half-spaces.
## Appendix

证明：（定理 5.）我们基本上模仿了 VC 基本定理的证明。唯一不同的是，在该定理中，假定有一个与整个样本一致的假设。而在这里，我们只能假设有一个假设能正确地将样本的 $1-\epsilon / 4$ 部分进行分类。

---

如果一个假设在分布上的误差大于 $\epsilon$，我们就称它为坏假设。让 $A$ 成为存在一个糟糕的一致假设的事件，即在样本上误差小于 $\epsilon / 8$，而在分布上误差大于 $\epsilon$ 的假设。我们想证明事件 $A$ 的概率最多为 $\delta$。为此，我们将 $B$ 定义为：对于一个包含 $2 m$ 例子的序列，有一个概念在前 $m$ 上的误差小于 $\epsilon / 8$，而在剩余的 $m$ 上的误差大于 $\epsilon / 2$。

---

接下来我们观察 $\operatorname{Pr}(A) \leq 2 \cdot \operatorname{Pr}(B)$。这是因为

$$
\operatorname{Pr}(B) \geq \operatorname{Pr}(A \text { and } B)=\operatorname{Pr}(A) \cdot \operatorname{Pr}(B / A)
$$

给定 $A $的 $B $的概率，$\operatorname{Pr}(B / A)$ 是在分布上误差为 $epsilon$ 的假设在一组 $m$ 例子上误差至少为 $epsilon / 2$ 的概率。利用切比切夫不等式，后一种概率至少为 $1 / 2$。

---

为了完成证明，我们将限定 $B$ 的概率。固定任意一组 $2 m$ 例子，并考虑将它们随机分割成两个大小相等的集合 $S_{1}$ 和 $S_{2}$。让 $\hat{h}$ 成为一个假设，它至少在 $epsilon m / 2$ 的 $2 m$ 例子中与目标假设不一致。这就是导致 $B$ 事件的候选假设。

---

让 $X_{i}$, for $i=1, \ldots, m$ 表示 $\hat{h}$ 在 $S_{1}$ 中的第 i 个例子上出错的事件。那么 $E\left(X_{i}\right)=\epsilon / 4$。定义

$$
X=\sum_{i=1}^{m} X_{i} .
$$

那么 $E(X)=\epsilon m / 4$. 根据切尔诺夫不等式

$$
\operatorname{Pr}\left(X \leq \frac{\epsilon}{4}(1-c)\right) \leq e^{-\frac{\epsilon m c^{2}}{8}}
$$

也就是说

$$
\operatorname{Pr}\left(X \leq \frac{\epsilon}{8}\right) \leq e^{-\epsilon m / 32} .
$$

$2 m$ 例子集的独特假设总数最多为 $C(2 m, k)$。换句话说，这就是在 $\boldsymbol{R}^{k}$ 中使用 $\mathcal{C}$ 中的概念来分割 $2 m$ 个点的不同方法的数量。将所有假设相加，我们得到

$$
\operatorname{Pr}(B) \leq C(2 m, k) e^{-\epsilon m / 32} .
$$

对于定理中考虑的 $m$ 值，我们有 $\operatorname{Pr}(B)<\delta / 2$，因此 $\operatorname{Pr}(A)<\delta$ 是必需的。


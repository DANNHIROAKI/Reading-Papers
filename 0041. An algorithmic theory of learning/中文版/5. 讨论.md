## 5. Discussion

### 5.1. A robust model of categorization

本文研究的模型可以被视为人类学习的基本模型。在这个模型中，在处理的外层，有一层神经元产生对任何呈现刺激的随机概要。然后由学习算法处理这个概要。外层扮演了随机投影的角色。该模型的主要洞察是，即使是独立于任何特定概念和独立于样本（刺激）分布的随机概要，也能保持学习类别所需的基本元素。学习的容易程度和概要保持概念的程度取决于它们的鲁棒性——概念越鲁棒，所需的概要越短，学习越容易。在本节中，我们从认知和神经心理学的工作中探讨这个模型的预测如何成立。我们的模型超越了之前做出类似预测的模型，因为它提出了一个简单的生理机制。

---

我们模型的一个有趣预测是，学习更鲁棒的概念需要更少的例子。这个预测得到了许多心理学研究的支持(Glass, et al., 1979; Komatsu, 1992; Reed, 1982; Reed & Friedman, 1973; Rosch, 1978; Rosch et al., 1976)，特别是那些从家族相似性角度来看待概念形成的研究（关于其他主要观点的详细说明，参见(Komatsu, 1992; Rakinson & Oakes, 2003)）。家族相似性观点认为，人类形成的类别（概念类）是分层的(Reed, 1982)，有三个明确的层次，称为上位级、基本级和下位级。例如，对于哺乳动物这个上位类别，一些基本级类别是大象、狗、人类，而大象的下位类别则是非洲象和印度象。类似地，乐器这个上位类别下面有吉他、钢琴、鼓等基本级类别，而吉他下面有民谣吉他和钢弦吉他等下位类别。基本级类别被认为是最重要的，它们之间的界限最为清晰。用我们的术语来说，它们是最鲁棒的，我们预期它们更容易学习。正如Rosch et al. (1976)所指出的，"...基本级类别彼此之间最为区分，因此它们是我们最先学习的类别，也是语言中最重要的类别。"

---

人类如何形成类别的另一个相关理论基于原型的概念(Glass, et al., 1979; Komatsu, 1992)。这个理论的基本预测也可以从鲁棒性推导出来。原型代表了一个类别中最典型的成员。该理论认为，我们通过对类别中样本的定义特征（的子集）形成某种加权平均来抽象出一个类别的原型。随后的实例会与原型进行比较，如果它与原型有足够程度的相似性，就会被判断为该类别的成员。这解释了研究中发现的结果：当被要求列举一个类别的例子时，受试者一致地更早且更频繁地列出更接近原型的成员（例如，对于鸟类这个类别，麻雀和知更鸟比鸵鸟更经常被提到）Rosch (1978)。此外，当被要求分类时，发现更接近原型的例子分类更快。在人工生成类别的研究中也发现了类似的结果(Reed & Friedman, 1973)。

---

对于一个原型P，我们可以根据与P的距离在P的类别中定义一系列嵌套的概念。那么最内层概念的成员与P非常相似，下一个概念的成员变化稍大，随着概念与P的最大距离增加，变化也在增加。换句话说，最内层概念在将类别与非成员（家族类别的）对象区分开来方面是最鲁棒的，随着向外移动，鲁棒性降低。本文的论证意味着内层概念比外层概念更容易学习和标记。这正是在前述研究中观察到的情况。

---

在我们的模型中，当机体呈现给定刺激时，会捕获其特征的随机概要。当观察到同一家族的另一个成员时，会抽象出另一个特征概要。来自同一"家族"的刺激之间共享的特征会随着时间形成一组具有类似特征的概要。这些类似的特征会产生一个原型家族成员（比如鸟类家族中的知更鸟），因为它体现了许多在这些"随机概要"中出现概率更大的特征，这些特征在家族中更常见（小型、有羽毛、会飞），而不是其他可能不典型的特征（大型、不会飞的鸵鸟或没有羽毛的企鹅）。

---

我们的模型还解决了另一个问题，即需要区分感知类别（红色、方形、响亮）和概念类别（甜点与沙拉或善与恶）。这个问题在当前的分类研究中很突出(Mandler, 2003)。虽然我们提到的例子（鸟类、大象和吉他）可以被描述为感知（基于物体的）类别，但值得注意的是我们的模型也适用于概念类别。这个想法是，除了物理特征外，抽象特征（最终也是刺激的函数，例如"深情"可能包括钢弦吉他和萨克斯管）也被随机概要保留。我们模型的预测类似于家族相似性观点；后者已成功地超越了基于物体的类别，扩展到情绪和性格特征等心理现象(Komatsu, 1992)。在我们模型的外层机制中，不需要分类的单独学习系统。

---

同样，当前模型也涉及了一个广泛的神经心理学问题：是否有必要提出多系统（即各种脑区）模型，而不是单系统模型（一般大脑处理）来解释一方面的物体识别和另一方面的分类(Knowlton, 1999)。我们将我们的模型视为一个提供学习"外层"一般生理机制的单系统模型。因此，我们认为这个模型部分回应了"开发形式化的单系统和多系统分类数学模型，收集使用正常和脑损伤人群的丰富参数数据集，并测试各自模型定量解释数据的能力"的呼吁(Nosofsky & Zaki, 1969)。

### 5.2. Open problems

在离散设置中，\ell-鲁棒概念是指即使改变其属性的\ell比例，正例仍保持其标签的概念。计算学习理论中一个重要的开放问题是在没有成员查询的情况下从均匀分布中学习DNF公式。这个概念类可以被视为具有鲁棒性1/\sqrt{n}的半空间的交集。如果存在一个在n和1/\ell的多项式时间内学习DNF公式的算法，这将解决在没有成员查询的情况下学习DNF公式的问题。

---

我们已经看到鲁棒性如何降低一些重要概念类的学习复杂性。我们以以下问题结束：对于哪些概念类，鲁棒性不会降低学习复杂性？特别是，学习鲁棒多项式阈值函数的复杂性是什么？


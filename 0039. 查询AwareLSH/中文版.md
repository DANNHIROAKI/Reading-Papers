# 查询感知的局部敏感哈希用于近似最近邻搜索

#### 摘要

局部敏感哈希（Locality-Sensitive Hashing, LSH）及其变体是高维欧几里得空间中解决$c$-近似最近邻（$c$-Approximate Nearest Neighbor, c-ANN）搜索问题的著名索引方案。传统上，LSH函数的构建是以查询无关的方式进行的，即在任何查询到达之前就已经划分了桶。然而，靠近查询的对象可能会被划分到不同的桶中，这是不理想的。由于使用了查询无关的桶划分，当前最先进的外部存储LSH方案，即C2LSH和LSB-Forest，仅适用于整数近似比$c \geq 2$的情况。

---

在本文中，我们引入了一种新的查询感知桶划分概念，它使用给定的查询作为桶划分的“锚点”。相应地，查询感知的LSH函数是一种结合了查询感知桶划分的随机投影，它消除了传统查询无关LSH函数所需的随机偏移。值得注意的是，查询感知桶划分可以很容易地实现，从而保证查询性能。我们提出了一种名为QALSH的新型查询感知LSH方案，用于外部存储中的$c$-ANN搜索。我们的理论研究表明，QALSH在查询质量上具有保证。使用查询感知的LSH函数使得QALSH能够适用于任何近似比$c>1$的情况。大量实验表明，QALSH在高维空间中尤其优于C2LSH和LSB-Forest。具体来说，通过使用$c<2$的比率，QALSH可以实现更好的查询质量。

## 1. 引言

欧几里得空间中的最近邻（Nearest Neighbor, NN）搜索问题在图像和视频数据库、信息检索以及数据挖掘等领域有着广泛的应用。在许多应用中，数据对象通常表示为欧几里得向量（或点）。例如，在图像搜索应用中，图像可以自然地映射为高维特征向量，每个维度对应一个像素。

---

为了规避在高维空间中寻找精确查询答案的困难，该问题的近似版本，即$c$-近似最近邻（$c$-Approximate Nearest Neighbor, $c$-ANN）搜索，吸引了广泛的研究[13, 10, 3, 7, 15, 4]。对于给定的近似比$c$（$c>1$）和查询对象$q$，$c$-ANN搜索返回与$q$的距离不超过其精确最近邻距离$c$倍的对象。由于近似比$c$是一个上界，较小的$c$意味着更好的查询质量保证。

---

局部敏感哈希（Locality-Sensitive Hashing, LSH）[7, 2]及其变体[12, 15, 4]是高维空间中$c$-ANN搜索的著名索引方案。Datar等人[2]首次提出了针对欧几里得空间的LSH方案，后来被称为E2LSH${ }^{1}$。E2LSH基于$p$-稳定分布构建LSH函数。对于欧几里得空间，E2LSH及其变体（如Entropy-LSH[12]、LSB-Forest[15]和C2LSH[4]）使用2-稳定分布，即标准正态分布$\mathcal{N}(0,1)$。

---

在欧几里得空间的LSH函数下，两个对象的碰撞概率（或简称为碰撞概率）随着它们的欧几里得距离的增加而单调递减。E2LSH的LSH函数的基本形式如下：$h_{\vec{a}, b}(o)=\left\lfloor\frac{\vec{a} \cdot \vec{o}+b}{w}\right\rfloor$。这样的LSH函数通过以下方式将对象划分到一个桶中：首先，它将对象$o$沿着由$\vec{a}$标识的随机线（或简称为随机线$\vec{a}$）进行投影，然后给投影$\vec{a} \cdot \vec{o}$加上一个随机偏移$b$，最后使用地板函数来确定偏移后的投影落在宽度为$w$的哪个区间内。该区间即为对象$o$的桶。在这种方法中，桶划分是在==任何查询到达之前==进行的，因此被称为查询无关的桶划分。相应地，这种LSH函数被称为查询无关的LSH函数。图1展示了查询无关的桶划分的示意图，其中随机线被分割为桶$[0, w),[-w, 0)$，$[w, 2 w),[-2 w,-w)$，等等。由于使用了地板函数，这里的随机线原点（即0）可以被视为定位每个区间边界的“锚点”。查询无关的桶划分的优势在于==将桶划分的开销留给了预处理步骤==。然而，查询无关的桶划分可能会导致一些不理想的情况，即靠近查询的对象可能被划分到不同的桶中。例如，如图1所示，尽管$o_{1}$比$o_{2}$更接近$q$，但$o_{1}$和$q$被划分到了不同的桶中。

---

$h_{\vec{a}, b}(o)$的基本形式已被E2LSH的变体（如Entropy-LSH和C2LSH）所使用。在LSB-Forest中，尽管LSH函数$\left(h_{\vec{a}, b}(o)=\vec{a} \cdot \vec{o}+b\right)$仅明确涉及随机投影和随机偏移，但其通过Z-order编码哈希值也隐式地使用了原点作为“锚点”。沿着随机线的随机偏移是查询无关的哈希函数具有局部敏感性的前提条件。总之，当前最先进的外部存储LSH方案，即C2LSH和LSB-Forest，都是基于查询无关的桶划分构建的。正如第5.1节所分析的，由于使用了查询无关的桶划分，C2LSH和LSB-Forest仅适用于整数$c \geq 2$的$c$-ANN搜索，这对于那些希望使用$c<2$的强近似比的应用来说是有限的。

---

受查询无关桶划分的局限性启发，我们提出了一种新的查询感知桶划分概念，并据此开发了新的查询感知LSH函数。给定一个预定义的桶宽度$w$，哈希函数$h_{\vec{a}}(o)=\vec{a} \cdot \vec{o}$首先像之前一样将对象$o$沿着随机线$\vec{a}$进行投影。当查询$q$到达时，我们计算$q$的投影（即$h_{\vec{a}}(q)$），并将查询投影（或简称为查询）作为桶划分的“锚点”。具体来说，区间$\left[h_{\vec{a}}(q)-\frac{w}{2}, h_{\vec{a}}(q)+\frac{w}{2}\right]$，即以$h_{\vec{a}}(q)$（或简称为$q$）为中心、宽度为$w$的桶，首先沿着随机线$\vec{a}$被划定。如果需要，我们可以以相同的方式，使用查询作为“锚点”，划定任何更大宽度的桶。这种桶划分方法被称为查询感知的。在第3节中，我们展示了结合查询感知桶划分的哈希函数$h_{\vec{a}}(o)$确实是局部敏感的，因此被称为查询感知的LSH函数。图2展示了一个查询感知桶划分的示例，其中$h(q)$将桶均匀地分割为两个宽度为$\frac{w}{2}$的半桶。通过应用查询感知的桶划分，$o_{1}$和$q$被划分到同一个桶中，从而避免了图1中所示的不理想情况。

---

需要注意的是，查询感知桶划分不需要随机偏移。因此，与查询无关的LSH函数相比，查询感知的LSH函数计算更简单。然而，我们需要动态地进行查询感知桶划分。给定一个查询感知的LSH函数$h_{\vec{a}}(o)=$ $\vec{a} \cdot \vec{o}$，在预处理步骤中，我们计算所有数据对象沿着随机线的投影，并通过$B^{+}$-树索引所有数据投影。当查询对象$q$到达时，我们计算查询投影，并使用$B^{+}$-树定位落在区间$\left[h_{\vec{a}}(q)-\right.$ $\left.\frac{w}{2}, h_{\vec{a}}(q)+\frac{w}{2}\right]$内的对象。如果我们的搜索算法需要，我们可以逐步定位离查询更远的数据对象，就像执行$B^{+}$-树范围搜索一样。换句话说，我们不需要物理上对整个随机线进行划分。因此，查询感知桶划分的开销是可承受的。

---

基于查询感知的LSH函数，我们提出了一种名为QALSH的新型查询感知LSH方案，用于在高维欧几里得空间中进行$c$-近似最近邻（$c$-ANN）搜索。有趣的是，正如第5.1节所分析的，查询感知桶划分使QALSH能够与任何$c>1$一起工作。在本文中，我们还开发了一种自动设置桶宽$w$的新方法，如第5.3节所示。相比之下，最先进的查询无关LSH方案依赖于手动设置$w$。例如，E2LSH和LSB-Forest都手动设置$w=4.0$，而C2LSH手动设置$w=1.0$。

---

总之，我们引入了查询感知桶划分的新概念，并据此开发了新的查询感知LSH函数。我们为外部存储中的高维$c$-ANN搜索提出了一种新颖的查询感知LSH方案QALSH。QALSH可以与任何近似比$c>1$配合使用，并在查询质量上享有理论保证。QALSH还解决了$c$-近似$k$最近邻居（$c-k$-ANN）搜索的问题。在四个真实数据集上的大量实验表明，在高维欧几里得空间中，QALSH优于同样对查询质量有保证的C2LSH和LSB-Forest。

---

本文其余部分的组织结构如下：我们首先在第2节讨论基础知识，然后在第3节介绍查询感知LSH家族。第4节介绍了QALSH方案，其理论分析在第5节给出。实验研究呈现在第6节，相关工作在第7节讨论，最后我们在第8节总结我们的工作。

## 2. 预备知识

### 2.1 问题设定

设$D$为在$d$维欧几里得空间$\mathcal{R}^{d}$中的$n$个数据对象的数据库，用$\left\|o_{1}, o_{2}\right\|$表示两个对象$o_{1}$和$o_{2}$之间的欧几里得距离。给定$\mathcal{R}^{d}$中的查询对象$q$和近似比$c(c>1)$，$c$-近似最近邻（$c$-ANN）搜索是要找到一个对象$o \in D$，使得$\|o, q\| \leq c\left\|o^{*}, q\right\|$成立，其中$o^{*}$是$D$中$q$的确切最近邻。类似地，$c$-$k$-ANN是指找到$k$个对象$o_{i} \in D(1 \leq i \leq k)$，使得$\left\|o_{i}, q\right\| \leq c\left\|o_{i}^{*}, q\right\|$成立，其中$o_{i}^{*}$是$D$中$q$的确切第$i$个最近邻。

### 2.2 查询无关LSH族

一族LSH函数能够以相应的更高概率将“更接近”的对象划分到同一个桶中。如果两个对象$o$和$q$被哈希函数$h$划分到同一个桶中，我们说$o$和$q$在$h$下发生碰撞。形式上，在欧几里得空间中的LSH函数族（或简称LSH族）定义如下：

---

定义1. 给定搜索半径$r$和近似比$c$，若对于任何$o, q \in \mathcal{R}^{d}$有：

- 如果$\|o, q\| \leq r$，则$\operatorname{Pr}_{H}[o$和$q$在$h$下碰撞$] \geq p_{1}$；
- 如果$\|o, q\|>cr$，则$\operatorname{Pr}_{H}[o$和$q$在$h$下碰撞$] \leq p_{2}$。

其中$c>1$且$p_{1}>p_{2}$，则称LSH函数族$H=\left\{h: \mathcal{R}^{d} \rightarrow U\right\}$是$(r, cr, p_{1}, p_{2})\text{-}$敏感的。

为了便于参考，$p_{1}$和$p_{2}$分别称为正碰撞概率和负碰撞概率。

---

查询无关LSH族是一个LSH族$H=\left\{h: \mathcal{R}^{d} \rightarrow \mathcal{Z}\right\}$，其中每个哈希函数$h$利用查询无关的桶划分，即在任何查询到达之前，$h$的哈希表中的桶是静态确定的。通常，对于一个查询无关LSH函数$h$，两个对象$o$和$q$在$h$下发生碰撞意味着$h(o)=h(q)$，这里$h(o)$标识了对象$o$所在的桶。典型的查询无关LSH函数正式定义如下：

$$
\begin{equation*}
h_{\vec{a}, b}(o)=\left\lfloor\frac{\vec{a} \cdot \vec{o}+b}{w}\right\rfloor, \tag{1}
\end{equation*}
$$

这里$\vec{o}$是一个表示对象$o$的$d$维欧几里得向量，$\vec{a}$是一个$d$维随机向量，其每个元素独立地从标准正态分布$\mathcal{N}(0,1)$中抽取。$w$是指定的桶宽，$b$是从区间$[0, w)$中均匀抽取的实数。

---

对于两个对象$o_{1}$和$o_{2}$，以及均匀随机选择的哈希函数$h_{\vec{a}, b}$，设$s=\left\|o_{1}, o_{2}\right\|$，它们的碰撞概率计算如下：

$$
\begin{align*}
\xi(s)\text{=}P_{\vec{a}, b}\left[h_{\vec{a}, b}\left(o_{1}\right)\text{=}h_{\vec{a}, b}\left(o_{2}\right)\right]\text{=}\int_{0}^{w} \frac{1}{s} f_{2}\left(\frac{t}{s}\right)\left(1–\frac{t}{w}\right) d t \tag{2}
\end{align*}
$$

这里$f_{2}(x)=\frac{2}{\sqrt{2 \pi}} e^{-\frac{x^{2}}{2}}$。对于固定的$w$，$\xi(s)$随着$s$的增加单调递减。令$\xi_{1}=\xi(r)$和$\xi_{2}=\xi(c r)$，哈希函数族$h_{\vec{a}, b}$是$\left(r, c r, \xi_{1}, \xi_{2}\right)$-敏感的。特别地，如果我们设置$r=1$且$c r=c$，则有引理1如下[2]：

引理1. 由公式（1）所标识的查询无关LSH族是$\left(1, c, \xi_{1}, \xi_{2}\right)$-敏感的，其中$\xi_{1}=\xi(1)$和$\xi_{2}=\xi(c)$。

## 3. 查询感知LSH族

在本节中，我们首先介绍查询感知LSH函数的概念。然后，我们对查询无关和查询感知LSH族之间的正碰撞概率和负碰撞概率进行计算比较。最后，我们展示查询感知LSH族能够以简单快捷的方式支持虚拟重哈希。

## $3.1\left(1, c, p_{1}, p_{2}\right)$-敏感LSH族

以查询感知方式构建LSH函数包括两个步骤：随机投影和查询感知桶划分。形式上，一个查询感知哈希函数$h_{\vec{a}}(o)$：$\mathcal{R}^{d} \rightarrow \mathcal{R}$将一个$d$维对象$\vec{o}$映射到由随机向量$\vec{a}$标识的实线上的一点，其中$\vec{a}$的各分量独立地从$\mathcal{N}(0,1)$中抽取。对于固定的$\vec{a}$，相应的哈希函数$h_{\vec{a}}(o)$定义如下：

$$
\begin{equation*}
h_{\vec{a}}(o)=\vec{a} \cdot \vec{o} \tag{3}
\end{equation*}
$$

对于所有数据对象，在预处理步骤中计算它们沿随机线$\vec{a}$的投影。当查询对象$q$到达时，我们通过计算$h_{\vec{a}}(q)$来获得查询投影。然后，我们使用查询作为“锚点”来定位宽度为$w$（由$h_{\vec{a}}(\cdot)$定义）的锚桶，即区间$\left[h_{\vec{a}}(q)-\frac{w}{2}, h_{\vec{a}}(q)+\frac{w}{2}\right]$。如果一个对象$o$的投影（即$h_{\vec{a}}(o)$）落在宽度为$w$的锚桶内，即$\left|h_{\vec{a}}(o)-h_{\vec{a}}(q)\right| \leq \frac{w}{2}$，我们就说$o$在$h_{\vec{a}}$下与$q$发生碰撞。

---

我们现在展示哈希函数族$h_{\vec{a}}(o)$结合查询感知桶划分是局部敏感的。在这个意义上，族中的每个$h_{\vec{a}}(o)$被称为==查询感知LSH函数==。对于对象$o$和$q$，设$s=\|o, q\|$。由于标准正态分布$\mathcal{N}(0,1)$的稳定性，我们有$(\vec{a} \cdot \vec{o}-\vec{a} \cdot \vec{q})$的分布为$sX$，其中$X$是从$\mathcal{N}(0,1)$中抽取的随机变量。令$\varphi(x)$为$\mathcal{N}(0,1)$的概率密度函数（PDF），即$\varphi(x)=\frac{1}{\sqrt{2 \pi}} e^{-\frac{x^{2}}{2}}$。在$h_{\vec{a}}$下$o$和$q$之间的碰撞概率计算如下：

$$
\begin{align*}
p(s) & =\operatorname{Pr}_{\vec{a}}\left[\left|h_{\vec{a}}(o)-h_{\vec{a}}(q)\right| \leq \frac{w}{2}\right]=\operatorname{Pr}\left[|s X| \leq \frac{w}{2}\right] \\
& =\operatorname{Pr}\left[-\frac{w}{2 s} \leq X \leq \frac{w}{2 s}\right]=\int_{-\frac{w}{2 s}}^{\frac{w}{2 s}} \varphi(x) d x \tag{4}
\end{align*}
$$

相应地，我们有如下引理2：

引理2. 所有由公式（3）标识并结合查询感知桶划分的哈希函数$h_{\vec{a}}(o)$构成的查询感知哈希族是$\left(1, c, p_{1}, p_{2}\right)$-敏感的，其中$p_{1}=p(1)$且$p_{2}=p(c)$。

---

证明：参照公式（4），简单计算表明$p(s)=1-2 \operatorname{norm}\left(-\frac{w}{2 s}\right)$，其中$\operatorname{norm}(x)=\int_{-\infty}^{x} \varphi(t) d t$。注意$\operatorname{norm}(x)$就是$\mathcal{N}(0,1)$的累积分布函数（CDF），它随着$x$的增加而单调递增。对于固定的$w$，$\operatorname{norm}\left(-\frac{w}{2 s}\right)$随着$s$的增加而单调递增，因此$p(s)$随着$s$的增加而单调递减。因此，根据定义1，由公式（3）标识的查询感知哈希族是$\left(1, c, p_{1}, p_{2}\right)$-敏感的，其中$p_{1}=p(1)$且$p_{2}=p(c)$。

### 3.2 碰撞概率的比较

一个$(r, cr, p_{1}, p_{2})$-敏感哈希族的有效性取决于正碰撞概率和负碰撞概率之间的差异，即$(p_{1}-p_{2})$，因为这种差异衡量了查询$q$的正碰撞数据对象与负碰撞数据对象之间可区分的程度。我们现在展示，在典型的桶宽$w$设置下，新的查询感知哈希族导致更大的$(p_{1}-p_{2})$。对于查询感知LSH族，从引理2的证明中我们有$p_{1}=1-2 \operatorname{norm}\left(-\frac{w}{2}\right)$和$p_{2}=1-2 \operatorname{norm}\left(-\frac{w}{2c}\right)$。对于查询无关LSH族，我们有$\xi_{1}=1-2 \operatorname{norm}(-w)-\frac{2}{\sqrt{2 \pi} w}(1-e^{-\left(w^{2} / 2\right)})$和$\xi_{2}=1-2 \operatorname{norm}(-w / c)-\frac{2}{\sqrt{2 \pi} w / c}(1-e^{-\left(w^{2} / 2 c^{2}\right)})$。

---

桶宽$w$是LSH函数的一个关键参数。虽然E2LSH和LSB-Forest手动设置$w=4.0$，C2LSH手动设置$w=1.0$。对于范围在$[0,10]$内的$w$值，从0.5开始，步长为0.5，我们在图3中展示了两个不同$c$值下的碰撞概率$p_{1}$、$p_{2}$、$\xi_{1}$和$\xi_{2}$的变化情况。我们发现所有碰撞概率随着$w$的增加而单调递增，并且当$w$接近10时，这些概率非常接近1。此外，$p_{1}$和$p_{2}$始终分别大于$\xi_{1}$和$\xi_{2}$。因此，我们还在图4中展示了关于$w$的两个差异$(p_{1}-p_{2})$和$(\xi_{1}-\xi_{2})$。我们有两个有趣的观察结果：(1) 在典型的桶宽下，即$w=4.0$和$w=1.0$时，$(p_{1}-p_{2})$大于$(\xi_{1}-\xi_{2})$。(2) $(p_{1}-p_{2})$和$(\xi_{1}-\xi_{2})$在$w$范围$[0,10]$内都倾向于达到最大值。观察结果(1)表明，我们的新型查询感知LSH族可以用于通过利用更大的$(p_{1}-p_{2})$来改进如C2LSH这样的查询无关LSH方案的性能。观察结果(2)启发我们通过最大化差异$(p_{1}-p_{2})$自动设置桶宽$w$，这实际上导致了QALSH中哈希表数量的最小化，如第5.3.1节所分析的那样。

---

由于C2LSH已被证明在高维空间中优于LSB-Forest，并且查询感知桶划分易于为单个查询感知LSH函数实现，本文建议遵循C2LSH的一般框架来展示查询感知LSH族的优越性。

### 3.3 虚拟重哈希

诸如C2LSH的LSH方案并不直接解决$c$-ANN搜索问题。这是因为一个$(R, cR, p_{1}, p_{2})$敏感的LSH族需要预先指定$R$以便计算$p_{1}$和$p_{2}$。它是$c$-ANN搜索问题的决策版本，即$(R, c)$-NN搜索问题，可以通过利用$(R, cR, p_{1}, p_{2})$-敏感LSH族直接解决。给定查询对象$q$和搜索半径$R$，$(R, c)$-NN搜索问题是找到一个与$q$的距离最多为$cR$的数据对象$o_{1}$，前提是存在一个与$q$的距离最多为$R$的数据对象$o_{2}$。

---

查询$q$的$c$-ANN搜索被简化为一系列具有适当增加搜索半径$R \in \{1, c, c^{2}, c^{3}, \ldots\}$的$(R, c)$-NN搜索。因此，对于每个$R$，我们需要一个$(R, cR, p_{1}, p_{2})$-敏感的LSH族。对于每个$R \in \{c, c^{2}, \ldots\}$，通过从$R=1$时的$(1, c, p_{1}, p_{2})$-敏感哈希族派生出$(R, cR, p_{1}, p_{2})$-敏感哈希族，所有后续半径的哈希表实际上可以叠加在$R=1$的物理哈希表上。这就是C2LSH虚拟重哈希的基本思想。

---

我们现在展示QALSH也可以通过从公式（3）中派生$(R, cR, p_{1}, p_{2})$-敏感函数来进行虚拟重哈希。QALSH的虚拟重哈希使其能够与任何$c>1$配合使用，而C2LSH和LSB-Forest仅能与整数$c \geq 2$配合使用。这一优势的正式证明见第5.1节。

---

命题1. 查询感知哈希族

$$
H_{\vec{a}}^{R}(o)=\frac{h_{\vec{a}}(o)}{R}
$$

是$\left(R, c R, p_{1}, p_{2}\right)$-敏感的，其中$c, p_{1}, p_{2}$和$h_{\vec{a}}(\cdot)$与引理2中定义相同，且$R$是$c$的幂（即$c^{k}$对于某个整数$k \geq 1$）。

证明：令$\overrightarrow{o^{\prime}}=\frac{\vec{o}}{R}$，从公式（3）我们有$H_{\vec{a}}^{R}(o)=$ $\frac{\vec{a} \cdot \vec{o}}{R}=\vec{a} \cdot \overrightarrow{o^{\prime}}=h_{\vec{a}}\left(o^{\prime}\right)$。根据引理2，我们断言$h_{\vec{a}}\left(o^{\prime}\right)$是$\left(1, c, p_{1}, p_{2}\right)$-敏感的。该断言意味着如果$\left\|o_{1}^{\prime}, o_{2}^{\prime}\right\| \leq 1$，则对象$o_{1}^{\prime}$和$o_{2}^{\prime}$在$h_{\vec{a}}(\cdot)$下碰撞的概率至少为$p_{1}$。而$\left\|o_{1}^{\prime}, o_{2}^{\prime}\right\| \leq 1$等价于$\left\|o_{1}, o_{2}\right\| \leq R$。因此，如果$\left\|o_{1}, o_{2}\right\| \leq R$，则$o_{1}$和$o_{2}$在$H_{\vec{a}}^{R}(\cdot)$下的碰撞概率至少为$p_{1}$。类似地，该断言还表明如果$\left\|o_{1}, o_{2}\right\| \geq c R$，则$o_{1}$和$o_{2}$在$H_{\vec{a}}^{R}(\cdot)$下的碰撞概率最多为$p_{2}$。因此，查询感知哈希族$H_{\vec{a}}^{R}(o)$是$\left(R, c R, p_{1}, p_{2}\right)$-敏感的。

---

给定一个查询$q$和预设的桶宽$w$，对于$R \in \{1, c, c^{2}, \ldots\}$，我们现在定义轮次-$R$锚桶$B^{R}$为由$H_{\vec{a}}^{R}(\cdot)$定义宽度为$w$的锚桶，即区间$\left[H_{\vec{a}}^{R}(q)-\frac{w}{2}, H_{\vec{a}}^{R}(q)+\frac{w}{2}\right]$，它以$q$沿随机线$\vec{a}$的投影$H_{\vec{a}}^{R}(q)$为中心。换句话说，轮次-$R$锚桶通过查询感知桶划分以桶宽$w$定位，如之前一样。具体来说，$B^{1}$就是区间$\left[h_{\vec{a}}(q)-\frac{w}{2}, h_{\vec{a}}(q)+\frac{w}{2}\right]$，这是由$h_{\vec{a}}(\cdot)$定义宽度为$w$的锚桶。

---

如第4.1节所示，为了找到查询$q$的$(R, c)$-NN，我们只需要检查特定$R$的轮次-$R$锚桶$B^{R}$。为了找到$q$的$c$-ANN，我们逐轮检查逐渐增加的$R\left(R \in \{1, c, c^{2}, \ldots\}\right)$轮次的锚桶。所有由$H_{\vec{a}}^{R}(\cdot)$定义的轮次-$R$锚桶都沿着相同的$\vec{a}$以$q$为中心，并可以沿$\vec{a}$方向以适当调整的桶宽定位。因此，我们只需保留一份沿$\vec{a}$的数据投影的实际副本。利用以下命题2和命题3的结果，我们可以虚拟地将$B^{R}$叠加到$B^{1}$上，从而将$B^{c R}$叠加到$B^{R}$上。这是QALSH虚拟重哈希的基本思想。这里我们只展示命题2的证明，因为命题3的证明与此相似。

---

命题2. 给定$q$和$w$，$B^{R}$包含$B^{1}$，且$B^{R}$的宽度是$B^{1}$宽度的$R$倍，即$wR$。

证明：根据$B^{R}$的定义，对于$B^{R}$中的每个对象$o$，我们有$\left|H_{\vec{a}}^{R}(o)-H_{\vec{a}}^{R}(q)\right| \leq \frac{w}{2}$，即$\left|\frac{h_{\vec{a}}(o)}{R}-\frac{h_{\vec{a}}(q)}{R}\right| \leq \frac{w}{2}$。因此，我们得到$\left|h_{\vec{a}}(o)-h_{\vec{a}}(q)\right| \leq \frac{wR}{2}$，这意味着$o$落在沿随机线$\vec{a}$的区间$\left[h_{\vec{a}}(q)-\frac{wR}{2}, h_{\vec{a}}(q)+\frac{wR}{2}\right]$内。这个区间就是由$h_{\vec{a}}(\cdot)$定义的宽度为$wR$的锚桶，显然它包含了子区间$\left[h_{\vec{a}}(q)-\frac{w}{2}, h_{\vec{a}}(q)+\frac{w}{2}\right]$，即$B^{1}$。而且，$B^{R}$的宽度是$B^{1}$宽度的$R$倍。

---

命题3. 给定$q$和$w$，$B^{cR}$包含$B^{R}$，且$B^{cR}$的宽度是$B^{R}$宽度的$c$倍。

参照在随机线$\overrightarrow{a_{1}}$上的图5，以$q$为中心宽度为$w$的区间是$B^{1}$，标记为"00"。$B^{2}$和$B^{4}$分别标记为"1001"和"32100123"。QALSH的虚拟重哈希等同于在$q$两侧对称地逐一搜索长度为$\frac{w}{2}$的半桶。第4.2节给出了一个详细的例子。 

### 3.4 准备桶划分

给定一个查询感知LSH函数$h_{\vec{a}}$，为了沿$\vec{a}$进行虚拟重哈希，我们需要通过查询感知桶划分快速定位一系列锚桶。因此，在预处理步骤中，我们准备$h_{\vec{a}}$的哈希表$T$。$T$是数据库$D$中每个对象$o$的对$\left(h_{\vec{a}}(o), I D_{o}\right)$的列表，其中$I D_{o}$是指向$o$的对象id。该列表按$h_{\vec{a}}(o)$升序排序，然后通过一个$B^{+}$-树进行索引。

---

给定预设的桶宽$w$。当查询$q$到达时，为了执行$(R, c)$-NN搜索，我们使用哈希表$T$上的$B^{+}$-树执行范围搜索$\left[h_{\vec{a}}(q)-\frac{w R}{2}, h_{\vec{a}}(q)+\frac{w R}{2}\right]$以定位轮次-$R$锚桶。为了执行$c$-ANN搜索，我们首先执行范围搜索$\left[h_{\vec{a}}(q)-\frac{w}{2}, h_{\vec{a}}(q)+\frac{w}{2}\right]$以定位轮次-1锚桶$B^{1}$。然后我们使用虚拟重哈希检查$B^{1}$的两侧以定位所需的轮次-$R$锚桶。通过这种方式，我们可以快速实现查询感知桶划分，而无需将整个随机线物理划分为宽度为$w$的桶。

---

本质上，QALSH的哈希表可以视为一个二级$B^{+}$-树，这使得QALSH能够支持更新并增强关系数据库的性能。

## 4. 查询感知LSH方案

给定一个查询感知LSH函数$h$，如果一个数据对象$o$在原始欧几里得空间中接近查询$q$，那么它们很有可能会在由$h$定义的宽度为$w$的锚桶内发生碰撞。然而，在特定函数下，它们可能完全不发生碰撞。因此，QALSH利用一组$m$个独立的查询感知LSH函数来保证质量。一个好的候选对象$o$作为查询答案，预期是在这$m$个函数下频繁与$q$发生碰撞的对象。QALSH从这些候选对象集合中识别最终的查询答案。

### 4.1 QALSH用于$(R, \mathbf{c})$-NN搜索

QALSH通过使用基$\mathcal{B}$中的$m$个查询感知LSH函数$\left\{H_{a_{1}}^{R}(\cdot), H_{a_{2}}^{R}(\cdot), \ldots, H_{a_{m}}^{R}(\cdot)\right\}$直接解决$(R, c)$-NN问题。这些LSH函数相互独立，并且均匀地从一个$(R, cR, p_{1}, p_{2})$敏感的查询感知LSH族中选取。对于每个$H_{a_{i}}^{R}(\cdot)$，我们构建一个由$B^{+}$-树索引的哈希表$T_{i}$，如第3.4节所述。

---

为了找到查询$q$的$(R, c)$-NN，我们首先计算$i=1,2,\ldots,m$时的哈希值$H_{a_{i}}^{R}(q)$，然后使用$T_{i}$上的$B^{+}$-树定位$m$个轮次-$R$锚桶。对于出现在某个$m$锚桶中的每个对象$o$，我们收集其碰撞数$\# \operatorname{Col}(o)$，其正式定义如下：

$$
\begin{equation*}
\# \operatorname{Col}(o)=\left|\left\{H_{\vec{a}}^{R}\left|H_{\vec{a}}^{R} \in \mathcal{B} \wedge\right| H_{\vec{a}}^{R}(o)-H_{\bar{a}}^{R}(q) \left\lvert\, \leq \frac{w}{2}\right.\right\}\right| \tag{5}
\end{equation*}
$$

给定预设的碰撞阈值$l$，如果$\# \operatorname{Col}(o) \geq l$，则称对象$o$是频繁的（相对于$q, w$和$\mathcal{B}$）。我们倾向于首先对那些投影更接近查询投影的对象收集碰撞数。我们只需要找到“前”$\beta n$个频繁对象（其中$\beta$稍后解释，$n$是$D$的基数），并计算它们到$q$的欧几里得距离。如果有某个频繁对象到$q$的距离小于或等于$cR$，我们返回YES及该对象；否则，返回NO。

---

基基数$m$是QALSH的关键参数之一，需要适当选择以确保以下两个属性能同时以常数概率成立：

- $\mathcal{P}_{1}$：如果存在一个对象$o$到$q$的距离在$R$之内，则$o$是一个频繁对象。
- $\mathcal{P}_{2}$：假阳性的总数少于$\beta n$，其中每个假阳性都是到$q$的距离大于$cR$的频繁对象。

上述断言由如下引理3保证，这为$(R, c)$-NN搜索的QALSH的正确性提供了保障。设$l$为碰撞阈值，$\alpha$为碰撞阈值的百分比，我们有$l=\alpha m$。设$\delta$为错误概率，$\beta$为假阳性的百分比。

---

引理3. 给定$p_{1}=p(1)$和$p_{2}=p(c)$，其中$p(\cdot)$由公式（4）定义。令$\alpha, \beta$和$\delta$如上定义。对于$p_{2}<\alpha<p_{1}, 0<\beta<1$且$0<\delta<\frac{1}{2}$，$\mathcal{P}_{1}$和$\mathcal{P}_{2}$能同时以至少$\frac{1}{2}-\delta$的概率成立，前提是基基数$m$如下给出：

$$
\begin{equation*}
m=\left\lceil\max \left(\frac{1}{2\left(p_{1}-\alpha\right)^{2}} \ln \frac{1}{\delta}, \frac{1}{2\left(\alpha-p_{2}\right)^{2}} \ln \frac{2}{\beta}\right)\right\rceil \tag{6}
\end{equation*}
$$

引理3在某种意义上是C2LSH的引理1的一个略微不同的版本，即明确限定了$\mathcal{P}_{1}$和$\mathcal{P}_{2}$联合发生的概率下界。因此，我们在附录A中仅给出证明概要。

### 4.2 QALSH用于$c$-ANN搜索

给定一个查询$q$和预设的桶宽$w$，为了找到$q$的$c$-ANN，QALSH首先使用$R=1$从轮次-1锚桶中收集频繁对象；如果目前为止收集到的频繁对象不够多，QALSH会自动更新$R$，并通过虚拟重哈希从轮次-$R$锚桶中收集更多的频繁对象，依此类推，直到最终找到足够多的频繁对象或识别出足够好的频繁对象。$q$的$c$-ANN必须是这些频繁对象之一。

如算法1所示，QALSH非常直接。候选集$C$用于存储目前为止找到的频繁对象，在开始时为空。

---

**终止条件**。QALSH在以下两种情况下终止，这两种情况分别由引理3的两个属性$\mathcal{P}_{1}$和$\mathcal{P}_{2}$支持：

- $\mathcal{T}_{1}$：在轮次-$R$，存在至少1个频繁对象，其到$q$的欧几里得距离小于或等于$cR$（参考算法1中的第9-11行）。
- $\mathcal{T}_{2}$：在轮次-$R$，已经找到至少$\beta n$个频繁对象（参考算法1中的第2行和第13行）。

---

**搜索半径$R$的更新**。可以检查到，在算法1中，如果终止条件$\mathcal{T}_{1}$仍未满足，即我们还没有找到足够好的频繁对象，则需要在第12行更新$R$。为便于参考，令$R$和$R^{\prime}$分别表示当前和下一个搜索半径。 

---

由于C2LSH静态设置$R^{\prime}=c \times R$，它依次进行一系列的$(R, c)$-NN搜索，其中$R \in \{1, c, c^{2}, \ldots\}$。实际上，某些轮次的搜索可能是浪费的。给定$c=2$和$l=2$，可以通过图5和算法1中的例子来说明。在算法1的第一轮之后（即在$(R=1, c=2)$-NN搜索之后），我们有$\# \operatorname{Col}(o_{2})=1$和$\# \operatorname{Col}(o_{3})=1$，因为只有$o_{2}$和$o_{3}$分别出现在标记为"00"的两个轮次-1锚桶中一次。由于$o_{2}$和$o_{3}$此时都不是频繁对象，算法1需要更新$R$。由于标记为"1001"的轮次-2锚桶中没有新的数据对象，我们不需要像C2LSH那样将$R$更新为$R=2$（即$R=c$）。

---

相比之下，QALSH通过利用数据对象的投影来适当更新$R$，选择跳过这种浪费的轮次。回想一下，QALSH的$m$个哈希表每个都只是一个$B^{+}$-树，我们可以很容易地找到最接近$q$且存在于当前轮次-$R$锚桶之外的对象$o$。因此，总共有$m$个这样的对象。假设它们到$q$的距离（以投影表示）按升序排序并记为$d_{1}, d_{2}, \ldots, d_{m}$，即$d_{1}$是最小的，$d_{m}$是最大的。令$d_{med}$表示$d_{1}, d_{2}, \ldots, d_{m}$的中位数。QALSH自动设置$R^{\prime}$为$R^{\prime}=c^{k}$，使得$\frac{wR^{\prime}}{2} \geq d_{med}$，并且整数$k$尽可能小。因此，在下一轮搜索中有至少$\frac{m}{2}$个对象用于收集碰撞数。

---

背后的直觉如下：如果我们根据$d_{1}$设置$R^{\prime}$，轮次-$R^{\prime}$的锚桶可能包含太少的数据对象用于收集碰撞数，从而浪费了对轮次-$R^{\prime}$锚桶的扫描。另一方面，如果我们根据$d_{m}$设置$R^{\prime}$，由于$d_{m}$可能太大，轮次-$R^{\prime}$的锚桶可能包含太多的数据对象，因此我们可能会做不必要的碰撞数收集和欧几里得距离计算。此外，$R^{\prime}$必须是$R^{\prime}=c^{k}$（对于整数$k$），这样才能保证QALSH的理论框架仍然有效。

### 4.3 QALSH用于$c$-$k$-ANN搜索

为了支持$c$-$k$-ANN搜索，QALSH只需更改其$c$-ANN的终止条件：

- $\mathcal{T}_{1}^{\prime}$：在轮次-$R$，存在至少$k$个频繁对象，它们到$q$的欧几里得距离在$cR$以内。
- $\mathcal{T}_{2}^{\prime}$：在轮次-$R$，已经找到至少$\beta n+k-1$个频繁对象。

## 5. 理论分析

在本节中，我们首先展示QALSH可以与任何近似比$c>1$一起工作，然后给出$c$-ANN搜索的近似比界限。接着讨论QALSH的参数设置，并提出一种自动设置桶宽$w$的方法。最后，我们展示QALSH的时间和空间复杂度。

### 5.1 支持任意近似比

C2LSH物理构建了搜索半径为$R=1$的哈希表，其中的桶被称为级别-1桶，并且在任何查询到达之前静态地划分。每个级别-1桶由一个称为bid的整数标识。根据C2LSH的观察3，当C2LSH执行搜索半径$R \in \{c, c^{2}, c^{3}, \ldots\}$的虚拟重哈希时，每个级别-$R$桶由连续的级别-1 bid标识的确切$R$个级别-1桶组成。当近似比$c$不是整数时，搜索半径$R$也不是整数，这意味着某些级别-1桶必须进一步划分。然而，级别-1桶已经被设置为桶划分的最小粒度。因此，C2LSH仅适用于整数$c \geq 2$。

---

LSB-Forest也遭受与C2LSH相同的静态桶划分问题。在将$k$维对象转换为Z序值之前，必须在$k$维空间的$k$坐标上施加网格。网格的每个单元等同于一个桶。Z序值实际上在不同级别上施加了网格。高级别的单元（桶）用于较大的搜索半径，由用于较小搜索半径的整数倍低级别单元（桶）组成。因此，LSB-Forest也仅适用于整数$c \geq 2$。现在我们展示：

引理4. 算法1可以与任何近似比$c>1$一起工作。

---

证明：如算法1所示，仅需要不同轮次的锚桶。而不是使用固定的桶id来标识预先划分的桶，所有不同轮次的锚桶都是通过指定一个桶范围来虚拟施加的，即$\left|H_{\vec{a}}^{R}(o)-H_{\vec{a}}^{R}(q)\right| \leq \frac{w}{2}$。我们可以使用任何桶范围来决定一个锚桶，因为哈希值，即投影，已经被记录在哈希表中。根据命题3，通过$c$倍扩大轮次-$R$锚桶以生成轮次-$cR$锚桶是通过$c$倍扩大相应的桶范围实现的，这里$c$不要求为整数。因此，算法1可以与任何$c>1$一起工作。

### 5.2 近似比的界限

对于$c$-ANN搜索，我们现在给出算法1的近似比界限。

定理1. 算法1以至少$\frac{1}{2}-\delta$的概率返回一个$c^{2}$-近似的最近邻（NN）。

由于QALSH和C2LSH都使用虚拟重哈希技术，这个定理是C2LSH定理1的一个更强版本，在于该定理中的概率明确地从下方有界。此定理简单地结合了C2LSH的定理1和QALSH的引理3得出。

### 5.3 参数设置

QALSH的准确性由错误概率$\delta$、近似比$c$和假阳性百分比$\beta$控制，其中$\delta, c$和$\beta$是由用户指定的常数。$\delta$控制任何基于LSH方法进行$c$-ANN搜索的成功率。在本文中，我们设$\delta=\frac{1}{e}$。较小的$c$意味着更高的准确性。直观上，较大的$\beta$允许C2LSH和QALSH检查更多的频繁对象，从而使它们能够实现更好的搜索质量，但会以随机I/O的成本增加为代价。类似于C2LSH，QALSH设定$\beta=100 / n$以限制随机I/O的数量。

---

我们现在考虑基基数$m$、碰撞阈值百分比$\alpha$和碰撞阈值$l$。参照引理3的公式(6)，令$m_{1}=\left\lceil\frac{1}{2\left(p_{1}-\alpha\right)^{2}} \ln \frac{1}{\delta}\right\rceil$和$m_{2}=\left\lceil\frac{1}{2\left(\alpha-p_{2}\right)^{2}} \ln \frac{2}{\beta}\right\rceil$，我们得到$m=\max \left(m_{1}, m_{2}\right)$。由于$p_{2}<\alpha<p_{1}$，$m_{1}$随$\alpha$单调增加且$m_{2}$随$\alpha$单调减少。因为$m=\max \left(m_{1}, m_{2}\right)$，当$m_{1}=m_{2}$时$m$最小。然后，$\alpha$可以通过以下方式确定：

$$
\begin{equation*}
\alpha=\frac{\eta \cdot p_{1}+p_{2}}{1+\eta}, \text { 其中 } \eta=\sqrt{\frac{\ln \frac{2}{\beta}}{\ln \frac{1}{\delta}}} \tag{7}
\end{equation*}
$$

将方程(7)中的$\alpha$替换入$m_{1}$中，我们得到：

$$
\begin{equation*}
m=\left\lceil\frac{\left(\sqrt{\ln \frac{2}{\beta}}+\sqrt{\ln \frac{1}{\delta}}\right)^{2}}{2\left(p_{1}-p_{2}\right)^{2}}\right\rceil \tag{8}
\end{equation*}
$$

设置$m$和$\alpha$的值后，我们计算整数碰撞阈值$l$如下：

$$
\begin{equation*}
l=\lceil\alpha m\rceil \tag{9}
\end{equation*}
$$

---

基基数$m$只是QALSH中哈希表的数量。较小的$m$导致QALSH中小的时间和空间开销，如第5.4节所示。然而，为了保证质量，$m$必须被设置以满足引理3的要求。根据方程(8)，对于固定的$\delta$和$\beta$，$m$随着差值$\left(p_{1}-p_{2}\right)$单调递减。从第3.2节我们知道在范围$[0,10]$内有一个$w$的值可以最大化$\left(p_{1}-p_{2}\right)$。E2LSH和LSB-Forest手动设置桶宽$w=4.0$，而C2LSH手动设置$w=1.0$。在下一节中，我们建议自动决定$w$，以便最小化基基数$m$。

### 5.3.1 自动设置$w$以最小化$m$

最小化$m$的策略是选择能最大化差值$\left(p_{1}-p_{2}\right)$的$w$值。形式上，我们有引理5来最小化$m$。

引理5. 假设$\delta$和$\beta$是用户指定的常数，对于任何近似比$c>1$，通过设置QALSH的基基数$m$最小化为：

$$
\begin{equation*}
w=\sqrt{\frac{8 c^{2} \ln c}{c^{2}-1}} \tag{10}
\end{equation*}
$$

证明：令$\mu(w)=p_{1}-p_{2}$。从公式(4)中，我们得到：

$$
\begin{aligned}
\mu(w) & =p_{1}-p_{2} \\
& =\int_{-\frac{w}{2}}^{\frac{w}{2}} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^{2}}{2}} d t-\int_{-\frac{w}{2 c}}^{\frac{w}{2 c}} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^{2}}{2}} d t \\
& =\frac{2}{\sqrt{2 \pi}} \int_{-\infty}^{\frac{w}{2}} e^{-\frac{t^{2}}{2}} d t-\frac{2}{\sqrt{2 \pi}} \int_{-\infty}^{\frac{w}{2 c}} e^{-\frac{t^{2}}{2}} d t
\end{aligned}
$$

使用微积分的基本技巧，我们取导数并得到以下等式：

$$
\mu^{\prime}(w)=\frac{1}{\sqrt{2 \pi}}\left(e^{-\frac{w^{2}}{8}}-\frac{1}{c} \cdot e^{-\frac{w^{2}}{8 c^{2}}}\right)
$$

令$\mu^{\prime}(w)=0$。由于$w>0$且$c>1$，我们得到表达式$w^{*}=\sqrt{\frac{8 c^{2} \ln c}{c^{2}-1}}$。当$0<w<w^{*}$时，$\mu^{\prime}(w)>0$；当$w>w^{*}$时，$\mu^{\prime}(w)<0$。因此，对于$0<w<w^{*}$，$\mu(w)$随$w$单调增加；对于$w>w^{*}$，$\mu(w)$随$w$单调减少。所以，当$w=w^{*}$时，$\mu(w)=p_{1}-p_{2}$达到最大值。根据公式(8)，因为$\beta$和$\delta$是常数，$m$随差值$\left(p_{1}-p_{2}\right)$单调减少。因此，当$w=w^{*}$时，$m$达到最小值。由于公式(8)源自引理3，$m$的最小值满足质量保证。

### 5.4 时间和空间复杂度

因为我们设置$\beta=\frac{100}{n}$，所以$\beta n$是常数。从公式(8)和(9)，我们分别有$m=O(\log n)$和$l=O(\log n)$。

QALSH的时间成本由四部分组成：首先，为$m$个哈希表计算查询的投影的成本为$md=O(d \log n)$；其次，在$B^{+}$-树中定位$m$个轮次-1锚桶的成本为$m \log n=O((\log n)^{2})$；第三，在最坏情况下，找到作为候选者的频繁对象需要在每个哈希表上对所有$n$个对象进行碰撞计数，这成本为$ln=O(n \log n)$；最后，计算候选者之间的欧几里得距离的成本为$\beta nd=O(d)$。因此，QALSH的时间复杂度为$O(d \log n+(\log n)^{2}+n \log n+d)=O(d \log n+n \log n)$。

QALSH的空间复杂度由两部分组成：数据集的空间$O(nd)$和索引的空间$mn=O(n \log n)$用于存储$n$个数据对象的id和投影的$m$个哈希表。因此，QALSH的总空间消耗为$O(nd+n \log n)$。

## 6. 实验

在本节中，我们使用四个真实数据集研究了QALSH的性能。由于QALSH具有质量保证并且设计用于外部存储器，我们将同类型的两个最先进的方案作为基准，即LSB-Forest和C2LSH。

### 6.1 实验设置

### 6.1.1 基准方法

- **LSB-Forest。** LSB-Forest使用一组$L$个LSB树来实现质量保证，其成功概率至少为$\frac{1}{2}-\frac{1}{e}$。对于$c$-ANN搜索，LSB-Forest需要$2L$个缓冲页面。因为LSB-Forest已被证明优于iDistance [8]和MEDRANK [3]，这里不再将它们纳入比较。
- **C2LSH。** C2LSH与QALSH最相关。它要求$c$-ANN搜索有$2m$页的缓冲区，其中$m$是C2LSH中使用的哈希表数量。我们考虑将$l$作为碰撞阈值的C2LSH，因为只有在这种情况下它才有质量保证。

我们的方法使用C++实现。所有方法都使用gcc 4.8编译，并开启-O3优化选项。所有实验都在一台配备Intel Core i7-2670M 2.20 GHz CPU、8GB内存和1TB硬盘的PC上进行，操作系统为Linux 3.11。

### 6.1.2 数据集和查询

我们在实验中使用了四个真实的数据集。我们将数值放大为整数以满足LSB-Forest和C2LSH的要求，而QALSH能够直接处理实数。根据LSB-Forest的最佳性能需求设置页面大小$B$。

- Mnist${ }^{2}$ 这是一个784维的数据集，包含60,000个对象。我们按照[15,4]中的做法，考虑方差最大的前50个维度。$B$被设置为4KB。
- Sift${ }^{3}$ 我们使用Sift的1,000,000个128维的基础向量作为数据集。$B$被设置为4KB。
- LabelMe${ }^{4}$ 这是一个512维的数据集，包含181,093个对象。坐标被标准化为范围在$[0,58104]$内的整数。$B$被设置为8KB。
- P53${ }^{5}$ 2012版本的这个5,408维生物数据集包含31,420个对象。我们移除了所有含有缺失值的对象，使得数据集的基数减少到31,159。坐标被标准化为范围在$[0,10000]$内的整数。$B$被设置为64KB。

---

LSB-Forest和C2LSH通过平均50个随机查询的结果来研究性能，而SRS使用100个随机查询。我们进行了三组查询实验，分别包含50、100和200个查询。由于这三组查询的实验结果显示出相似的趋势，出于篇幅限制，我们仅报告包含100个查询的那组结果。对于Mnist和Sift数据集，查询从对应的测试集中均匀随机选择。对于LabelMe和P53数据集，查询是从数据对象中均匀随机选择的。Mnist和Sift被视为低维数据集。LabelMe和P53分别被视为中维和高维数据集。

- ### 6.1.3 评估指标

  我们使用以下指标进行性能评估。

  - **索引大小。** 因为所有方法的数据集大小是恒定的，我们使用由一种方法生成的索引的大小来评估该方法的空间开销。
  - **整体比率。** 整体比率15,4用于衡量方法的准确性。对于$c$-$k$-ANN搜索，它定义为$\frac{1}{k} \sum_{i=1}^{k} \frac{\left\|o_{i}, q\right\|}{\left\|o_{i}^{*}, q\right\|}$，其中$o_{i}$是一个方法返回的第$i$个对象，而$o_{i}^{*}$是真正的第$i$个最近邻对象，$i=1,2,\ldots,k$。直观上，较小的整体比率意味着更高的准确性。
  - **I/O成本。** 我们遵循LSB-Forest和C2LSH的做法，使用I/O成本来评估方法的效率。它被定义为需要访问的页数。I/O成本包括两部分：找到候选者（即频繁对象）的成本和在原始空间中对候选者的距离计算成本。
  - **运行时间。** 由于查询感知的桶划分引入了额外的开销，我们也考虑处理一个查询的运行时间成本。它被定义为一个方法解决$c$-$k$-ANN问题所需的实际时间（挂钟时间）。 


### 6.2 参数设置

为了保证公平性，所有方法的成功概率都设置为$\frac{1}{2}-\frac{1}{e}$，即QALSH和C2LSH的$\delta$设置为$\frac{1}{e}$。我们使用$c=2.0$的设置，以便LSB-Forest和C2LSH能达到最佳性能。QALSH和C2LSH都将假阳性百分比$\beta$设置为$100 / n$，以限制候选者的数量，从而相应地限制随机I/O的数量。LSB-Forest和C2LSH的其他参数设置为其默认值。

---

我们通过公式(10)计算QALSH的桶宽$w$，对于$c=2$得到$w=2.719$。由于在C2LSH和LSB-Forest中$w$分别手动设置为1.0和4.0，我们也考虑了两个中间值$w=2.0$和$w=3.0$。表1显示了在$w$的五种设置下QALSH的索引大小。我们观察到，在$w=2.719$设置下的索引大小确实是最小的。因为每个哈希表大小相同，索引大小的不同反映了哈希表数量（即基基数$m$）的不同。换句话说，在$w$的五种设置中，设置$w=2.719$使$m$最小化。我们还评估了在$w$的五种设置下QALSH的整体比率、I/O成本和运行时间。我们注意到不同设置下的整体比率基本相等。由于在$w=2.719$设置下的索引大小最小，该设置下的I/O成本和运行时间也都是最小的。由于篇幅限制，这里省略了那些结果。

---

由于QALSH和C2LSH的基基数$m$都是通过公式(8)计算的，我们同样自动计算C2LSH的$w$以最小化$m$（或最大化$\left(\xi_{1}-\xi_{2}\right)$），并得到对于$c=2$时$w=2.184$。表2展示了在$w$的五种设置下C2LSH的索引大小。有趣的是，我们的实验结果显示C2LSH在$w=2.184$设置下的表现优于其默认值$w=1.0$的情况。由于篇幅限制，这里的相关结果也被省略了。

---

我们的实验表明，通过最小化基基数$m$来自动确定桶宽$w$的有效性。在后续的实验中，我们只展示$w$设置为自动确定值的QALSH和C2LSH的结果。具体来说，对于$c=2$，QALSH的$w=2.719$，C2LSH的$w=2.184$。由于LSB-Forest的哈希函数数量不受$w$的影响，我们仍然使用其手动设置的值$w=4.0$。

### 6.3 索引大小和索引时间

我们在表3中列出了所有三种方法在四个数据集上的索引大小，其中$L$是LSB-Forest使用的LSB树的数量，而$m$是C2LSH和QALSH使用的哈希表数量。每种方法都需要$2m$或$2L$个缓冲页面来进行$c$-ANN搜索，在实验中我们将缓冲页面的数量设置为$2\max(m,L)$，以确保LSB-Forest或C2LSH有足够的缓冲页面。根据表3，QALSH的$m$值始终小于C2LSH的$m$值，并且除了在Mnist数据集上，也始终小于LSB-Forest的$L$值。换句话说，QALSH只需要较少数量的缓冲页面。

---

对于每个数据集，QALSH和C2LSH的索引大小比LSB-Forest的索引大小大约小两到三个数量级。LSB-Forest在每个LSB树的叶页面中存储对象的坐标和Z序值。较大的数据维度$d$导致存储坐标的开销较大。此外，每个Z序值有$uv$位，其中$u=O(\log_2 d)$，$v=O(\log dn)$。总体来说，LSB-Forest的索引大小以$O(d^{1.5}n^{1.5})$的速度增长。因此，LSB-Forest在高维数据集上产生了极大的空间开销。相比之下，QALSH和C2LSH的索引大小与$d$无关。同时，QALSH和C2LSH仅在其哈希表中存储对象ID和投影，而在计算欧几里得距离时需要使用随机I/O来访问坐标。QALSH的索引大小约为C2LSH的$29\%$至$57\%$。它们索引大小之间的差异主要是由于每种方法所需的哈希表数量不同。QALSH使用的更简单的查询感知LSH函数导致了较少数量的哈希表。

---

构建索引的实际时间（即索引时间）通常与索引大小成正比。在每个数据集上，QALSH的索引时间是最短的，而LSB-Forest的索引时间是最长的。具体而言，在包含一百万个数据对象的Sift数据集上，LSB-Forest构建索引花费超过2.5小时，C2LSH大约需要3分钟，而QALSH仅需约50秒。

### 6.4 整体比率

我们通过将$k$从1变化到100来评估$2-k$-ANN搜索的整体比率。结果如图6所示。

所有方法都获得了令人满意的整体比率，这些比率远小于理论界限$c^{2}=4$。与LSB-Forest相比，QALSH和C2LSH实现了显著更高的准确性。QALSH和C2LSH的整体比率始终保持在1.05以下，而在四个数据集上LSB-Forest的最小整体比率仍然大于1.24。QALSH的整体比率基本上与C2LSH相同。这是因为影响准确性的参数在这两种方法中被设置为相同的值。

---

随着$k$的增加，QALSH和C2LSH的整体比率倾向于增加，而LSB-Forest的整体比率则倾向于减少。实际上，QALSH和C2LSH从大小为$\beta n+k-1$的候选集中返回最佳的$k$个对象。随着$k$的增加，仅检查额外的$k-1$个候选者以可能改进比率。相比之下，LSB-Forest倾向于检查相对更多的对象。

### 6.5 I/O成本

我们通过将$k$从1变化到100来评估$2-k$-ANN搜索的I/O成本。结果如图7所示。

与QALSH和C2LSH相比，LSB-Forest在低维和中维数据集（即Mnist、Sift和LabelMe）上需要的I/O成本要小得多。然而，其整体比率远大于QALSH和C2LSH。对于高维数据集P53，QALSH的I/O成本低于LSB-Forest。这是因为LSB-Forest的I/O成本随着数据维度$d$的增加而单调增加，而QALSH和C2LSH的I/O成本与$d$无关。与C2LSH相比，QALSH使用的I/O成本约为C2LSH的$49\%$至$76\%$，但仍然达到了相同的准确性。

---

当$k$增加时，LSB-Forest的I/O成本增加较为平缓，而QALSH和C2LSH的I/O成本增加更为明显。这是因为LSB-Forest已经在每个LSB树中存储了对象的坐标，因此无需额外的I/O成本即可计算欧几里得距离。然而，QALSH和C2LSH都不在哈希表中存储坐标，因此在最坏情况下，每处理一个候选对象都需要一次随机I/O。随着$k$的增加，候选对象的数量增加，相应地，QALSH和C2LSH的I/O成本也随之增加。

### 6.6 运行时间

我们通过将$k$从1变化到100来研究$2-k$-ANN搜索的运行时间。结果如图8所示。

有趣的是，即使其I/O成本低于QALSH，在中维数据集LabelMe上LSB-Forest的运行时间仍大于QALSH。虽然在高维数据集P53上LSB-Forest的I/O成本略高于QALSH，但其运行时间惊人地比QALSH大了两个数量级以上。实际上，随着数据维度$d$的增加，LSB-Forest倾向于花费更多的CPU时间来查找Z序值最接近查询Z序值的候选对象。正如在第6.3节中解释的那样，较大的$d$导致更长的Z序值，因此处理Z序值的时间成本更高。值得一提的是，虽然QALSH在中维和高维数据集上比LSB-Forest更高效，但它也实现了远高于LSB-Forest的搜索准确性。

---

在低维数据集（即Mnist和Sift）上，QALSH的运行时间大于LSB-Forest，但QALSH的搜索准确性远高于LSB-Forest。请注意，在这组实验中，我们将$c$设置为2.0以使LSB-Forest能够达到最佳性能。实际上，我们可以通过设置更大的$c$值来权衡QALSH的准确性和效率。更多解释将在第6.7节给出。

---

在所有四个数据集上，QALSH的运行时间始终小于C2LSH。尽管QALSH可能在定位锚桶时使用更多时间，但其I/O成本显著小于C2LSH，如图7所示。由于I/O成本是主要开销，QALSH的总运行时间小于C2LSH。

### 6.7 性能与近似比

我们研究了近似比$c$如何影响QALSH的性能。由于篇幅限制，我们仅在图9中展示了Mnist和P53的结果。我们从另外两个数据集的结果中观察到了类似的趋势。

---

QALSH在较小的$c$值下实现了更好的查询质量。根据图9(a)和9(b)，QALSH的整体比率随着$c$的减小而单调下降。当$c$设置为1.5时，即使是对于$k=100$，QALSH的整体比率也非常接近1.0。这意味着，通过使用$c<2.0$，QALSH能够返回极其准确的结果。同时，当$c$设置为3.0时，QALSH在这两个数据集上的整体比率仍然小于1.07。

---

根据图9(c)到9(f)，QALSH的I/O成本和运行时间都随着$c$的增加而单调减少。具体来说，在$c=3.0$设置下的I/O成本分别是$c=1.5$设置下在Mnist和P53数据集上的约25%和50%。对于QALSH的运行时间也可以观察到类似的趋势。因此，在某些对搜索效率有严格要求的情况下，我们可以通过设置更大的$c$值来权衡QALSH的准确性和效率。例如，对于低维数据集Mnist，$c=3.0$的QALSH运行时间与图8(a)中所示的LSB-Forest运行时间相当，但$c=3.0$的QALSH整体比率仍然远小于LSB-Forest。

### 6.8 QALSH与C2LSH对比

我们通过将C2LSH的$m$和$l$设置为与QALSH相同来研究两者在四个数据集上的性能。由于篇幅限制，我们仅在图10中展示了Mnist和P53的结果，在另外两个数据集上观察到了类似的趋势。

---

根据图10(a)和10(b)，QALSH的整体比率远小于C2LSH。实际上，通过设置相同的$m$和$\beta$值，根据第3.2节讨论的公式(8)，$(\xi_{1}-\xi_{2})$的最大值小于$(p_{1}-p_{2})$。因此，在相同的$m$和$l$下，C2LSH的错误概率$\delta$被迫增加，使得QALSH相应地享有更高的准确性。从图10(c)到10(f)，QALSH还享有更低的I/O成本和运行时间。对于P53中的特殊情况，当$k \leq 30$时，C2LSH的运行时间略少于QALSH。这是因为它们的I/O成本彼此接近，但QALSH需要更多时间来定位锚桶。

---

我们还通过将QALSH的$m$和$l$设置为与C2LSH相同来研究两者的性能，并在四个数据集的结果中观察到了类似的趋势。

### 6.9 总结

基于实验结果，我们得出以下结论。首先，为了达到相同的查询质量，QALSH比C2LSH消耗更少的空间进行索引构建。此外，QALSH比C2LSH更加高效，因为其I/O成本和运行时间都远小于C2LSH。其次，当QALSH和C2LSH使用相同大小的索引时，QALSH享有更低的I/O成本和运行时间，并且实现了更高的准确性。第三，QALSH可以与任何$c>1$一起工作。通过设置$c<2.0$可以找到更准确的查询结果，但这会以增加I/O为代价。相比之下，LSB-Forest和C2LSH仅适用于整数$c \geq 2$。最后，与LSB-Forest相比，虽然QALSH在低维和中维数据集上使用的I/O和运行时间更多，但它使用了更小的索引来实现更高的准确性。对于高维数据集，QALSH在所有四项评估指标上均优于LSB-Forest。这是因为数据维度对依赖空间填充曲线（如Z序）的任何方法都有影响。

## 7. 相关工作

局部敏感哈希（LSH）函数最早由Indyk和Motwani提出，用于汉明空间[7]。Datar等人引入了基于$p$稳定分布的欧式空间中的LSH函数[2]，这导致了用于处理内存数据集的E2LSH。E2LSH为一系列搜索半径构建物理哈希表，因此导致存储空间的巨大消耗。一种节省空间的替代方案是使用单一的“魔法”半径来处理不同的查询[5]，然而这样的“魔法”半径很难确定[15]。

---

虚拟重哈希在LSBForest[15]和C2LSH[4]中被隐式或显式地使用以避免为每个搜索半径构建物理哈希表。由于使用了查询感知的LSH函数，QALSH中使用的虚拟重哈希比C2LSH更加简单有效。具体来说，QALSH的虚拟重哈希不涉及任何随机移位和向下取整操作，并且是以对称方式进行的。LSB-Forest、C2LSH和QALSH在查询质量上都有理论保证。最近，一个名为SK-LSH的LSB-Forest变体[11]利用线性顺序而不是Z顺序编码哈希值，但在查询质量上没有任何理论保证。

---

无论查询无关还是查询感知的欧式空间中的LSH函数都涉及到随机投影。随机投影也被MEDRANK[3]用于将对象投影到一组$m$条随机线上。但是，MEDRANK并不将随机线分割成桶。如果一个对象在至少$\frac{m}{2}$条随机线上被认为是最接近查询的对象，则报告其为查询的$c$-ANN。$\frac{m}{2}$的中位数阈值被C2LSH和QALSH中的碰撞阈值所泛化，用于寻找频繁对象。关于随机投影的一个经典结果是Johnson-Lindenstrass引理[9]，该引理指出通过沿着$m$条随机线投影$d$维欧氏空间中的对象，原始$d$维中的距离可以在$m$维中近似保持不变。在最近关于欧式空间中内存数据集的LSH工作中，Andoni等人[1]建议用数据感知投影代替随机投影（即数据无关投影）。然而，LSH方案仍然是查询无关的。最近，Sun等人[14]介绍了另一种基于投影的方法SRS。SRS仅使用6次随机投影将高维数据对象转换为低维对象，以便它们可以被单个$R$-树索引。虽然C2LSH的整体比率优于SRS，但SRS使用非常小的索引并且也产生了更少的I/O成本。由于SRS只利用了6到10次随机投影，自然会想到能否执行几组这样的投影。然而，在SRS中哪一组投影能带来最佳整体比率尚不清楚。直观上，由于SRS基于不到10次投影，而C2LSH和QALSH利用了更多的投影，所以SRS不如C2LSH和QALSH稳定。

## 8. 结论

在本文中，我们引入了一种新颖的查询感知LSH函数概念，并据此提出了一种新的LSH方案QALSH，用于高维欧式空间中的$c$-近似最近邻（$c$-ANN）搜索。查询感知LSH函数是一种与查询感知桶划分相结合的随机投影。该函数不需要传统LSH函数所需的随机移位。查询感知LSH函数还使QALSH能够与任何近似比$c>1$一起工作。相比之下，最先进的LSH方案如C2LSH和LSB-Forest仅适用于整数$c \geq 2$。我们的理论分析表明，QALSH为$c$-ANN搜索实现了质量保证。我们还提出了一种自动决定QALSH中使用的桶宽$w$的方法。在四个真实数据集上的实验结果表明，QALSH优于C2LSH和LSB-Forest，尤其是在高维空间中。

## 附录

## A. 引理3的证明

证明：在从下方限定$\operatorname{Pr}\left[\mathcal{P}_{1} \cap \mathcal{P}_{2}\right]$并因此证明引理3之前，我们需要先对$\mathcal{P}_{1}$和$\mathcal{P}_{2}$给出下界。

现在展示$\operatorname{Pr}\left[\mathcal{P}_{1}\right] \geq 1-\delta$的部分证明细节。设$S_{1}=\{o \mid\|o-q\| \leq R\}$。对于$\forall o \in S_{1}, \operatorname{Pr}\left[\mathcal{P}_{1}\right]=$ $\operatorname{Pr}[\# \operatorname{Col}(o) \geq \alpha m]=\sum_{i=\lceil\alpha m\rceil}^{m} C_{m}^{i} p^{i}(1-p)^{m-i}$，其中$p=$ $\operatorname{Pr}\left[\left|H_{a_{j}}^{R}(o)-H_{a_{j}}^{R}(q)\right| \leq \frac{w}{2}\right] \geq p_{1}>\alpha, j=1,2, \ldots, m$。然后遵循基于Hoeffding不等式[6]的相同推理，如同C2LSH的引理1中那样，我们有$\operatorname{Pr}\left[\mathcal{P}_{1}\right] \geq$ $1-\delta$，当$m=\left\lceil\max \left(\frac{1}{2\left(p_{1}-\alpha\right)^{2}} \ln \frac{1}{\delta}, \frac{1}{2\left(\alpha-p_{2}\right)^{2}} \ln \frac{2}{\beta}\right)\right\rceil$时成立。

类似地，使用相同的$m$，我们有$\operatorname{Pr}\left[\mathcal{P}_{2}\right]>\frac{1}{2}$。
对于$(R, c)$-NN搜索，由于QALSH在$\mathcal{P}_{1}$或$\mathcal{P}_{2}$任一条件满足时终止，我们有$\operatorname{Pr}\left[\mathcal{P}_{1} \cup \mathcal{P}_{2}\right]=1$。我们还有公式：$\operatorname{Pr}\left[\mathcal{P}_{1} \cup \mathcal{P}_{2}\right]=\operatorname{Pr}\left[\mathcal{P}_{1}\right]+\operatorname{Pr}\left[\mathcal{P}_{2}\right]-\operatorname{Pr}\left[\mathcal{P}_{1} \cap \mathcal{P}_{2}\right]$。因此，我们可以如下从下方限定$\operatorname{Pr}\left[\mathcal{P}_{1} \cap \mathcal{P}_{2}\right]$：

$$
\begin{aligned}
\operatorname{Pr}\left[\mathcal{P}_{1} \cap \mathcal{P}_{2}\right] & =\operatorname{Pr}\left[\mathcal{P}_{1}\right]+\operatorname{Pr}\left[\mathcal{P}_{2}\right]-\operatorname{Pr}\left[\mathcal{P}_{1} \cup \mathcal{P}_{2}\right] \\
& \geq 1-\delta+\frac{1}{2}-1=\frac{1}{2}-\delta
\end{aligned}
$$

因此引理3得证。

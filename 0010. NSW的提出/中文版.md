# Approximate nearest neighbor algorithm based on navigable small world graphs  



# 0. Abstract

我们提出了一种新颖的方法来解决度量空间中的近似 $k$-最近邻搜索问题。该搜索结构基于可导航的小世界图，图中的顶点对应于存储的元素，边表示它们之间的链接，并使用一种变体的贪婪算法进行搜索。可导航的小世界图通过保留在构建开始时产生的旧德劳内图近似链接而简单创建。该方法非常通用，适用于任意度量空间，同时也很简单。该算法处理插入与查询的方式相同：通过找到插入元素的近似邻居并将其连接到这些邻居。搜索和插入均可并行进行，仅需结构的局部信息。该结构可以分布式实现。概率 $k$-最近邻查询的准确性可以在不重建结构的情况下进行调整。

---

在欧几里得空间进行的仿真表明，使用所提出算法构建的结构具有小世界导航特性，插入和搜索复杂度为 $\log^2(n)$，在固定准确度下表现良好，尤其在高维度情况下。在 CoPHiR 数据集上的仿真显示，在大数据集(在固定召回率下相比排列索引减少了一个数量级的度量计算)中其高效性。要实现 0.999 的召回率，仅需评估 1000 万个 208 维向量数据集的 $0.03%$。在双 Intel X5675 Xeon 服务器节点上，使用 Java 实现，对于召回率 0.93，处理速度可达 2800 查询/秒。



# 1. Introduction

任何软件系统的可扩展性都受到其数据结构可扩展性的限制。像 BitTorrent 或 Skype 这样的大规模分布式系统基于分布式哈希表。虽然这些结构具有良好的可扩展性，但它们的搜索功能仅限于精确匹配。这一限制产生的原因是，元素值的微小变化会导致哈希值的大幅且混乱的变化，从而使基于哈希的方法无法用于区间搜索和相似性搜索问题。

---

然而，许多应用(如模式识别与分类[1]、基于内容的图像检索[2]、机器学习[3]、推荐系统[4]、相似 DNA 序列搜索[5]、语义文档检索[6])需要相似性搜索，而不仅仅是精确匹配。k -最近邻搜索(k -NNS)问题是相似性搜索的数学形式化。它的定义如下：我们需要从有限对象集 $X \subseteq \mathcal{D}$ 中找到与给定查询 $q \in \mathcal{D}$ 最接近的 k 个对象的集合 $P$，其中 $\mathcal{D}$ 是所有可能对象的集合(数据域)。两个对象 $o^{\prime}, o^{\prime \prime} \in \mathcal{D}$ 的接近性或相似性通过距离函数 $\delta\left(o^{\prime}, o^{\prime \prime}\right)$ 定义。

---

k-NNS 问题的一个简单解决方案是计算查询 $q$ 与 $X$ 中每个元素之间的距离函数 $\delta$。这导致线性搜索的时间复杂度，远不如精确匹配搜索结构的可扩展性，使得简单版本的 k-NNS 几乎无法用于大型数据集。

---

我们提出了一种最近邻搜索问题的解决方案：一个由图 $G(V, E)$ 表示的数据结构，其中 $X$ 中的每个对象 $o_i$ 唯一地与图中顶点 $v_i$ 相关联。从数据集 $X$ 中搜索与查询 $q$ 最近的元素变成在图 $G$ 中搜索顶点。

---

这为构建去中心化的相似性搜索导向存储系统提供了机会，其中物理数据的位置不依赖于内容，因为每个数据对象可以放置在任意物理机器上，并可以像 p2p 系统一样通过链接与其他对象连接。

---

在具有度量对象的图中，贪婪搜索算法是基本的顶点搜索算法之一。它的实现简单，可以从任何顶点启动。为了使算法正确工作(始终返回精确结果)，网络必须包含德劳内图作为其子图，而德劳内图是与沃罗诺伊镶嵌对偶的。然而，德劳内图存在一些主要缺点：它需要对度量空间的内部结构有一定了解，并且受到维度诅咒的影响。此外，对于上述应用，并不要求搜索的精确性。因此，寻找精确最近邻的问题可以用近似最近邻搜索来替代，因此我们不需要支持完整的/精确的德劳内图。

---

具有贪婪搜索算法的对数可扩展性的图称为可导航的小世界图，这在欧几里得空间中是众所周知的。值得注意的是，像 [10] 这样的非可导航小世界模型并不具备这一特性。尽管图中存在短路径，但贪婪算法并不倾向于找到这些路径，最终导致幂律搜索复杂度。为构建可导航小世界图提出的解决方案通常更为复杂，需要采样、迭代、重连等步骤 [11-14]。我们证明，即使在没有对度量空间内部结构(如维度或数据密度分布)事先了解的情况下，也可以通过更简单的技术实现小世界导航特性。

---

在本文中，我们提出了一种简单的算法，用于基于可导航小世界网络拓扑构建数据结构，图 $G(V, E)$ 使用贪婪搜索算法来解决近似 k-最近邻搜索问题。图 $G(V, E)$ 包含德劳内图的近似，并具有长距离链接以及小世界导航特性。我们提出的搜索算法能够选择搜索的准确性，而无需修改结构。所提出的算法不使用坐标表示，也不假设欧几里得空间的属性，因为它们仅基于比较对象与查询之间的距离，因此原则上适用于一般度量空间(甚至非度量空间)中的数据。仿真结果显示，对于欧几里得数据，算法对维度的依赖性较弱。



# 2. Related Work

Kd-tree [15] 和四叉树 [16] 是最早研究 kNN 问题的工作之一。它们在 2-3 维空间中表现良好(实际搜索复杂度接近 $O(\log n)$)，但对这些结构的最坏情况分析 [17] 指出，搜索复杂度为 $O\left(d^* N^{1-1 / d}\right)$，其中 $d$ 是维度。

---

在文献 [8] 中提出了一种精确近邻搜索结构，使用德劳内图与贪婪搜索算法。作者展示了在一般度量空间中找到精确德劳内图的不可行性，并为保持搜索的精确性而采用了回溯方法。所提数据结构的构建时间为 $O\left(n \log ^2 n / \log \log n\right)$，在高维情况下搜索时间为 $O\left(n^{1-\theta(1 / \log \log n)}\right)$，在低维情况下为 $O\left(n^\alpha\right),(0<\alpha<1)$。

---

总体而言，目前在高维度度量空间中没有有效的精确 NNS 方法。这背后的原因在于维度的“诅咒” [18]。为了避免维度诅咒，同时保持对元素数量的对数成本，提出了降低 kNN 问题解决要求的方案，使其变为近似(近似 kNN)。

---

近似邻居搜索有两种常用的定义。一类方法提出了以预定义的准确度 $\varepsilon$ 进行搜索($\varepsilon$-NNS)。这意味着查询与结果中任何元素之间的距离不超过查询到其真实第 k 个最近邻的距离的 $1+\varepsilon$ 倍。这类方法在文献 [19-23] 中有所描述。另一类方法则提供了找到查询的真实 k 个最近点的概率保证 [24-31]，使用“召回率”(找到的真实 k 个最近元素的比例)。

---

一些结构 [19-23] 仅适用于欧几里得空间。其他方法 [24-31] 则适用于一般度量空间。更多信息可以在综述 [32,33] 中找到。

---

置换索引(PI) [25,34] 是一种高效的非分布式算法，适用于一般度量空间。PI 背后的理念是用一组引用的置换表示每个数据库对象，这些置换称为 permutants，并按距离对象的远近排序。对象之间的距离通过其各自置换之间的距离来暗示。已知 PI 即使对于具有高内在维度的数据集，也具有高精度和召回率。

---

Houle 和 Sakuma 的工作 [26] 特征化了一种基于选择最近邻的概率树状结构，用于在一般度量空间中进行近似最近邻搜索。该算法在真实数据上进行了模拟。Chávez 和 Tellez 的工作 [27] 也在其构造算法中使用了最近邻的确定，并采用贪婪算法进行搜索。该算法的主要缺点是随着数据集大小的增加，扩展性较差(线性)。这两种算法都提供了高召回率，只需评估数据集的一小部分。

---

Kleinberg 的工作 [9] 展示了使用可导航的小世界网络结合贪婪搜索算法寻找最近邻的可能性。该算法依赖于遵循链接长度概率幂律 $r^{-\gamma}$ 的随机长距离链接进行导航，并使用二维晶格确保结果的正确性。为了具备可导航的小世界特性，链接长度分布必须具有特定的 $\gamma$ 值。在 Voronet [35] 中，Kleinberg 的方法通过构建二维德劳内镶嵌而扩展到任意二维数据，而不是使用常规晶格。在他们的下一项工作 [13] 中，他们削弱了对搜索精确性的要求，以避免在 $d$ 维欧几里得空间中出现维度诅咒。该算法通过选择 $3 d+1$ 个邻居来逼近德劳内图，以最小化相应沃罗诺伊单元的体积。该算法在很大程度上依赖于德劳内图近似的质量，需要反复迭代以达到可接受的准确性，并且原则上仅在欧几里得空间中有效。这项工作以及其他一些工作 [11-14] 还提出了一些复杂的算法，以支持 Kleinberg 的幂律链接长度分布，具有特定的指数值。



# 3. Core idea  

结构 $S$ 被构建为一个可导航的小世界网络，表示为图 $G(V, E)$，其中来自集合 $X$ 的对象唯一映射到集合 $V$ 的顶点。边的集合 $E$ 由结构构造算法确定。由于每个顶点都唯一映射到集合 $X$ 中的一个元素，因此我们将“顶点”、“元素”和“对象”这些术语互换使用。我们将共享边的顶点称为“朋友”。与顶点 $v_i$ 共享公共边的顶点列表称为顶点 $v_i$ 的朋友列表。

---

我们使用贪婪搜索算法的变体作为 $\mathrm{k}-\mathrm{NN}$ 搜索的基础算法。该算法从一个元素遍历到另一个元素，每次选择一个未访问的朋友，该朋友与查询的距离最近，直到达到停止条件。有关算法的详细描述，请参见第 4.2 节。

---

需要注意的是，图中的链接(边)有两个不同的用途：

1. 有一个短程链接的子集，用作贪婪搜索算法所需的德劳内图的近似 [7]。
2. 另一个子集是长程链接，用于贪婪搜索的对数缩放。长程链接负责构建图的可导航小世界特性 [9]。

---

The structure performance is illustrated in Fig. 1  

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922141654774.png" alt="image-20240922141654774" style="zoom: 25%;" /> 

图 1. 结构的图形表示。圆圈(顶点)是度量空间中的数据，黑色边是德劳内图的近似，红色边是用于对数缩放的长程链接。箭头显示了贪婪算法从入口点到查询(以绿色显示)的示例路径。(有关此图例中颜色引用的解释，请参见本文的网络版本)

---

该结构的构建基于对所有元素的连续插入。对于每个新进入的元素，我们从结构中找到其最近邻的集合(德劳内图的近似)。该集合与元素相连，反之亦然。随着越来越多的元素插入结构，之前作为短程链接的边现在变为长程链接(详细信息见第 5 节)，从而形成一个可导航的小世界。结构中的所有查询是独立的，可以并行进行，如果元素随机分布在物理计算节点上，则查询处理负载可以在物理节点之间共享。



# 4. Search algorithm  

## 4.1. Basic greedy search algorithm  

基本的单个最近邻搜索算法从图 $G(V, E)$ 的一个顶点遍历到另一个顶点。该算法需要两个参数：查询和顶点 $V_{\text{entry\_point}} \in V[G]$，后者是搜索的起始点(入口点)。从入口点开始，算法计算查询 $q$ 到当前顶点的朋友列表中每个顶点的距离，然后选择距离最小的顶点。如果查询与所选顶点之间的距离小于查询与当前元素之间的距离，算法就会移动到所选顶点，并将其设为新的当前顶点。当算法到达局部最小值时停止：即朋友列表中不包含比该顶点更接近查询的顶点。算法:

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922142717261.png" alt="image-20240922142717261" style="zoom: 20%;" /> 

---

对于查询 $q \in \mathcal{D}$，局部最小值的元素可能是集合 $X$ 中与查询 $q$ 之间真正最近的元素，也可能是一个错误的最近邻。

---

如果结构中的每个元素在其朋友列表中都有所有的 Voronoi 邻居，则这将排除假全局最小值的存在。维持这一条件等同于构造 Delaunay 图，该图是 Voronoi 图的对偶。

---

实际上，对于一个未知的度量空间，确定精确的 Delaunay 图是不可能的(不包括完全图的变体)，因此我们无法避免假全局最小值的存在。对于上述定义的近似搜索问题，这并不构成障碍，因为近似搜索并不需要整个 Delaunay 图。

---

需要注意的是，与文献 [19-23] 中定义的 ANN 问题不同，在这些文献中，它是以 $\varepsilon$-邻域的形式表达的。与 [24-31] 中的情况一样，在我们的结构中，对算法的最近邻结果和真实最近邻结果之间的绝对距离没有限制。结果的保证是概率性的，意味着只有找到真实最近邻的概率是保证的。当数据分布高度倾斜且很难为所有区域同时定义一个值 $\varepsilon$ 时，使用这种搜索效果的定义可能更方便。

## 4.2. k-NN search modification  

在我们之前的工作 [36] 中，我们使用了一种简单的 $\mathrm{k}-\mathrm{NN}$ 搜索算法，该算法基于一系列 m 次搜索并返回最佳结果。随着每次后续搜索未能找到最近邻的概率呈指数下降，允许在不需要重建结构的情况下提高准确性。

---

在本工作中，我们提出了一个更复杂的 $\mathrm{k}-\mathrm{NN}$ 算法，具有两个关键修改：

1. 我们使用不同的停止条件。该算法在未访问的元素上迭代(即那些链接列表尚未读取的元素)，寻找与查询最接近的元素。它在下一次迭代时，当查询的 k 个最近结果不再改变时停止。简单来说，算法以贪婪的方式不断探索最近元素的邻域，只要它能在每一步改善已知的 k 个最近元素。
2. 访问过的元素列表 visitedSet 在一系列搜索中共享，从而防止无用的重复提取。

使用 TreeSet 有序列表允许根据与查询的接近程度存储评估过的元素，从而轻松提取最近的元素，这在步骤 6、9 和 20 中是必需的。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922143301727.png" alt="image-20240922143301727" style="zoom:23%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922143324565.png" alt="image-20240922143324565" style="zoom:23%;" /> 

---

如果 $m$ 足够大，该算法变成穷举搜索，假设入口点从不重用。如果网络的图具有小世界特性，则可以在与数据集大小的对数成比例的随机步骤中选择一个随机顶点，而无需进行任何度量计算，这不会导致整体的对数搜索复杂度。



# 5. Data insertion algorithm  

由于我们构建了Delaunay图的近似，因此在构建算法的细节上有很大的灵活性。主要目标是最小化假全局极小值的概率，同时保持链接的数量尽可能少。一些方法基于对所用度量空间的拓扑知识。例如，在[13]中，建议构建一个近似Delaunay图，以最小化Voronoi区域的体积(通过蒙特卡洛方法计算)，在每个图中每个顶点的固定边数下实现(通过对图中每个节点的邻居选择进行多次迭代)。我们提议通过逐个插入元素来组装结构，并在每一步与已经在结构中的$f$个最近对象连接。我们的方法基于一个想法，即Voronoi邻居的元素集合与$f$个最近元素的交集应该是大的。

---

图可以通过逐个插入所有元素来构建。对于每个新来的元素，我们从结构中找到其最近邻的集合(Delaunay图的近似)。该集合与该元素相连，反之亦然。这种方法的一个优势(已在一维数据中经验性地证明)是，通过这种算法创建的图，即使在随机顺序到达的一般度量数据中，也具有小世界导航特性，而无需额外的安排。

---

为了确定$f$个最近元素的集合，我们使用近似kNN搜索算法(见第4.2节)。该算法需要三个参数：要插入结构中的对象，以及两个正整数：$f$(要连接的最近邻数量)和$w$(多次搜索的数量)。

---

首先，算法使用k-NNSSearch程序(见第4.2节)确定包含$f$个局部最近元素的邻居集合。之后，将新对象与集合中的每个对象连接，反之亦然。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922143824107.png" alt="image-20240922143824107" style="zoom:30%;" />  

## 5.1. Choice of parameters  

参数$w$影响构造算法中最近邻的确定准确性(召回率)[36]。如第4.2节所述，将$w$设置为一个大数等同于在结构中对最近元素进行的穷举搜索，从而实现完美的召回。其思路是将$w$设置得足够大，以使召回率接近1(例如0.95-0.99)。较小的召回率会导致错误链接的比例增加，从而仅增加算法的复杂性，而我们的实验表明，插入时将召回率提高到0.99以上对搜索质量没有可测量的影响。测试还表明，最佳召回率的$w$在数据集大小变化时缓慢(对数)变化，因此如果我们已经知道接近良好召回的近似$w_0$，我们可以进行随机查询测试，首先将$m$设置得远大于$w_0$(例如$m=2^*w_0+10$)，假设$m$足够大，使得搜索结果是真正的$k$个最近邻，然后增加$w$，重复测试直到达到较高的召回率(例如0.95-0.99)。该操作的复杂性与数据集大小呈对数关系，因此不会影响整体构造复杂性。

---

测试表明[36]，至少对于维度$d=1 \ldots 20$的欧几里得数据，连接的邻居数量$f$的最佳值约为$3d$，使得内存消耗与维度成线性关系。较小的$f$值可以用来减少单次搜索的复杂性，但会牺牲其召回质量。



# 6. Test results and discussion  

## 6.1. Test data  

我们实现了上述算法，以验证我们对结构可扩展性的假设，并评估其性能。在我们的测试中，使用了一台基于两个Intel Xeon X5675六核处理器，配备192GB RAM的工作站。算法是用Java编写的，使用了Oracle Java平台。

---

我们使用了以下测试数据集：

- 均匀分布的随机点，采用$\mathrm{L}_2$(欧几里得距离)距离函数(最多$5 \times 10^7$个元素，最多50维)。
- 从CoPHiR [38] 数据集中提取的子集，以便与其他工作进行比较。该数据集提取了208维特征向量，采用$\mathrm{L}_1$度量作为距离函数。在搜索过程中找到30个近似最近邻。

## 6.2. Small world navigation properties  

为了验证所提结构的小世界导航特性，我们测量了贪婪搜索算法(见第4.1节)在不同维度的欧几里得空间中引发的平均路径长度(见图2)。$f$ 的值设置为 $3 d$。图表清晰地显示了贪婪搜索路径长度与数据集大小之间的对数依赖关系，证明了所提结构是一个可导航的小世界。值得注意的是，对于更高的维度，依赖关系较弱。这并不是由于$f$的不同值(它们对路径长度的影响并不显著)，而可能是由于集合的“拓扑直径”缩短。当贪婪算法遇到长距离链接时，它会选择靠近查询方向的元素，而忽略其他方向，使搜索呈现出准一维的特性。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922145032846.png" alt="image-20240922145032846" style="zoom:30%;" /> 

图2. 贪婪搜索算法对不同维度欧几里得数据引发的平均跳数 $(\mathrm{k}=10, \mathrm{w}=20)$。可导航的小世界特性从对数缩放中显而易见。

---

如果我们添加逐渐扩大集合体积的元素(即非随机插入)，或者更新元素的链接，删除那些与最近的 $f$ 个元素不连接的链接，那么对数复杂度会受到影响。这些事实表明，图的可导航小世界特性是基于保持初始构建阶段创建的 Delaunay 近似链接的长距离链接。

## 6.3. Parallel and distributed operation  

我们提出的方法的一个关键特点是，结构以独立对象的形式表示，仅通过链接连接。这些元素可以位于不同的计算机上，共享负载。基于 Apache Tomcat 开发了一个分布式原型。服务器之间的通信基于客户端-服务器模型。客户端(可以是任何服务器)执行第 4.2 节中描述的算法，但排除了第 12 步，因为该步骤需要从其他服务器获取链接列表。为了提高性能(但增加内存需求)，原型中的每个元素的链接列表还包含列表中每个链接对象的副本。这使得在算法的每个步骤中，服务器之间节省了大约 $6d$ 次数据请求。

---

我们早期在 4 节点计算机集群上进行的 $d=1$ 测试显示，这种方法导致总吞吐量几乎与系统中的处理核心数量呈线性扩展。未来的测试需要展示分布式原型在不同数据下的工作情况。

---

我们还进行了元素的并行插入实验。对于 $d=10$，数据库中的前 1000 个元素是串行插入的。之后，插入由 16 个并行线程进行。尽管数据库规模非常小，且可能存在许多组装错误，但我们在测试中没有发现搜索准确性的可测下降，从而允许在没有额外同步手段的情况下进行大规模并行构建。

## 6.4. k-Nearest neighbor search complexity scaling  

我们的主要质量度量是召回率：即相关结果与通过近似搜索获得的对象之间的比率。我们通过将搜索中真实结果的平均数量除以 $k$(要查找的邻居数量)来计算召回率(因此其范围从零到一)。我们还测量了访问元素的比例，以评估搜索的复杂性。这个比例是通过将单次搜索中的总体度量计算次数除以元素的总数来计算的。

---

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922150110927.png" alt="image-20240922150110927" style="zoom: 33%;" /> 

图 3. 在单次 $10-\mathrm{NN}$ 搜索中，访问元素的平均比例与不同维度数据集大小的关系，召回率为 0.999。

---

我们在随机欧几里得数据上进行了测试，固定召回率为 0.999，覆盖不同的维度(从 3 到 50)。搜索召回率的固定值是通过调整参数 $m$ 来控制的。构造参数 $f$ 在所有试验中设置为 $3 d$(高召回的最佳值)，$w$ 则被更新以获得构造算法中的高召回(0.99)的测试数据。我们使用了 20,000 个随机元素作为查询，并在搜索中找到了 $\mathrm{k}=10$ 个最近邻。图 3 中的绘图以对数-对数比例呈现了不同维度的结果。它显示随着结构中元素数量的增加，访问元素的百分比降低，曲线逐渐接近直线(对应于幂律衰减)。这意味着在固定准确度下，搜索复杂性不会随着数据集的大小显著变化。固定召回率搜索的整体复杂性以及为了获得所需召回率的 $m$ 值在图 4 中描绘。复杂性按 $C \log^2(n)$ 进行扩展，这与预期相符。一个“对数”来自于可导航小世界的平均路径长度(见图 2)，另一个则来自于多次搜索的数量(见图 4)。

---

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922150136375.png" alt="image-20240922150136375" style="zoom:36%;" /> 

图 4. 为了获得 0.999 召回率，距离计算和 $m$ 值与数据集大小的关系，维度 $d=20$。度量计算次数的复杂度按 $C \log^2(n)$ 扩展。

## 6.5. Dimensionality scaling  

为了测试维度扩展性，我们在图 5 中绘制了约 2200 万元素数据集中单次 $10-\mathrm{NN}$ 搜索中访问元素的平均比例与维度的关系，召回率为 0.999。从图中可以明显看到一个“最佳”维度的平稳区间。随着数据集大小的增加，“最佳”维度的位置缓慢移动，这可能与高维度下更短的贪婪路径有关(见第 6.2 节)。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922150535489.png" alt="image-20240922150535489" style="zoom: 33%;" /> 

图 5. 在约 2200 万元素数据集中，单次 $10-\mathrm{NN}$ 搜索中访问元素的平均比例与维度的关系，召回率为 0.999。

## 6.6. CoPHiR, comparison with other works  

为了了解该算法相较于之前的 k-NN 算法的表现，我们在 CoPHiR 集合 [38] 的 1000 万条子集上进行了测试。我们使用相同的 $\mathrm{L}_1$ 距离，对从 XML 文档中提取的 208 维特征进行处理。在搜索过程中找到 $k=30$ 个最近邻。使用了来自数据集的 10 万个不同元素作为查询。结构的构建通过 16 个线程并行完成，耗时约 2 小时。

---

由于在最优情况下 $\mathrm{f} \sim 30-40$(有效维度 10-13)，该算法在单次搜索时就能达到高召回率，因此我们比较了召回误差(1 减去召回率)，而不是召回率(见图 6，召回误差与访问元素的比例在对数坐标下的关系)。实现的结果甚至略优于预期的指数下降。仅评估了 $0.031 %$ 的数据库就能获得 0.999 的召回率，使搜索几乎精确。在吞吐量方面，当 $\mathrm{m}=1$ 且召回率约为 0.92 时，我们的 12 核测试系统可以并行执行约 2800 次搜索。图 6 的插图显示了在数据集大小增长时，单次 0.999 召回搜索中评估元素数量的对数增长。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922151346031.png" alt="image-20240922151346031" style="zoom: 33%;" /> 

图 6. 单次 k-NN 搜索中访问元素的平均比例与召回误差的关系，基于来自 CoPHiR 数据库的 1000 万个 208 维向量。插图显示了获取 0.999 召回率所需的距离计算量(纵轴)随数据集大小(横轴)的对数增长。

---

图 7. 关于与 NAPP [25] 的数据比较，参数 $K=7$。在 NAPP 中，$\sigma$ 的值选择是为了在固定的访问元素比例下获得最佳召回率。我们的算法在大数据集上非常有效，特别是在高召回的情况下，达到 0.999 的召回率时需要的度量计算量比其他算法少了超过一百倍。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922151614077.png" alt="image-20240922151614077" style="zoom:33%;" /> 

图 7. 单次 $\mathrm{k}-\mathrm{NN}$ 搜索中访问元素的平均比例与召回误差的关系，基于 1000 万个 CoPHiR 对象。

---

在低数量($10^4$)但高维度($d=1024$)的情况下与 Ordering Permutation 索引 [34] 的比较显示，小世界导航特性并未发挥关键作用，我们的算法表现更佳(对于我们的算法，约 65% 的数据库元素在 0.9 召回率下被访问，而 OP 的比例为 $42 %$)。



# 7. Conclusions and open problems

我们提出了一种将数据组织为可导航的小世界图结构的方法，适用于度量空间中的分布式近似 k 最近邻搜索。该算法不使用数据和空间的内部拓扑信息(即仅依赖于集合中对象与查询之间的相对距离)，因此在原则上适用于任意度量数据。搜索是从概率的角度来看是近似的。

---

该算法非常简单，易于理解。图的可导航小世界特性源于保留了在构建初期创建的 Delaunay 近似链接的远程链接，它不使用度量空间结构。结构中的所有元素都是相同类型的，没有中心或根元素。该算法处理插入与查询的方式相同，通过为插入的元素找到近似邻居并将其连接到这些邻居上。算法在每一步仅使用局部信息，可以从任何顶点启动。

---

通过使用多个随机初始顶点的搜索，可以提高近似搜索的准确性，回忆错误随着访问元素数量的增加而指数下降。在低复杂度下，可以获得非常高的回忆(超过 0.999)，使我们的方法成为精确搜索结构的强劲竞争者。在固定准确度的情况下，既可以实现对数搜索和构建复杂度，并且这两者都可以并行执行而无需特别关注。实验表明，欧几里得数据的维度依赖性较弱。

---

与基于排列索引的其他算法的比较表明，在大数据集上，提出的方法在固定回忆的情况下在度量计算数量上可以提供更高的效率(提高一个数量级以上)。为了实现 0.999 的回忆(几乎是精确搜索)，只需评估 10 百万 208 维 CoPHiR 数据集中的 0.03% 的数据。对于 0.93 的回忆，单个服务器节点的处理速度可以达到 2800 查询/秒。

---

提出的改进 k-NN 搜索算法在大数据集上提供了非常高的效率和良好的可扩展性。然而，仍然有几种方法可以优化结构，以获得更低的复杂度和/或更好的准确性常数，例如：

- 更复杂的节点朋友选择算法(见第 5 节)。显然，将最近邻作为朋友的选择并不是近似 Delaunay 图的最佳方式，因为这种方法仅考虑新元素与候选者之间的距离，而忽略了候选者之间的距离。对度量空间内部结构的了解可以提升搜索性能。在文献 [13] 中显示，对于欧几里得空间，可以在固定每个节点的朋友数量的情况下显著提高单次搜索的准确性。
- 更复杂的可导航小世界创建算法。
- 更高效的多重搜索管理。

---

尽管该算法原则上可以应用于任意度量空间，并且在向量空间和 CoPHiR 中的性能已通过实验展示，但尚不清楚该算法的实际适用范围。需要进一步研究以澄清这一点。

---

总之，算法的简单性、有效性、高可扩展性(无论是在规模还是数据维度上)以及分布式特性为构建许多现实世界相似性搜索应用提供了良好的基础。
















































































































































































































































































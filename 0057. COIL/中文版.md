### COIL：在信息检索中重新审视基于上下文倒排列表的精确词汇匹配

#### 摘要

经典的信息检索系统（如BM25）依赖于精确的词汇匹配，并通过倒排列表索引高效地进行搜索。最近的神经信息检索模型转向对所有查询和文档术语进行软语义匹配，但它们失去了精确匹配系统的计算效率。本文提出了COIL，一种基于上下文精确匹配的检索架构，结合了语义词汇匹配。COIL的评分基于重叠的查询和文档词汇的上下文表示。新架构将上下文词汇表示存储在倒排列表中，结合了精确匹配的效率和深度语言模型的表示能力。我们的实验结果表明，COIL在相同或更小的延迟下优于经典词汇检索器和最先进的深度语言模型检索器。${ }^{1}$

## 1 引言

广泛使用的词袋（BOW）信息检索（IR）系统（如BM25）依赖于查询和文档术语之间的精确词汇匹配${ }^{2}$。最近神经信息检索的研究采取了不同的方法，计算所有查询和文档术语之间的软匹配以建模复杂的匹配关系。

---

神经信息检索模型向软匹配的转变试图解决词汇不匹配问题，即查询和相关文档使用不同的术语表示相同的概念（例如，cat与kitty）（Huang等，2013；Guo等，2016；Xiong等，2017）。后来，深度语言模型（LM）引入的上下文表示（Peters等，2018）进一步解决了语义不匹配问题，即相同的术语可以指代不同的概念（例如，河岸与金融银行）。经过微调的深度LM重排器基于上下文生成词汇表示，并在文本排序中取得了巨大的性能飞跃（Nogueira和Cho，2019；Dai和Callan，2019b）。

---

尽管软匹配所有词汇的思想贯穿了神经信息检索模型的发展，但在看到深度语言模型带来的成功之后，我们退后一步并提出了一个问题：如果我们将上下文表示重新引入精确词汇匹配系统中，我们能获得多少增益？换句话说，我们能否构建一个系统，仍然执行查询和文档词汇的精确匹配，但使用上下文词汇表示来计算匹配信号，而不是依赖于启发式方法？这似乎是对模型的一种约束，但精确词汇匹配比软匹配产生更可解释和可控的模式。它还允许搜索仅关注与查询有重叠词汇的文档子集，这可以通过倒排列表索引高效完成。同时，使用密集的上下文词汇表示使模型能够处理语义不匹配问题，这是经典词汇系统中长期存在的问题。

---

为了回答这个问题，我们提出了一种新的词汇匹配方案，该方案使用查询和文档重叠词汇的上下文表示之间的向量相似性来替代经典系统中使用的启发式评分。我们提出了**上下文倒排列表（COIL）**，一种结合深度语言模型表示的新型精确词汇匹配检索架构。COIL在离线状态下使用深度语言模型处理文档，并为每个文档词汇生成表示。这些表示根据其表面词汇分组到倒排列表中。在搜索时，我们为查询词汇构建表示向量，并执行上下文精确匹配：使用每个查询词汇查找其对应的倒排列表，并计算与倒排列表中存储的文档向量的相似性作为匹配分数。COIL通过丰富的语义匹配实现了高效的搜索。

---

我们的贡献包括：  
1) 提出了一种新颖的检索架构——**上下文倒排列表（COIL）**，将语义匹配引入词汇信息检索系统；  
2) 展示了从精确词汇匹配中推导出的匹配信号可以捕捉复杂的匹配模式；  
3) 证明了COIL在两个检索任务中显著优于经典词汇检索器、深度语言模型增强的词汇检索器以及最先进的密集检索器。

## 2 相关工作

**词汇检索器**。经典的信息检索系统依赖于精确词汇匹配检索器，例如布尔检索、BM25（Robertson和Walker，1994）和统计语言模型（Lafferty和Zhai，2001）。这类检索模型通过将文档组织成倒排索引来快速处理查询，其中每个不同的词汇都有一个倒排列表，存储了该词汇出现的文档信息。如今，它们仍然广泛应用于生产系统中。然而，这些检索模型在匹配相关词汇（词汇不匹配）或建模词汇上下文（语义不匹配）方面存在不足。早期许多努力致力于改进精确词汇匹配检索器，例如匹配n-gram（Metzler和Croft，2005）或使用相关文档中的词汇扩展查询（Lavrenko和Croft，2001）。然而，这些方法仍然使用词袋框架，在建模人类语言方面能力有限。

---

**神经排序器**。为了解决词汇不匹配问题，引入了依赖于数值文本表示之间软匹配的神经检索器。早期尝试通过计算预训练词嵌入（如word2vec（Mikolov等，2013）和GLoVe（Pennington等，2014））之间的相似性来生成匹配分数（Ganguly等，2015；Diaz等，2016）。最近的一种方法将查询和文档分别编码为一个向量并计算向量相似性（Huang等，2013）。后来的研究意识到单个向量编码细粒度信息的能力有限，并引入了完全交互模型以在所有词汇向量之间执行软匹配（Guo等，2016；Xiong等，2017）。在这些方法中，评分基于学习的神经网络，而计算成本的大幅增加限制了它们仅用于对词汇检索器生成的候选列表进行重排序。

---

**基于深度语言模型的排序器和检索器**。深度语言模型对神经信息检索产生了巨大影响。经过微调的Transformer（Vaswani等，2017）语言模型BERT（Devlin等，2019）在段落和文档重排序中取得了最先进的性能（Nogueira和Cho，2019；Dai和Callan，2019b）。如图1a所示，常见的方法是将拼接的查询和文档文本通过BERT输入，并使用BERT的[CLS]输出标记生成相关性分数。深度语言模型重排序器通过计算上下文词汇表示之间的完全交叉注意力，解决了词汇和语义不匹配问题。更轻量级的深度语言模型排序器被开发出来（MacAvaney等，2020；Gao等，2020），但它们的交叉注意力操作对于全集合检索来说仍然过于昂贵。

---

因此，后续研究转而通过增强词汇检索与深度语言模型的结合来缩小词汇差距，例如通过扩展文档表面形式（如DocT5Query，Nogueira和Lin，2019）或调整词汇权重以强调重要词汇（如DeepCT，Dai和Callan，2019a）。巧妙结合深度语言模型检索器和重排序器可以为最终性能带来额外增益（Gao等，2021a）。然而，这些检索器仍然像传统词汇检索器一样面临词汇和语义不匹配的问题。

---

另一条研究路线延续了单向量表示的工作，并构建了密集检索器，如图1b所示。它们将文档向量存储在密集索引中，并通过最近邻搜索进行检索。使用深度语言模型，密集检索器在多个检索任务中取得了令人瞩目的成果（Karpukhin等，2020）。后续研究表明，通过更好的训练可以进一步改进密集检索系统（Xiong等，2020；Gao等，2021b）。

---

单向量系统也被扩展到多向量表示系统。Polyencoder（Humeau等，2020）将查询编码为一组向量。类似地，Me-BERT（Luan等，2020）用一组向量表示文档。一项并行工作ColBERT（图1c）使用多个向量同时编码查询和文档（Khattab和Zaharia，2020）。特别是，它用文档中所有词汇的向量表示文档，并用扩展的词汇向量集合表示查询。然后，它计算词汇之间的全对全（笛卡尔）软匹配。ColBERT通过点积和池化操作进行交互，这使得它也能够利用密集索引进行全语料库检索。然而，由于ColBERT用所有词汇编码文档，它为上述所有方法增加了一个数量级的索引复杂性：集合中的文档词汇需要存储在单个庞大的索引中，并在查询时被考虑。因此，ColBERT对工程和硬件要求较高。

## 3 方法论

在本节中，我们首先介绍一些关于精确词汇匹配系统的预备知识。然后讨论COIL的上下文精确匹配设计及其搜索索引的组织方式。我们还对COIL与其他流行的检索器进行了比较。

### 3.1 预备知识

经典的词汇检索系统依赖于在词形泛化（如词干提取）下查询和文档词汇的重叠，即精确词汇匹配，来对查询和文档对进行评分。评分函数通常定义为匹配词汇得分的总和，这些得分通常基于统计信息，例如词频（$tf$）。一般来说，可以表示为：

$$
\begin{equation*}
s=\sum_{t \in q \cap d} \sigma_{t}\left(h_{q}(q, t), h_{d}(d, t)\right) \tag{1}
\end{equation*}
$$

其中，对于查询$q$和文档$d$之间的每个重叠词汇$t$，函数$h_{q}$和$h_{d}$提取词汇信息，而词汇评分函数$\sigma_{t}$将它们结合起来。一个流行的例子是BM25，其计算方式为：

$$
\begin{align*}
& s_{\mathrm{BM} 25}=\sum_{t \in q \cap d} i d f(t) h_{q}^{\mathrm{BM} 25}(q, t) h_{d}^{\mathrm{BM} 25}(d, t) \\
& h_{q}^{\mathrm{BM} 25}(q, t)=\frac{t f_{t, q}\left(1+k_{2}\right)}{t f_{t, q}+k_{2}}  \tag{2}\\
& h_{d}^{\mathrm{BM} 25}(d, t)=\frac{t f_{t, d}\left(1+k_{1}\right)}{t f_{t, d}+k_{1}\left(1-b+b \frac{|d|}{\mathrm{avgdl}}\right)}
\end{align*}
$$

其中，$t f_{t, d}$表示词汇$t$在文档$d$中的词频，$t f_{t, q}$表示词汇$t$在查询中的词频，$i d f(t)$是逆文档频率，$b$、$k_{1}$和$k_{2}$是超参数。

---

精确词汇匹配系统的一个关键优势在于效率。由于仅对精确匹配的词汇进行求和，每个查询词汇的评分只需针对包含匹配词汇的文档进行。这可以通过倒排列表索引高效完成（图2）。倒排列表将词汇映射到包含该词汇的文档列表。为了计算公式（1），检索器只需遍历查询词汇倒排列表中的文档子集，而无需遍历整个文档集合。

- 图2：传统倒排列表的示意图。倒排列表将词汇映射到包含该词汇的文档列表。检索器查找查询词汇的倒排列表，并使用存储的统计信息（如词频$tf$）对这些文档进行评分。

---

尽管最近的神经信息检索研究主要集中在通过文本的软匹配打破精确匹配的瓶颈，我们假设精确匹配本身可以通过将语义无关的基于词频的评分替换为语义丰富的评分来改进。在本节的剩余部分，我们将展示如何通过上下文词汇表示来改进精确词汇匹配框架，以构建高效且有效的检索系统。

### 3.2 上下文精确词汇匹配

我们希望通过编码词汇的语义来促进更有效的匹配，而不是仅仅依赖词频。受深度语言模型最新进展的启发，我们将查询和文档词汇编码为上下文向量表示，并在精确匹配的词汇之间进行匹配。图1d展示了COIL的评分模型。

---

在本研究中，我们使用Transformer语言模型$^{3}$作为上下文化函数。我们通过语言模型（LM）对查询$q$进行编码，并通过投影相应的输出来表示其第$i$个词汇：

$$
\begin{equation*}
\boldsymbol{v}_{i}^{q}=\boldsymbol{W}_{t o k} \mathrm{LM}(q, i)+\boldsymbol{b}_{t o k} \tag{3}
\end{equation*}
$$

其中，$\boldsymbol{W}_{t o k}^{n_{t} \times n_{l m}}$是一个矩阵，将LM的$n_{l m}$维输出映射到较低维度$n_{t}$的向量。我们假设使用较低维度的词汇向量已经足够，并在第5节中验证了这一点。同样地，我们对文档$d$的第$j$个词汇$d_{j}$进行编码：

$$
\begin{equation*}
\boldsymbol{v}_{j}^{d}=\boldsymbol{W}_{t o k} \mathrm{LM}(d, j)+\boldsymbol{b}_{t o k} \tag{4}
\end{equation*}
$$

---

然后，我们基于精确匹配的查询和文档词汇对的向量相似性，定义上下文精确词汇匹配评分函数：

$$
\begin{equation*}
s_{\mathrm{tok}}(q, d)=\sum_{q_{i} \in q \cap d} \max _{d_{j}=q_{i}}\left(\boldsymbol{v}_{i}^{q \mathrm{~T}} \boldsymbol{v}_{j}^{d}\right) \tag{5}
\end{equation*}
$$

需要注意的是，求和仅针对重叠词汇$q_{i} \in q \cap d$。对于每个查询词汇$q_{i}$，我们找到文档中所有相同的词汇$d_{j}$，并使用上下文词汇向量计算它们与$q_{i}$的相似性。选择最大相似性作为查询词汇$q_{i}$的得分。采用最大值操作符以捕捉最重要的信号（Kim，2014）。这符合一般词汇匹配的公式，其中$h_{q}$为$q_{i}$提供表示，$h_{t}$为所有$d_{j}=q_{i}$提供表示，$\sigma_{t}$计算查询向量与文档向量之间的点积相似性，并对得分进行最大池化。

---

与经典词汇系统一样，公式（5）中定义的$s_{t o k}$不考虑不同词汇之间的相似性，因此面临词汇不匹配问题。许多流行的语言模型（Devlin等，2019；Yang等，2019；Liu等，2019）使用特殊的CLS标记来聚合序列表示。我们通过$\boldsymbol{W}_{c l s}^{n_{c} \times n_{l m}}$投影CLS向量来表示整个查询或文档：

$$
\begin{align*}
\boldsymbol{v}_{c l s}^{q} & =\boldsymbol{W}_{c l s} \mathrm{LM}(q, \mathrm{CLS})+\boldsymbol{b}_{c l s} \\
\boldsymbol{v}_{c l s}^{d} & =\boldsymbol{W}_{c l s} \mathrm{LM}(d, \mathrm{CLS})+\boldsymbol{b}_{c l s} \tag{6}
\end{align*}
$$

$\boldsymbol{v}_{c l s}^{q}$和$\boldsymbol{v}_{c l s}^{d}$之间的相似性提供了高层次的语义匹配，缓解了词汇不匹配问题。COIL的完整形式为：

$$
\begin{equation*}
s_{\mathrm{full}}(q, d)=s_{\mathrm{tok}}(q, d)+\boldsymbol{v}_{c l s}^{q}{ }^{\top} \boldsymbol{v}_{c l s}^{d} \tag{7}
\end{equation*}
$$

在本文的其余部分，我们将包含CLS匹配的系统称为COIL-full，不包含的称为COIL-tok。

---

COIL的评分模型（图1d）是完全可微的。根据先前的工作（Karpukhin等，2020），我们使用查询$q$、正例文档$d^{+}$和一组负例文档$\left\{d_{1}^{-}, d_{2}^{-}, . . d_{l}^{-} ..\right\}$的负对数似然作为损失函数进行训练：

$$
\begin{equation*}
\mathcal{L}=-\log \frac{\exp \left(s\left(q, d^{+}\right)\right)}{\exp \left(s\left(q, d^{+}\right)\right)+\sum_{l} \exp \left(s\left(q, d_{l}^{-}\right)\right)} \tag{8}
\end{equation*}
$$

根据Karpukhin等（2020）的方法，我们使用批次内负例和BM25生成的困难负例。具体细节在实现部分（第4节）中讨论。

### 3.3 COIL的索引与检索

COIL预先计算文档表示并构建搜索索引，如图3所示。集合中的文档被离线编码为词汇和CLS向量。形式上，对于词汇表$V$中的唯一词汇$t$，我们从集合$C$中所有包含该词汇的文档中收集其上下文向量，构建词汇$t$的上下文倒排列表：

$$
\begin{equation*}
I^{t}=\left\{\boldsymbol{v}_{j}^{d} \mid d_{j}=t, d \in C\right\} \tag{9}
\end{equation*}
$$

其中，$\boldsymbol{v}_{j}^{d}$是公式（4）中定义的基于BERT的词汇编码。我们定义搜索索引以存储词汇表中所有词汇的倒排列表，$\mathbb{I}=\left\{I^{t} \mid t \in V\right\}$。对于COIL-full，我们还为CLS标记构建索引$I^{c l s}=\left\{\boldsymbol{v}_{c l s}^{d} \mid d \in C\right\}$。

- 图3：COIL的索引与检索架构。COIL-tok依赖于精确词汇匹配（下方）。COIL-full额外包含CLS匹配（上方）。

---

如图3所示，在本研究中，我们通过将每个倒排列表$I^{t}$中的向量堆叠成矩阵$M^{n_{t} \times}\left|I^{k}\right|$来实现COIL，从而可以通过优化的BLAS（Blackford等，2002）例程在CPU或GPU上高效地执行遍历倒排列表并计算向量点积的操作。所有$\boldsymbol{v}_{c l s}^{d}$向量也可以类似地组织成矩阵$M_{c l s}$，并通过矩阵乘积进行查询。这里的矩阵实现是一种详尽的方法，涉及倒排列表中的所有向量。作为一组密集向量，也可以将每个倒排列表组织为近似搜索索引（Johnson等，2017；Guo等，2019），以进一步加速搜索。

---

当查询$q$到达时，我们将其每个词汇编码为向量$\boldsymbol{v}_{i}^{q}$。这些向量被发送到与查询词汇对应的COIL倒排列表子集$\mathbb{J}=\left\{I^{t} \mid t \in q\right\}$中，执行上述矩阵乘积操作。由于$|\mathbb{J}| \ll|\mathbb{I}|$，只有所有倒排列表的一小部分参与搜索，因此效率很高。对于COIL-full，我们还使用编码的CLS向量$\boldsymbol{v}_{c l s}^{q}$查询CLS索引以获取CLS匹配分数。不同倒排列表的评分可以并行执行。然后通过公式（5）将得分结合起来对文档进行排序。

读者可以在附录A中找到详细的图示，分别是索引构建和查询的图4和图5。

### 3.4 与其他检索器的联系

**基于深度语言模型的词汇索引**。像DeepCT（Dai和Callan，2019a，2020）和DocT5Query（Nogueira和Lin，2019）这样的模型使用深度语言模型BERT或T5修改文档中的$t f_{t, d}$。这与$n_{t}=1$的COIL-tok类似。然而，单个自由度更多地衡量的是词汇的重要性，而不是语义一致性。

---

**密集检索器**。密集检索器（图1b）等同于COIL-full的CLS匹配。COIL通过精确匹配信号弥补了密集检索器中丢失的词汇级交互。

---

**ColBERT**。ColBERT（图1c）通过软匹配所有查询和文档词汇的上下文向量来计算相关性：

$$
\begin{equation*}
s(q, d)=\sum_{q_{i} \in[c l s ; q ; e x p]} \max _{d_{j} \in[c l s ; d]}\left(\boldsymbol{v}_{i}^{q \boldsymbol{\top}} \boldsymbol{v}_{j}^{d}\right) \tag{10}
\end{equation*}
$$

其中，交互发生在查询$q$、文档$d$、CLS标记和查询扩展词汇集$\exp$之间。全对全匹配与COIL仅使用精确匹配形成对比。它需要对所有文档词汇的表示进行密集检索，而COIL仅考虑查询的重叠词汇，因此其计算成本远高于COIL。

## 4 实验方法

**数据集**。我们在TREC 2019深度学习（DL）共享任务中的两个大规模检索基准上进行实验：MSMARCO段落（约800万条英文段落，平均长度约60个词汇）和MSMARCO文档（约300万篇英文文档，平均长度约900个词汇）${ }^{4}$。对于每个数据集，我们使用MSMARCO训练集查询训练模型，并在MSMARCO开发集查询和TREC DL 2019测试集查询上记录结果。我们主要报告全语料库检索结果，但也包括在MSMARCO开发集查询上的重排序任务，其中我们使用神经评分对MSMARCO组织者提供的BM25检索结果进行重新排序。官方指标包括测试集上的MRR@1K和NDCG@10，以及MSMARCO开发集上的MRR@10。我们还根据先前工作（Dai和Callan，2019a；Nogueira和Lin，2019）报告开发集查询的召回率。

---

**对比系统**。基线系统包括：1）传统的精确匹配系统BM25，2）深度语言模型增强的BM25系统DeepCT（Dai和Callan，2019a）和DocT5Query（Nogueira和Lin，2019），3）密集检索器，以及4）全对全软匹配检索器ColBERT。对于DeepCT和DocT5Query，我们使用作者提供的排序结果。对于密集检索器，我们报告了两个使用BM25负例或混合BM25和随机负例训练的密集检索器，结果来自Xiong等（2020）。然而，由于这些系统使用了RoBERTa（Liu等，2019）作为语言模型，并在MSMARCO段落集上训练文档检索器，我们还复现了第三个密集检索器，其训练设置与COIL完全相同。所有密集检索器使用768维嵌入。对于ColBERT，我们报告其已发布的结果（仅在段落集合上可用）。在重排序任务中，我们添加了BERT重排序器。

我们包括两个COIL系统：1）COIL-tok，仅使用精确词汇匹配的系统；2）COIL-full，包含词汇匹配和CLS匹配的模型。

---

**实现**。我们基于huggingface transformers（Wolf等，2019）使用Pytorch（Paszke等，2019）构建模型。COIL的语言模型基于BERT的base版本。COIL系统默认使用词汇维度$n_{t}=32$，COIL-full使用CLS维度$n_{c}=768$，共110M参数。在必要时，我们为CLS向量添加了Layer Normalization。所有模型使用AdamW优化器训练5个epoch，学习率为$3 \mathrm{e}-6$，预热比例为0.1，并采用线性学习率衰减，训练时间约为12小时。困难负例从BM25的前1000个结果中采样。每个查询使用1个正例和7个困难负例；每个批次在MSMARCO段落集上使用8个查询，在MSMARCO文档集上使用4个查询。文档被截断为前512个词汇以适应BERT。我们在训练集中随机选择512个查询进行验证。延迟时间在双路Xeon E5-2630 v3 CPU和RTX 2080 ti GPU上测量。我们如第3.3节所述，将COIL的倒排列表实现为矩阵，使用NumPy（Harris等，2020）在CPU上运行，使用Pytorch在GPU上运行。我们执行以下操作：a）一组矩阵乘积以计算上下文倒排列表上的词汇相似性，b）将词汇得分映射回文档，c）对文档进行排序。详细图示见附录中的图5。

## 5 结果

本节研究了COIL的有效性以及COIL中向量维度对有效性与效率权衡的影响。我们还对上下文精确匹配进行了定性分析。

### 5.1 主要结果

表1报告了各种系统在MSMARCO段落集合上的表现。仅使用精确词汇匹配的COIL-tok系统显著优于所有先前的词汇检索系统。通过上下文词汇相似性，COIL-tok的MRR达到0.34，而BM25的MRR仅为0.18。同样使用BERT和T5等深度语言模型的DeepCT和DocT5Query能够突破启发式词频的限制，但仍然受限于语义不匹配问题。我们看到COIL-tok大幅优于这两个系统。

---

COIL-tok在候选列表的顶部排序上也优于密集检索器。它在MRR和NDCG上表现优异，同时在召回率上与最佳密集检索系统持平，表明COIL的词汇级交互可以提高精确度。通过添加CLS匹配，COIL-full获得了处理词汇不匹配的能力，并实现了进一步的性能飞跃，超越了所有密集检索器。

---

COIL-full与ColBERT的性能差距非常小。需要注意的是，ColBERT计算所有词汇对之间的全对全软匹配。在检索时，它需要为每个查询词汇考虑集合中所有词汇的所有出现（MSMARCO段落集合中约有5亿个词汇出现）。COIL-full通过仅使用查询词汇的出现进行精确匹配信号，并通过单个CLS匹配来弥合词汇差距，能够同样有效地捕捉匹配模式。

---

在重排序任务中，我们观察到类似的模式。COIL-tok已经能够超越密集检索器，而COIL-full通过CLS匹配进一步提升了性能，与ColBERT持平。同时，先前的BERT重排序器在性能上几乎没有优势${ }^{5}$。在实践中，我们发现BERT重排序器的成本要高得多，重排序需要超过2700毫秒，而COIL仅需约10毫秒。

---

表2报告了MSMARCO文档集合上的结果。总体而言，我们观察到与段落集合类似的模式。COIL系统在MRR和NDCG上显著优于词汇和密集检索系统，并在召回率上保持小幅优势。结果表明，COIL适用于更长的文档，并在有效性上具有一致的优势。

---

结果表明，通过引入上下文表示，COIL可以显著改进精确词汇匹配机制。COIL的词汇级匹配也比密集检索器的全局匹配信号提供了更好的细粒度信号。COIL-full进一步将词汇信号与密集CLS匹配结合，形成了一个能够处理词汇和语义不匹配的系统，其有效性可与全对全系统媲美。

### 5.2 维度分析

第二个实验测试了改变COIL的词汇维度$n_{t}$和CLS维度$n_{c}$如何影响模型的有效性和效率。我们在表3中记录了在MSMARCO段落集合上的检索性能和延迟。

- 表3：不同表示维度下COIL系统的性能和延迟。不适用结果用“-”表示，无法获得用“n.a.”表示。这里$n_{c}$表示COIL的CLS维度，$n_{t}$表示词汇向量维度。*：ColBERT使用近似搜索和量化。我们从测量中排除了I/O时间。

---

在COIL-full系统中，将CLS维度从768降低到128会导致在开发集上的性能略有下降，表明对于COIL来说，完整的768维度可能并非必要。将CLS维度保持在128时，词汇维度为32和8的系统性能差异非常小，这表明词汇特定的语义消耗的维度要少得多。在COIL-tok系统$\left(n_{c}=0\right)$中，我们也观察到$n_{t}$的类似模式。

---

在DL2019查询中，我们观察到降低维度实际上提高了MRR。我们认为这是由于正则化效应，因为测试查询的标注方式与MSMARCO训练/开发集查询不同（Craswell等，2020）。

---

我们还在表3中记录了CPU和GPU的搜索延迟。将COIL-full的CLS维度从768降低到128带来了显著的加速，使COIL比DPR系统更快。进一步降低词汇维度提供了一些额外的加速。COIL-tok系统比COIL-full运行得更快，其延迟与传统BM25系统处于同一数量级。重要的是，较低维度的COIL系统在保持对密集检索系统性能优势的同时，速度更快。我们包括了ColBERT在原始论文中报告的延迟，该延迟通过近似搜索和量化进行了优化。尽管我们当前的实现没有使用这些优化技术，但所有COIL系统的延迟都低于ColBERT。然而，我们注意到近似搜索和量化也适用于COIL，将COIL的加速研究留给未来工作。

### 5.3 案例分析

COIL与之前所有基于嵌入的模型不同，它没有使用单一的统一嵌入空间。相反，对于特定词汇，COIL学习了一个嵌入空间来编码和衡量该词汇在不同上下文中的语义相似性。在本节中，我们展示了COIL在不同上下文中区分词汇不同含义的示例。在表4中，我们展示了相关和不相关查询文档对中，词汇相似性得分在不同上下文中的差异。

• 表4：由COIL生成的查询文档对示例及其相似性得分。被检查的词汇用蓝色标注。括号中的数字是由COIL生成的向量计算的查询-文档向量相似性。

---

第一个查询在“govt”（“government”的缩写）的上下文中寻找“cabinet”。两个文档都包含查询词汇“cabinet”，但含义不同。第一个文档中的“cabinet”指的是政府内阁，而第二个文档中的“cabinet”指的是柜子或橱柜。COIL成功地将查询中的“cabinet”与第一个文档中的“cabinet”匹配，并给出了更高的得分。在第二个查询中，两个文档中的“pass”都表示许可的概念。然而，通过上下文化，COIL捕捉到了同一概念的变化，并为第一个文档中的“pass”分配了更高的得分。

---

在经典精确匹配信息检索系统中，像“it”、“a”和“the”这样的停用词通常会被移除，因为它们本身并不具有信息量。然而，在第三个查询中，我们观察到COIL能够区分解释性句子中的“is”和被动形式中的“is”，并为前者分配更高的得分以匹配查询上下文。

---

所有这些示例都表明，COIL能够超越词汇表面形式的匹配，并引入丰富的上下文信息来估计匹配。不同上下文中相似性得分的差异展示了COIL系统如何比词汇系统更强大。

## 6 结论与未来工作

精确词汇匹配系统在经典信息检索系统中已被广泛使用数十年，并证明是有效且高效的。在本文中，我们指出了一个关键问题——语义不匹配，这一问题通常限制了所有基于表面词汇匹配的信息检索系统。为了解决语义不匹配问题，我们引入了上下文精确匹配，以区分不同上下文中的相同词汇，提供有效的语义感知词汇匹配信号。我们进一步提出了上下文倒排列表（COIL）搜索索引，该索引将倒排列表中的词汇统计替换为上下文向量表示，以执行有效的搜索。

---

在两个大规模即席检索基准上，我们发现COIL显著改进了词汇检索，并优于最先进的密集检索系统。这些结果表明，简单但高效的精确词汇匹配方案仍有很大的改进空间。当引入上下文化处理语义不匹配问题时，精确匹配系统获得了建模复杂匹配模式的能力，这是经典系统无法捕捉的。

---

COIL中的词汇不匹配问题也可以通过高层次的CLS向量匹配得到大幅缓解。完整系统的表现与更昂贵和复杂的全对全匹配检索器相当。完整系统的成功还表明，密集检索和COIL的精确词汇匹配具有互补效应，COIL弥补了密集检索系统丢失的词汇级匹配信号，而密集检索系统则可能为COIL解决了词汇不匹配问题。

---

随着我们的COIL系统显示出可行的搜索延迟，我们相信本文在构建存储语义的下一代索引方面迈出了坚实的一步。在词汇系统和神经系统的交叉点上，为两者提出的高效算法可以将COIL推向现实世界的系统。

## A 附录

### A.1 索引构建图示

下图展示了文档“apple pie baked ...”如何被COIL索引。文档首先通过一个微调的深度语言模型处理，为每个词汇生成上下文向量。每个词汇“apple”和“juice”的向量被收集到相应的倒排列表索引中，并附带文档ID以便查找。


### A.2 搜索图示

下图展示了查询“apple juice”如何被COIL处理。每个词汇“apple”和“juice”的上下文向量进入相应的倒排列表索引，该索引由一个查找ID数组和一个由文档词汇向量堆叠而成的矩阵组成。对于每个索引，运行矩阵向量乘积以生成得分数组。随后，通过最大得分分散和排序操作生成最终排名。请注意，对于每个索引，我们仅展示了索引矩阵中部分向量（3个向量）的操作。

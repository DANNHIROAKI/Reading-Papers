# 2. Principles of deferred data structuring.  

在本节中，我们将发展延迟数据结构的基本思想。设$X\text{=}\left\{x_1, x_2, \cdots, x_n\right\}$是从一个完全有序集合$U$中抽取的$n$个元素。考虑一系列查询，每个查询$q_j$是$U$中的一个元素；对于每个查询，我们必须确定它是否存在于$X$中。

:one:查询结构

1. 数据集：从完全有序集$U$中，抽取$n$个元素构成$X\text{=}\left\{x_1, x_2, \cdots, x_n\right\}$
2. 查询：从完全有序集𝑈中，抽取一个元素$q_j$
3. 查询任务：确定$q_j$是否位于$X$中

------

如果我们只需要回答一个查询，我们可以将查询$q_1$与$X$中的每个成员进行比较，并在$O(n)$次比较操作中回答查询。这是回答少量查询的首选方法。另一方面，如果我们知道查询的数量$r$很大，我们可以先将$X$中的元素排序，排序的时间复杂度为$p(n)\text{=}O(n \log n)$，从而构建出一个二叉搜索树$T_X$。然后对于每个查询，我们可以进行二分查找，每次查询的比较次数为$Q(n)\text{=}O(\log n)$；这样总共需要进行$O((n\text{+}r) \text{⸱} \log n)$次比较。

:one:回答单个查询：让$q_1$与$X$中的每个成员进行比较，在$O(n)$内回答查询

:two:回答$r$个(大量)查询：总耗时$O((n\text{+}r) \text{⸱} \log n)$

1. 先将$X$中所有元素快速排序$\text{→}$构建一个二叉搜索树$T_X$，耗时$p(n)\text{=}O(n \log n)$ 
2. 在二叉搜索树中二分搜索每个查询，每个查询耗时$Q(n)\text{=}O(\log n)$

------

接下来，我们将确定在集合$X$上回答$r$个查询的复杂度（比较次数）；我们不知道$r$的值，并且每个查询必须在我们知道下一个查询之前就被回答。

## 2.1. The lower bound.  

我们首先证明这个问题的一个信息理论下界。

**定理 1**：在最坏情况下，处理 $r$ 个查询所需的比较次数至少是 $(n\text{+}r) \text{⸱} \log (\min \{n, r\}) \text{–} O(\min \{n, r\})$。

**备注**：注意，上述两种策略（线性搜索或排序后进行二分搜索）都无法在所有 $r \leq n$ 的情况下达到这个下界。

**证明**：如果我们能够==先收集 $r$ 个查询==并==离线处理==它们，我们将得到一个==集合交集==问题，在该问题中，我们需要找出集合 $X \text{=} \{x_1, x_2, \cdots, x_n\}$ 和 $Q \text{=} \{q_1, \cdots, q_r\}$ 中的共同元素。我们将证明，确定两个集合（大小分别为 $n$ 和 $r$）交集所需的比较次数的下界为 $\Omega((n\text{+}r) \text{⸱} \log (\min \{n, r\}))$。这个离线下界==同样适用==于我们感兴趣的在线情况。我们将为 $r \leq n$ 的情况给出证明，另一个情况是对称的。

:one:问题：给定数据集和查询$X \text{=} \{x_1, x_2, \cdots, x_n\}$ 和 $Q \text{=} \{q_1, \cdots, q_r\}$，要确定二者的交集

:two:结论：

1. 该问题中，比较次数的下界为$(n\text{+}r) \text{⸱} \log (\min \{n, r\}) \text{–} O(\min \{n, r\})$
2. 不论是暴力扫描还是快排$+$二分搜索，在$r \leq n$情况下都无法达到该下界

:three:证明过程：通过信息论分析，先算出总的可能排列数$I$，再得到要处理的信息量下界$\log{}I$

- 具体过程先按下不表

---

由于我们关注的是该问题的下界，我们可以将注意力限制在==$X \cap Q \text{=} \varnothing$==的情况。在这种情况下，算法必须确定集合 $X$ 中每个元素与集合 $Q$ 中每个元素的关系。对手可以确保，对于 $Q$ 中的任意两个元素，至少存在一个 $X$ 中的元素，其值介于它们之间。换句话说，$Q$ 中的元素将 $X$ 划分为至少 $r \text{–} 1$ 个非空类。每个这样的类将包含所有位于 $Q$ 中连续两个元素之间的 $X$ 中的成员。我们将通过计算某些排列方式来给出一个信息理论下界，以满足上述约束条件。

------

$Q$ 中元素的排列方式有 $r!$ 种。给定 $Q$ 上的一个全序关系，可以通过 $X$ 中任意选择的 $r \text{–} 1$ 个元素来分隔 $Q$ 中的元素，排列方式有 $(r \text{–} 1)!$ 种。剩下的 $X$ 中元素可以任意放置。由 $Q$ 中的 $r$ 个有序元素所确定的可用插槽有 $r \text{+} 1$ 个。这可以有 $(r \text{+} 1)^{n \text{–} r \text{+} 1}$ 种方式进行排列。设 $I$ 为当 $S \cap Q \text{=} \varnothing$ 时，$X$ 和 $Q$ 的所有可能交错方式的总数。那么，以上指定的排列方式数是 $I$ 的下界：

$I \geqq r! \text{⸱} (r \text{–} 1)! \text{⸱} (r \text{+} 1)^{n \text{–} r \text{+} 1}$。

由于算法必须识别出至少 $I$ 种可能的排列方式，因此下界是 $\log I$：

$\log I \geqq (n \text{+} r) \text{⸱} \log r \text{–} 2r \log e$。

这里，$e$ 代表自然对数的底。

## 2.2. Upper bounds.  

我们现在提出两种方法来获得一个上界，该上界与下界相差一个常数倍。第一种方法基于归并排序，而第二种方法基于递归地查找中位数。

### 2.2.1. An approach based on merge-sort.

以下算法在常数因子范围内达到了下界。它使用递归==归并排序==技术来完全排序集合 $X$。归并排序在 $\log n$ 个阶段进行。每个阶段结束时，集合 $X$ 被划分为若干个大小相等的完全排序子集，这些子集称为runs。每个阶段将上一个阶段得到的所有runs配对并合并，创建更长的runs。这些阶段==与查询集的处理交替进行==，直到只剩下一个完全排序的runs，此后不再需要对 $X$ 中的元素进行比较。处理一个查询意味着在==每个==现有的runs中进行二分查找。在连续合并阶段之间处理的查询数量，或者等价地，$i$th 查询之前runs的最小长度是适当选择的。

:one:归并排序的过程

<img src="https://i-blog.csdnimg.cn/direct/de3b45faecee48a2ab001894a8caeeb9.png" alt="image-20241103004334657" width=550 /> 

1. 分割过程：将待排序数组等分为左右$\text{Runs}$，再对左右$\text{Runs}$递归式等分，直至不可分割 (经历$\log{}n$阶段)
2. 归并过程：将所有$\text{Runs}$两两递归合并，逐步得到较大有序$\text{Runs}$，直到得到完整有序数组 (经历$\log{}n$阶段)

:two:查询处理策略

1. 查询的时序：每进行一步归并(得到了若干个完全排序的$\text{Runs}$)，就立即处理==若干个==查询
2. 查询的处理：将查询值$q_j$，在当前阶段的所有$\text{Runs}$都进行一遍二分查找
3. 查询的数量：对于合并一次，对应处理多少个查询，是需要适当考量的
   - 或者说：对于每个查询，需要考量所对应$\text{Runs}$的大小

------

该算法确保每个runs的长度在第 $i$ 个查询之前至少为 $L(i)$。$L(i)$ 的合适选择是 $\Theta(i \log i)$。由于runs的长度必须是 2 的幂，因此我们选择

$L(i)\text{=}2^{\lceil\log (i \log i)\rceil}$。

:one:控制查询所对应$\text{Runs}$的大小：

1. 基本逻辑：第$i$个查询到来时，$\text{Runs}$的长度至少为$L(i)$ 

2. $L(i)$的选取：$L(i)\text{=}2^{\lceil\log (i \log i)\rceil}$ 

   $\begin{array}{|c|c|c|c|c|c|}
   \hline \text { i Range } & 2 & 3 & 4-7 & 8-12 & 13-21 & 22-35 \\
   \hline \text { L(i) } & 2 & 4 & 16 & 32 & 64 & 128 \\
   \hline \text { Width } & 1 & 1 & 4 & 5 & 9 & 14 \\
   \hline
   \end{array}$ 

   <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/output.png" alt="output" style="zoom:33%;" /> 

   - 以$\Theta(i \log i)$为增长趋势==(为何呢?)== 

   - 但$\text{Runs}$长度必须是$2$的幂，所以用$L(i)\text{=}2^{\log (i \log i)}$曲线救国，并且取整为$2^{\lceil\log (i \log i)\rceil}$

---

从一个阶段（runs的长度为 1）到长度为 $L(i)$ 的runs所需的处理成本是 $O(n \log L(i))$。因此，回答 $r$ 个查询的总成本为 $O(n \log r)$。第 $i$ 个查询的搜索成本的上界是 $n \text{⸱}\lceil\log (L(i)\text{+}1)\rceil / L(i)$。对前 $r$ 个查询求和，搜索成本的上界为

$\displaystyle{}\sum_{i\text{=}1}^r \cfrac{n}{L(i)} \text{⸱}\lceil\log (L(i)\text{+}1)\rceil\text{=}O(n \log r)$。

------

定理 2. 对于 $r \leqq n$，回答 $r$ 个查询的总成本为 $O(n \log r)$。

当 $r>n$ 时，我们注意到集合 $X$ 将被我们的方法完全排序。此时，所有查询都可以通过二分查找在 $O(\log n)$ 时间内得到答案。

证明：处理成本和搜索成本都是 $O(n \log r)$，因此回答前 $r$ 个查询的总成本为 $O(n \log r)$。

### 2.2.2. An approach based on recursive median finding. 

我们现在描述一种基于中位数查找的替代方法；算法的伪代码如下。该算法以查询驱动的方式构建二叉搜索树 $T_X$。$T_X$ 的每个内部节点 $v$ 被视为表示 $X$ 的一个子集 $X(v)$——根节点表示 $X$，其左子节点和右子节点分别表示 $X$ 中最小的 $(n\text{–}1)/2$ 个元素和最大的 $(n\text{–}1)/2$ 个元素，依此类推。令 $LSon(v)$ 和 $RSon(v)$ 分别表示 $v$ 的左子节点和右子节点。我们现在可以将构建 $T_X$ 的过程描述为：对于每个内部节点 $v$，扩展过程包括将 $X(v)$ 分割为两个大小相等的子集——小于 $X(v)$ 中位数的元素将构成 $X(LSon(v))$，而大于中位数的元素将构成 $X(RSon(v))$。我们用 $X(v)$ 的中位数标记节点 $v$。因此，位于第 $i$ 层的节点最多表示 $n / 2^i$ 个元素。随后，$LSon(v)$ 和 $RSon(v)$ 可以继续扩展。由于 $X(v)$ 的中位数可以通过 $3|X(v)|$ 次比较找到[12]，因此节点 $v$ 的扩展需要 $3|X(v)|$ 次比较。如果我们从扩展 $T_X$ 的根节点（表示整个集合 $X$）开始，然后扩展每个新创建的节点，$T_X$ 可以通过 $3n \log n$ 次比较构建完成。

---

查询的搜索过程可以看作是在 $T_X$ 中追踪一条从根到叶的路径。关键的观察是，对于给定的查询 $q_j$，我们只需要扩展那些在搜索过程中经过的节点；这就是之前提到的基于查询驱动的树构建。每次扩展后，最多只有一个新的子节点会被访问。第一个查询 $q_1$ 的回答需要在构建 $T_X$ 的一条根到叶路径时执行 $O(n\text{+}n/2\text{+}\cdots)\text{=}O(n)$ 次操作。因此，回答 $q_1$ 所需的时间与线性搜索的时间相差一个常数因子。在回答 $q_1$ 的过程中，我们已经构建了对后续查询有用的结构；任何将访问已扩展节点的未来搜索，只需进行一次比较即可继续搜索到下一级；此时该节点无需进一步扩展。那些尚未扩展的节点将在其他查询访问它们时被扩展。当回答了 $n$ 个查询并访问了所有 $n$ 个叶节点时，$T_X$ 将完全构建完成。实际上，我们是在省略显式的预处理阶段，也就是说，我们只在需要时进行“预处理”操作。数据结构的构建成本被分摊到多个查询中。

---

**算法的详细描述。** 在树的每个节点中，我们关联一组值和一个标签，这些值和标签有时可能是未定义的。

正文部分：

- 第一步：用根节点初始化树 $T_X$，并将 $n$ 个数据键置于根节点。
- 第二步：获取一个查询 $q$。
- 第三步：结果 $\leftarrow$ SEARCH（根节点，$q$）。
- 第四步：输出结果。
- 第五步：跳转到第二步。

------

过程 SEARCH（v：节点；q：查询）：布尔值；

- 第一步：如果 ($v$ 没有标签)，则调用 EXPAND($v$)。
- 第二步：如果 ($\operatorname{label}(v) \text{=} q$)，则返回 true。
- 第三步：如果 ($v$ 是叶节点)，则返回 false。
- 第四步：如果 ($q < \operatorname{label}(v)$)，则返回 SEARCH（$\operatorname{left_child}(v)$， $q$）。
- 第五步：如果 ($q > \operatorname{label}(v)$)，则返回 SEARCH（$\operatorname{right_child}(v)$， $q$）。

------

过程 EXPAND（v：节点）；

- 第一步：$S \leftarrow \operatorname{set}(v)$。
- 第二步：$m \leftarrow$ MEDIAN_FIND($S$)。
- 第三步：$\operatorname{label}(v) \leftarrow m$。
- 第四步：如果 ($|S| \text{=} 1$)，则返回。
- 第五步：$S_l \leftarrow [x \mid x \in S \text{ 且 } x < m]$。
- 第六步：$S_r \leftarrow [x \mid x \in S \text{ 且 } x > m]$。
- 第七步：设置 $\operatorname{left_child}(v) \leftarrow S_l$。
- 第八步：设置 $\operatorname{right_child}(v) \leftarrow S_r$。

---

需要注意的是，两个子集 $S_l$ 和 $S_r$ 是通过 MEDIAN_FIND 过程在寻找中位数时计算出来的。一旦找到中位数，确定这两个集合不需要额外的工作。

为了分析我们的算法，我们定义一个关于 $n$ 和 $r$ 的函数如下：

$\displaystyle{}\Lambda(n, r)\text{=} \begin{cases}3 n \log r\text{+}r \log n, & r \leqq n, \\ (3 n\text{+}r) \text{⸱} \log n, & r>n .\end{cases}$ 

注意，$\Lambda(n, r) \text{=} \Theta((n \text{+} r) \text{⸱} \log \min(n, r))$，因为对于 $r \leq n$，有 $r \text{⸱} \log n \leq n \text{⸱} \log r$。

---

**定理 3.** 处理 $r$ 个查询所需的操作数最多为 $\Lambda(n, r)$。

**证明.** 考虑 $r \leq n$ 的情况。对于每一层的节点，在处理 $r$ 个查询后，不会有超过 $r$ 个节点被扩展。对于前 $\log r$ 层的节点，总成本小于 $3n \log r$。这是因为在前 $\log r$ 层，每一层的所有节点可能都会被扩展。扩展一个节点 $v$ 包括找到 $X(v)$ 的中位数，这在最坏情况下至少需要 $3|X(v)|$ 次比较[12]。对于 $i > \lceil \log r \rceil$，第 $i$ 层的节点扩展成本为 $O\left(r \text{⸱} n / 2^i\right)$，因为扩展第 $i$ 层节点的成本至多是 $3 \text{⸱} n / 2^i$。对除了前 $\lceil \log r \rceil$ 层的所有层进行求和，节点扩展的成本为 $O(n)$。除了扩展成本，我们还需要考虑与搜索相关的成本；每个查询的搜索成本最多是 $\log n$ 次比较。因此，搜索部分的成本总是小于 $r \log n$。

当 $r$ 超过 $n$ 时，扩展成本永远不会超过完全构建 $T_X$ 的成本；这个成本是 $3n \log n$。再次注意，3的系数来自中位数查找过程。

## 2.3. A general paradigm for deferred data structuring.  

我们现在准备陈述延迟数据结构化的通用范式。该范式将隔离一些对于搜索问题而言，能够适应这种方法的关键特性，并简化我们在$\S\S 4$和5中描述的几何搜索问题。它还使我们能够识别出一些不太可能适用这种方法的问题。

------

设$\Pi$为一个具有以下特性的搜索问题。 (1) 搜索在一个包含$n$个数据点的集合$S$上进行（在上述示例中，$S\text{=}X$）。 (2) 一个查询$q$可以在$O(n)$时间内得到回答。 (3) 在$O(n)$时间内，我们可以将$S$划分为两个大小相等的子集$S_1$和$S_2$，使得（i）查询$q$在集合$S$上的答案与查询$q$在$S_1$或$S_2$上的答案相等；（ii）在划分$S$的过程中，我们可以计算出一个函数$f(S)$，并且存在一个常数时间过程，TEST$(f(S), q)$，它将确定查询$q$在$S$上的答案应当出现在$S_1$还是$S_2$中。（在上述示例中，$f(S) \text{=} \operatorname{MEDIAN}(S)$，而TEST是一个简单的比较操作。）

------

在这些条件下，我们可以采用延迟数据结构化方法，逐步构建搜索树。我们将在$\S\S 4$和5中通过几个几何示例来说明这一范式。
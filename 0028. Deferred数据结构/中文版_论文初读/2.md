# 2. Principles of deferred data structuring.  

在本节中，我们将发展延迟数据结构的基本思想。设$X\text{=}\left\{x_1, x_2, \cdots, x_n\right\}$是从一个完全有序集合$U$中抽取的$n$个元素。考虑一系列查询，每个查询$q_j$是$U$中的一个元素；对于每个查询，我们必须确定它是否存在于$X$中。

:one:查询结构

1. 数据集：从完全有序集$U$中，抽取$n$个元素构成$X\text{=}\left\{x_1, x_2, \cdots, x_n\right\}$
2. 查询：从完全有序集$U$中，抽取一个元素$q_j$
3. 查询任务：确定$q_j$是否位于$X$中

------

如果我们只需要回答一个查询，我们可以将查询$q_1$与$X$中的每个成员进行比较，并在$O(n)$次比较操作中回答查询。这是回答少量查询的首选方法。另一方面，如果我们知道查询的数量$r$很大，我们可以先将$X$中的元素排序，排序的时间复杂度为$p(n)\text{=}O(n \log n)$，从而构建出一个二叉搜索树$T_X$。然后对于每个查询，我们可以进行二分查找，每次查询的比较次数为$Q(n)\text{=}O(\log n)$；这样总共需要进行$O((n\text{+}r) \text{×} \log n)$次比较。

:one:回答单个查询：让$q_1$与$X$中的每个成员进行比较，在$O(n)$内回答查询

:two:回答$r$个(大量)查询：总耗时$O((n\text{+}r) \text{×} \log n)$

1. 先将$X$中所有元素快速排序$\text{→}$构建一个二叉搜索树$T_X$，耗时$p(n)\text{=}O(n \log n)$ 
2. 在二叉搜索树中二分搜索每个查询，每个查询耗时$Q(n)\text{=}O(\log n)$

------

接下来，我们将确定在集合$X$上回答$r$个查询的复杂度（比较次数）；我们不知道$r$的值，并且每个查询必须在我们知道下一个查询之前就被回答。

## 2.1. The lower bound.  

我们首先证明这个问题的一个信息理论下界。

**定理 1**：在最坏情况下，处理 $r$ 个查询所需的比较次数至少是 $(n\text{+}r) \text{×} \log (\min \{n, r\}) \text{–} O(\min \{n, r\})$。

**备注**：注意，上述两种策略（线性搜索或排序后进行二分搜索）都无法在所有 $r \leq n$ 的情况下达到这个下界。

**证明**：如果我们能够==先收集 $r$ 个查询==并==离线处理==它们，我们将得到一个==集合交集==问题，在该问题中，我们需要找出集合 $X \text{=} \{x_1, x_2, \cdots, x_n\}$ 和 $Q \text{=} \{q_1, \cdots, q_r\}$ 中的共同元素。我们将证明，确定两个集合（大小分别为 $n$ 和 $r$）交集所需的比较次数的下界为 $\Omega((n\text{+}r) \text{×} \log (\min \{n, r\}))$。这个离线下界==同样适用==于我们感兴趣的在线情况。我们将为 $r \leq n$ 的情况给出证明，另一个情况是对称的。

:one:问题：给定数据集$X \text{=} \{x_1, x_2, \cdots, x_n\}$和查询$Q \text{=} \{q_1, \cdots, q_r\}$，要确定二者的交集

:two:结论：

1. 该问题中，比较次数的下界为$(n\text{+}r) \text{×} \log (\min \{n, r\}) \text{–} O(\min \{n, r\})$ 
2. 不论是暴力扫描还是快排$+$二分搜索，在$r \leq n$情况下都无法达到该下界

:three:证明过程：通过信息论分析，先算出总的可能排列数$I$，再得到要处理的信息量下界$\log{}I$

---

由于我们关注的是该问题的下界，我们可以将注意力限制在==$X \cap Q \text{=} \varnothing$==的情况。在这种情况下，算法必须确定集合 $X$ 中每个元素与集合 $Q$ 中每个元素的关系。对手可以确保，对于 $Q$ 中的任意两个元素，至少存在一个 $X$ 中的元素，其值介于它们之间。换句话说，$Q$ 中的元素将 $X$ 划分为至少 $r \text{–} 1$ 个非空类。每个这样的类将包含所有位于 $Q$ 中连续两个元素之间的 $X$ 中的成员。我们将通过计算某些排列方式来给出一个信息理论下界，以满足上述约束条件。

$Q$ 中元素的排列方式有 $r!$ 种。给定 $Q$ 上的一个全序关系，可以通过 $X$ 中任意选择的 $r \text{–} 1$ 个元素来分隔 $Q$ 中的元素，排列方式有 $(r \text{–} 1)!$ 种。剩下的 $X$ 中元素可以任意放置。由 $Q$ 中的 $r$ 个有序元素所确定的可用插槽有 $r \text{+} 1$ 个。这可以有 $(r \text{+} 1)^{n \text{–} r \text{+} 1}$ 种方式进行排列。设 $I$ 为当 $S \cap Q \text{=} \varnothing$ 时，$X$ 和 $Q$ 的所有可能交错方式的总数。那么，以上指定的排列方式数是 $I$ 的下界：

$I \geqq r! \text{×} (r \text{–} 1)! \text{×} (r \text{+} 1)^{n \text{–} r \text{+} 1}$。

由于算法必须识别出至少 $I$ 种可能的排列方式，因此下界是 $\log I$：

$\log I \geqq (n \text{+} r) \text{×} \log r \text{–} 2r \log e$。

这里，$e$ 代表自然对数的底。

:one:证明思路

1. 构造最坏情况：
   - 只考虑$X \cap Q \text{=} \varnothing$的情况，这种情况又是需要最多次比较的
   - 确保任意$q_iq_{i+1}$之间都有$X$的元素存在，如果$q$相邻会简化算法搜索的过程
2. 信息论证明算法下界的思路：
   - 如果一个问题有$N$种可能的答案，那么至少需要进行$\log N$次二分决策，才能彻底区分所有$N$种情况
   - 所以在此处，需要先算出排列总数$I$的下界，然后$\log I$就是复杂度的下界

:two:总的排列方式数

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20241231193632957.png" alt="image-20241231193632957" width=400 /> 

1. 组合的限制条件：确保任意$q_iq_{i+1}$之间都有$X$的元素存在，也就是可将$X$划分为$r \text{–} 1/r/r \text{+} 1$个$\text{Class}$ 

2. 排列数计算：$I\text{≥}r! \text{×} (r \text{–} 1)! \text{×} (r \text{+} 1)^{n \text{–} r \text{+} 1}$ 
   - $Q$中所有元素的排列总方式数：$r\text{!}$
   - 对于$Q$的每种排列，又从$X$的每个$\text{Class}$中各提取一个元素
     - 共有可能$r \text{–} 1/r/r \text{+} 1$个元素，但这里考虑==下界==即$r \text{–} 1$的情况，因此排序总方式数为($r \text{–} 1$)$\text{!}$ 
   - 这样一来已经确保了任意$q_iq_{i+1}$之间都有$X$的元素存在
     - 剩下的元素可在$x_{\alpha{}1}\text{→}x_{\alpha{}(r-1)}$分割而成的$r\text{+}1$个插槽内任意防止
     - 总的情况数就为$(r\text{+}1)^{n\text{–}r\text{+}1}$
3. 复杂度下界：$\log I \text{≥} (n \text{+} r) \text{×} \log r \text{–} 2r \log e$
   - 先取对数：$\log I \text{≥} \log(r!) \text{+} \log((r\text{–}1)!) \text{+} \log((r\text{+}1)^{n-r\text{+}1})$
   - 利用$\text{Stirling's}$公式化简：$n! \text{≈} \sqrt{2\pi n}(\cfrac{n}{e})^n\xRightarrow{}\log(n!) \text{≈} n\log n\text{–}n\log e \text{+} O(\log n)$，$e$是自然对数
     - $\log(r!) \text{ ≈ } r\log r\text{–}r\log e \text{+} O(\log r)$
     - $\log((r\text{–}1)!) \text{ ≈ } (r\text{–}1)\log(r\text{–}1)\text{ – }(r\text{–}1)\log e \text{+} O(\log(r\text{–}1))$ 
     - $\log((r\text{+}1)^{n\text{–}r\text{+}1}) = (n\text{–}r\text{+}1)\log(r\text{+}1)$ 
   - 让$\log(r\text{–}1)\text{ ≈ }\log r$，去掉所有的$O(\text{×})$余项，即得到最终的结果

## 2.2. Upper bounds.  

我们现在提出两种方法来获得一个上界，该上界与下界相差一个常数倍。第一种方法基于归并排序，而第二种方法基于递归地查找中位数。

### 2.2.1. An approach based on merge-sort.

以下算法在常数因子范围内达到了下界。它使用递归==归并排序==技术来完全排序集合 $X$。归并排序在 $\log n$ 个阶段进行。每个阶段结束时，集合 $X$ 被划分为若干个大小相等的完全排序子集，这些子集称为runs。每个阶段将上一个阶段得到的所有runs配对并合并，创建更长的runs。这些阶段==与查询集的处理交替进行==，直到只剩下一个完全排序的runs，此后不再需要对 $X$ 中的元素进行比较。处理一个查询意味着在==每个==现有的runs中进行二分查找。在连续合并阶段之间处理的查询数量，或者等价地，$i$th 查询之前runs的最小长度是适当选择的。

:one:归并排序的过程

<img src="https://i-blog.csdnimg.cn/direct/de3b45faecee48a2ab001894a8caeeb9.png" alt="image-20241103004334657" width=550 /> 

1. 分割过程：将待排序数组等分为左右$\text{Runs}$，再对左右$\text{Runs}$递归式等分，直至不可分割 (经历$\log{}n$阶段)
2. 归并过程：将所有$\text{Runs}$两两递归合并，逐步得到较大有序$\text{Runs}$，直到得到完整有序数组 (经历$\log{}n$阶段)

:two:查询处理策略

1. 查询的时序：每进行==一步归并==(得到了若干个完全排序的$\text{Runs}$)，就立即处理==若干个==查询
2. 查询的处理：将查询值$q_j$，在当前阶段的所有$\text{Runs}$都进行一遍二分查找
3. 查询的数量：对于合并一次，对应处理多少个查询，是需要适当考量的
   - 或者说：对于每个查询，需要考量所对应$\text{Runs}$的大小

------

该算法确保每个runs的长度在第 $i$ 个查询之前至少为 $L(i)$。$L(i)$ 的合适选择是 $\Theta(i \log i)$。由于runs的长度必须是 2 的幂，因此我们选择

$L(i)\text{=}2^{\lceil\log (i \log i)\rceil}$。

:one:控制查询所对应$\text{Runs}$的大小：

1. 基本逻辑：第$i$个查询到来时，$\text{Runs}$的长度至少为$L(i)$ 

2. $L(i)$的选取：$L(i)\text{=}2^{\lceil\log (i \log i)\rceil}$ 

   $\begin{array}{|c|c|c|c|c|c|}
   \hline \text { i Range } & 2 & 3 & 4-7 & 8-12 & 13-21 & 22-35 \\
   \hline \text { L(i) } & 2 & 4 & 16 & 32 & 64 & 128 \\
   \hline \text { Width } & 1 & 1 & 4 & 5 & 9 & 14 \\
   \hline
   \end{array}$ 

   <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/output.png" alt="output" style="zoom:33%;" /> 

   - 以$\Theta(i \log i)$为增长趋势==(为何呢?)== 

   - 但$\text{Runs}$长度必须是$2$的幂，所以用$L(i)\text{=}2^{\log (i \log i)}$曲线救国，并且取整为$2^{\lceil\log (i \log i)\rceil}$

---

从一个阶段（runs的长度为 1）到长度为 $L(i)$ 的runs所需的处理成本是 $O(n \log L(i))$。因此，回答 $r$ 个查询的总成本为 $O(n \log r)$。第 $i$ 个查询的搜索成本的上界是 $n \text{×}\lceil\log (L(i)\text{+}1)\rceil / L(i)$。对前 $r$ 个查询求和，搜索成本的上界为

$\displaystyle{}\sum_{i\text{=}1}^r \cfrac{n}{L(i)} \text{×}\lceil\log (L(i)\text{+}1)\rceil\text{=}O(n \log r)$。

:one:构建成本：归并排序的开销为$O(n \log L(i))$

1. 将长度为$1$的$\text{Runs}$，合并为长度为$k$的$\text{Runs}$，就是要耗时$O(n \log k)$
   - 每次执行归并都需要扫描整个数组，复杂度为$O(n)$
   - 当$\text{Runs}$长度从$1$到$k$时，一共需要$\log k$轮归并
   - 最终复杂度就是：每轮复杂度$O(n)\text{×}$轮数$\log k$ 
2. 所以从$1$合并到$L(i)$长度，成本为$O(n \log L(i))$ 

:two:查询成本：

1. 当$\text{Runs}$的长度为$L(i)$时，$\text{Runs}$的数量为$\cfrac{n}{L(i)}$
2. 在每个$\text{Runs}$中进行二分查找，需要$\lceil\log(L(i)+1)\rceil$次比较
   - 对长度为$L$的$\text{Runs}$进行二分查找时，实际需要比较的次数是$\lceil\log(L\text{+}1)\rceil$而非$\lceil\log(L)\rceil$ 
   - 最简单的例子就是，即使$L\text{=1}$还是要进行一次比较的
3. 总的来讲，当每个$\text{Runs}$长度为$L(i)$时，查询成本是$n \text{×}\lceil\log (L(i)\text{+}1)\rceil / L(i)$ 

:three:总的搜索成本：

1. 从第$1\text{→}r$轮查询($i\text{=}1\text{→}r$)，每轮成本为$\cfrac{n}{L(i)} \text{×}\lceil\log (L(i)\text{+}1)\rceil$，合一起为$\displaystyle{}\sum_{i\text{=}1}^r \cfrac{n}{L(i)} \text{×}\lceil\log (L(i)\text{+}1)\rceil$  
2. 关于为何$\displaystyle{}\sum_{i\text{=}1}^r \cfrac{n}{L(i)} \text{×}\lceil\log (L(i)\text{+}1)\rceil\text{=}O(n \log r)$
   - 处理$\log(L(i)\text{+}1)$ 
     - $L(i)\text{=}2^{\log (i \log i)}$是$2$的幂，所以$L(i)\text{+}1 \text{≤} 2L(i)$
     - $\log(L(i)\text{+}1)\text{≤} \log (2L(i))\text{=}1\text{+}\log(L(i))$ 
     - 所以$\log(L(i)\text{+}1) \text{=} \log(L(i)) \text{+} O(1)$
   - 处理$\log(L(i))$
     - $\log(L(i)) \text{=} \log(2^{\lceil\log (i \log i)\rceil}) \text{=} \lceil\log (i \log i)\rceil$
     - $\log(i \log i)  \text{=} \log i + \log(\log i)  \text{=} O(\log i)$
   - 代入原式：
     - $\log(L(i)\text{+}1)\text{=}O(\log i)\text{+}O(1)\xrightarrow{忽略常数项}O(\log i)$ 
     - 原式$\text{=}\displaystyle{}\sum_{i\text{=}1}^r \cfrac{n}{L(i)}O(\log i)$ 
   - 化简结果：
     - $L(i)\text{=}2^{\lceil\log (i \log i)\rceil}\text{≥} 2^{\log (i \log i)} \text{=} i \log i$ 
     - 所以$\cfrac{n}{L(i)}\text{≤}\cfrac{n}{i \log i}$，即原式$\text{≤} \displaystyle{}\sum_{i=1}^r \cfrac{n}{i \log i}O(\log i) \text{＝} O(n\sum_{i=1}^r \frac{1}{i})$
     - 注意调和级数$\displaystyle{}\sum_{i=1}^r \cfrac{1}{i} \text{=} O(\log r)$，所以最终结果是$O(n \log r)$

------

定理 2. 对于 $r \leqq n$，回答 $r$ 个查询的总成本为 $O(n \log r)$。

当 $r>n$ 时，我们注意到集合 $X$ 将被我们的方法完全排序。此时，所有查询都可以通过二分查找在 $O(\log n)$ 时间内得到答案。

证明：处理成本和搜索成本都是 $O(n \log r)$，因此回答前 $r$ 个查询的总成本为 $O(n \log r)$。

:one:这说明了$\text{DDS}$的一个优雅特性

1. $r\text{≤}n$时：归并排序的下界是$O(n \log r)$，比正常来讲的$O(n \log n)$还要小
   - 注意此时搜索和构建成本都是$O(n \log r)$，二者相加的总成本还是$O(n \log r)$ 
2. $r\text{＞}n$时：数据集已被完全构建(排好序)，就过渡到了传统的二分查找法，每查一次开销为$O(\log n)$

### 2.2.2. An approach based on recursive median finding. 

我们现在描述一种基于中位数查找的替代方法；算法的伪代码如下。该算法以查询驱动的方式构建二叉搜索树 $T_X$。$T_X$ 的每个内部节点 $v$ 被视为表示 $X$ 的一个子集 $X(v)$——根节点表示 $X$，其左子节点和右子节点分别表示 $X$ 中最小的 $(n\text{–}1)/2$ 个元素和最大的 $(n\text{–}1)/2$ 个元素，依此类推。令 $LSon(v)$ 和 $RSon(v)$ 分别表示 $v$ 的左子节点和右子节点。我们现在可以将==构建 $T_X$ 的过程==描述为：对于每个内部节点 $v$，扩展过程包括将 $X(v)$ 分割为两个大小相等的子集——小于 $X(v)$ 中位数的元素将构成 $X(LSon(v))$，而大于中位数的元素将构成 $X(RSon(v))$。我们用 $X(v)$ 的中位数标记节点 $v$。因此，位于第 $i$ 层的节点最多表示 $n / 2^i$ 个元素。随后，$LSon(v)$ 和 $RSon(v)$ 可以继续扩展。由于 $X(v)$ 的中位数可以通过 $3|X(v)|$ 次比较找到[12]，因此节点 $v$ 的扩展需要 $3|X(v)|$ 次比较。如果我们从扩展 $T_X$ 的根节点（表示整个集合 $X$）开始，然后扩展每个新创建的节点，$T_X$ 可以通过 $3n \log n$ 次比较构建完成。

:one:中位数查找树$T_X$的构建

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20241231222402157.png" alt="image-20241231222402157" width=400 /> 

1. 结点的内容：一个结点$v$拥有集合$X$的某一子集$X(v)\text{+}$该子集中的中位数，根结点拥有整个$X$
2. 结点的划分：以中位数分界，较小的一半进入左子树$X(\text{LSon}(v))$，较大的一半进入右子树$X(\text{RSon}(v))$ 

:two:中位数查找树$T_X$的构建分析

1. 每层的节点数为$\cfrac{n}{2^i}$ 

2. 总的比较次数：

   - 扩展操作本质上就是得到单个结点的中位数，需要的比较次数是[$3|X(v)|$](https://doi.org/10.1016/S0022-0000(76)80029-3) 

   - 每层的比较次数：每层都是$3n$次

     - 深度$=0$(根节点)：$1$个结点，需要$3n$次比较

     - 深度$=1$：$2$个结点，每个结点需要$3\text{×}\cfrac{n}{2}$次比较，一共是$3n$次比较

     - 深度$=2$：$4$个结点，每个结点需要$3\text{×}\cfrac{n}{4}$次比较，一共是$3n$次比较

       ..............

   - 总的比较次数：共$\log n$层，所以是$3n \log n$次

---

查询的搜索过程可以看作是在 $T_X$ 中追踪一条从根到叶的路径。关键的观察是，对于给定的查询 $q_j$，我们只需要扩展那些在搜索过程中经过的节点；这就是之前提到的基于==查询驱动==的树构建。每次扩展后，最多只有一个新的子节点会被访问。第一个查询 $q_1$ 的回答需要在构建 $T_X$ 的一条根到叶路径时执行 $O(n\text{+}n/2\text{+}\cdots)\text{=}O(n)$ 次操作。因此，回答 $q_1$ 所需的时间与线性搜索的时间相差一个常数因子。在回答 $q_1$ 的过程中，我们已经构建了对后续查询有用的结构；任何将访问已扩展节点的未来搜索，只需进行一次比较即可继续搜索到下一级；此时该节点无需进一步扩展。那些尚未扩展的节点将在其他查询访问它们时被扩展。当回答了 $n$ 个查询并访问了所有 $n$ 个叶节点时，$T_X$ 将完全构建完成。实际上，我们是在省略显式的预处理阶段，也就是说，我们只在需要时进行“预处理”操作。数据结构的构建成本被分摊到多个查询中。

:one:延迟的查询$\mathbf{/}$构建策略：只需扩展那些==在搜索过程中经过的节点==

1. 第一次查询：从根节点开始查找，==只当需要向下移动时==才向下构建子节点
2. 之后的查询：从根节点开始查找，在已构建的结构上下降，没查到就再向下构建子节点

:two:查询的复杂度分析

1. 第一个查询：
   - 对于第一个查询，是一定需要构建从根$\text{→}$叶的路径的
   - 深度为$i$(根节点$i\text{=0}$)的结点，构建的成本(比较次数)为$O\left(\cfrac{n}{2^i}\right)$
   - 总的成本为$O\left(n\text{+}\cfrac{n}{2}\text{+}\cfrac{n}{4}\text{+}\cdots+1\right)\text{=}O(2n\text{–}1)\text{=}O(n)$ 
2. 之后的查询：
   - 势必小于第一次查询的成本
   - 随和查询的不断进行(查询至少$n$个以上)，$T_X$逐渐被完整构建

---

**算法的详细描述。** 在树的每个节点中，我们关联一组值和一个标签，这些值和标签有时可能是未定义的。

正文部分：

- 第一步：用根节点初始化树 $T_X$，并将 $n$ 个数据键置于根节点。
- 第二步：获取一个查询 $q$。
- 第三步：结果 $\leftarrow$ SEARCH（根节点，$q$）。
- 第四步：输出结果。
- 第五步：跳转到第二步。

过程 SEARCH（v：节点；q：查询）：布尔值；

- 第一步：如果 ($v$ 没有标签)，则调用 EXPAND($v$)。
- 第二步：如果 ($\operatorname{label}(v) \text{=} q$)，则返回 true。
- 第三步：如果 ($v$ 是叶节点)，则返回 false。
- 第四步：如果 ($q < \operatorname{label}(v)$)，则返回 SEARCH（$\operatorname{left_child}(v)$， $q$）。
- 第五步：如果 ($q > \operatorname{label}(v)$)，则返回 SEARCH（$\operatorname{right_child}(v)$， $q$）。

过程 EXPAND（v：节点）；

- 第一步：$S \leftarrow \operatorname{set}(v)$。
- 第二步：$m \leftarrow$ MEDIAN_FIND($S$)。
- 第三步：$\operatorname{label}(v) \leftarrow m$。
- 第四步：如果 ($|S| \text{=} 1$)，则返回。
- 第五步：$S_l \leftarrow [x \mid x \in S \text{ 且 } x < m]$。
- 第六步：$S_r \leftarrow [x \mid x \in S \text{ 且 } x > m]$。
- 第七步：设置 $\operatorname{left_child}(v) \leftarrow S_l$。
- 第八步：设置 $\operatorname{right_child}(v) \leftarrow S_r$。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20250101133736559.png" alt="image-20250101133736559" width=400 /> 

:one:主程序：$\text{Main}(X,Q)$

1. 先用整个$X$构建$T_X$的根
2. 从根开始用$\text{Search(root},q)$递归地处理$Q$中每个查询，并返回查询结果
3. 当$\text{Search}$遇到还为扩展的结点，需先执行$\text{Expand}$以扩展该节点

:two:搜索程序：$\text{Search}(v,q)$ 

| 条件$\textbf{1: }$结点$\boldsymbol{v}$有中位数 | 条件$\mathbf{2: }$结点$\boldsymbol{v}$是叶节点 | 条件$\textbf{3: }\boldsymbol{q}\xleftrightarrow{}\boldsymbol{v}$中位数 |                 操作                  |
| :--------------------------------------------: | :--------------------------------------------: | :----------------------------------------------------------: | :-----------------------------------: |
|                   ❌(未构建)                    |                      任意                      |                             任意                             |        调用$\text{Expand}(v)$         |
|                   ✅(已构建)                    |                       ❌                        |                             $>$                              | 调用$\text{Search}(\text{RSon}(v),q)$ |
|                   ✅(已构建)                    |                       ❌                        |                             $<$                              | 调用$\text{Search}(\text{LSon}(v),q)$ |
|                   ✅(已构建)                    |                       ❌                        |                             $=$                              |  返回$\text{True}$(查询$q\text{∈}X$)  |
|                   ✅(已构建)                    |                       ✅                        |                             任意                             | 返回$\text{False}$(查询$q\text{∉}X$)  |

:three:结点扩展：$\text{Expand}(v)$

1. 本结点：获取当前结点的数据集$S$，找到$S$的中位数$m$(即为当前结点的值)
2. 子节点：将小于$m$的元素分给左子节点，大于$m$的元素分给右子节点

---

需要注意的是，两个子集 $S_l$ 和 $S_r$ 是通过 MEDIAN_FIND 过程在寻找中位数时计算出来的。一旦找到中位数，确定这两个集合不需要额外的工作。

为了分析我们的算法，我们定义一个关于 $n$ 和 $r$ 的函数如下：

$\displaystyle{}\Lambda(n, r)\text{=} \begin{cases}3 n \log r\text{+}r \log n, & r \leqq n, \\\\ 3 n \log n \text{+}r  \log n, & r>n .\end{cases}$ 

注意，$\Lambda(n, r) \text{=} \Theta((n \text{+} r) \text{×} \log \min(n, r))$，因为对于 $r \leq n$，有 $r \text{×} \log n \leq n \text{×} \log r$。

:one:$r \log n \leq n  \log r$证明：本质上是$f(x)\text{=}\cfrac{\log x}{x}$的单调性，高中数学不展开了

:one:每次找到中位数时，必定也会一并得到大于$\mathbf{/}$小于中位数的集合$R_l\mathbf{/}R_r$

:two:$\Lambda(n, r) \text{=} \Theta((n \text{+} r) \text{×} \log \min(n, r))$的证明

0. 原式展开：$\displaystyle{}\Lambda(n, r)\text{=} \begin{cases}3 n \log r\text{+}r \log n\text{=}\Theta(n\log r \text{+} r\log r), & r \text{≤} n, \\\\ 3 n \log n \text{+}r  \log n\text{=}\Theta(n \log n\text{+} r\log n) , & r\text{＞}n .\end{cases}$ 
   - $r\text{＞}n$时好理解
1. 对于$r \text{≤} n$的情况，主要问题在于为何$r \log n\text{→}\Theta(r\log r)$
   - $r\log r\text{≤}r\log n\text{≤}n\log r$ 
   - 请注意，$r \log n\text{→}\Theta(r\log r)$的定义是$c_1r\log r\text{≤}r\log n\text{≤}c_2r\log r$
     - 显然$c_1\text{<1}/c_2\text{>}\cfrac{n}{r}$即可

---

**定理 3.** 处理 $r$ 个查询所需的操作数最多为 $\Lambda(n, r)$。

**证明.** 考虑 $r \leq n$ 的情况。对于每一层的节点，在处理 $r$ 个查询后，不会有超过 $r$ 个节点被扩展。对于前 $\log r$ 层的节点，总成本小于 $3n \log r$。这是因为在前 $\log r$ 层，每一层的所有节点可能都会被扩展。扩展一个节点 $v$ 包括找到 $X(v)$ 的中位数，这在最坏情况下至少需要 $3|X(v)|$ 次比较[12]。对于 $i > \lceil \log r \rceil$，第 $i$ 层的节点扩展成本为 $O\left(r \text{×} n / 2^i\right)$，因为扩展第 $i$ 层节点的成本至多是 $3 \text{×} n / 2^i$。对除了前 $\lceil \log r \rceil$ 层的所有层进行求和，节点扩展的成本为 $O(n)$。除了扩展成本，我们还需要考虑与搜索相关的成本；每个查询的搜索成本最多是 $\log n$ 次比较。因此，搜索部分的成本总是小于 $r \log n$。

当 $r$ 超过 $n$ 时，扩展成本永远不会超过完全构建 $T_X$ 的成本；这个成本是 $3n \log n$。再次注意，3的系数来自中位数查找过程。

:one:当$r\text{≤}n$时的扩展成本

1. 为何前$\log r$层全都被扩展了：
   - 分析一种扩展次数最少的情况，即$r$个相异的查询，每个查询只扩展一个结点就找到了
     - 因为相异，所以不可能不扩展
   - 从根结点开始扩展了$r$个结点，那就代表前$\log r$层必定都被扩展了
2. 前$\log r$层扩展成本
   - 对于第$i$层每个结点，找到中位数需要$3|X(v)|\text{=}\cfrac{3n}{2^i}$ 
   - 对于第$i$层所有结点，总的成本为${2^i}\text{×}\cfrac{3n}{2^i}\text{=}3n$
   - 所以前$\log r$层的扩展成本为==$3n\log r$==
3. 对于$i \text{>} \lceil \log r \rceil$层的扩展成本
   - 在单个这些层里
     - 每层被扩展的结点数不可能超过查询数$r$ 
     - 每个结点的扩展成本是$3|X(v)|\text{=}\cfrac{3n}{2^i}$ 
     - 该层扩展的总成本为$\cfrac{3nr}{2^i}$
   - 在所有这些层里：扩展的总成本是$\displaystyle{}\sum_{i=\log r + 1}^{\log n} \cfrac{3nr}{2^i}\xRightarrow{等比求和}\cfrac{3n}{2}\left(1 \text{–} \cfrac{r}{n}\right)\text{=}O(n)$  
4. 总的扩展成本$3n\log r\text{+}O(n)\text{=}3n\log r$ 

:two:当$r\text{>}n$时的扩展成本：数需要被完全构建，直接把$r$改成$n$即可，==$3n\log n$==

:three:搜索成本：不论$r/n$关系怎样，从根到叶搜索，最坏情况也不过$\log n$，故一共为==$r\log n$==

## 2.3. A general paradigm for deferred data structuring.  

我们现在准备陈述==延迟数据结构化的通用范式==。该范式将隔离一些对于搜索问题而言，能够适应这种方法的关键特性，并简化我们在$\S\S 4$和5中描述的几何搜索问题。它还使我们能够识别出一些不太可能适用这种方法的问题。

------

设$\Pi$为一个具有以下特性的搜索问题。 (1) 搜索在一个包含$n$个数据点的集合$S$上进行（在上述示例中，$S\text{=}X$）。 (2) 一个查询$q$可以在$O(n)$时间内得到回答。 (3) 在$O(n)$时间内，我们可以将$S$划分为两个大小相等的子集$S_1$和$S_2$，使得（i）查询$q$在集合$S$上的答案与查询$q$在$S_1$或$S_2$上的答案相等；（ii）在划分$S$的过程中，我们可以计算出一个函数$f(S)$，并且存在一个常数时间过程，TEST$(f(S), q)$，它将确定查询$q$在$S$上的答案应当出现在$S_1$还是$S_2$中。（在上述示例中，$f(S) \text{=} \operatorname{MEDIAN}(S)$，而TEST是一个简单的比较操作。）

------

在这些条件下，我们可以采用延迟数据结构化方法，逐步构建搜索树。我们将在$\S\S 4$和5中通过几个几何示例来说明这一范式。

:one:延迟数据结构的通用范式：$\Pi$问题是一个搜索问题，具有以下特点

1. 搜索：可在$O(n)$时间内，扫描$S$的元素

2. 分割：可在$O(n)$时间内，将$S$等分为$S_1/S_2$
   - 分割过程：生成一个值$f(S)$，存在函数$\text{Test}(f(S),q)$可判断查询的结果被分到了$S_1$还是$S_2$
     - 在中位数二叉树中，$f(S)\text{=}S$中位数
   - 分割结果：对$S$查询一次，对$S_1$和$S_2$各查询一次，结果相同




# 0. Abstract. 

我们考虑在静态数据集上回答一系列在线查询的问题。解决这类问题的传统方法通常包括一个预处理阶段，该阶段构建一个具有良好搜索行为的数据结构。然后，表示数据集的数据结构在处理查询时保持固定。而我们的方法涉及数据集的动态或查询驱动结构；我们的算法仅在回答查询时才处理数据集。以这种方式逐步构建的数据结构称为延迟数据结构。

------

我们通过解决在有序集合上回答成员查询的问题来发展延迟数据结构的概念。我们获得了一个随机化算法，该算法在高概率下实现了渐近最优性能。然后，我们提出了以下平面问题的最优延迟数据结构：测试凸包成员资格、半平面交集查询和固定约束的多目标线性规划。我们还将延迟数据结构化技术应用于多维支配查询问题。

# 1. Introduction.  

我们考虑几个搜索问题，其中给定一个包含n个元素的集合，我们称之为数据集。我们需要回答关于数据集的一系列查询。

------

传统的搜索问题方法包括在时间$p(n)$内对数据集进行预处理，从而构建一个能够高效回答查询的搜索结构。随后，每个查询可以在时间$q(n)$内得到回答。因此，回答$r$个查询所需的时间是$p(n) + r \cdot q(n)$。通常情况下，单个查询可以在没有预处理的情况下，在时间$o(p(n))$内回答。因此，除非查询的数量$r$足够大，否则预处理方法是低效的。

------

我们在此提出一种替代预处理的方法，其中搜索结构是在查询被回答时“即时”构建的。在本文中，我们假设一个对手会生成一个查询流，该查询流可以在任何时刻停止。每个查询都必须在线回答，在下一个查询到达之前。如果对手生成足够多的查询，我们将展示如何在时间$O(p(n))$内构建完整的搜索结构，以便进一步的查询能够在时间$q(n)$内回答。另一方面，如果对手生成的查询较少，我们将展示，在回答查询的过程中，我们所付出的总工作量（包括部分构建搜索结构）是渐近小于$p(n) + r \cdot q(n)$的。因此，我们的性能至少与预处理方法相当，实际上当$r$较小的时候，我们的效率更高。我们在没有事先知道$r$的情况下实现了这一点。我们将这种方法称为延迟数据结构化，因为我们在查询到达时逐步构建搜索结构，而不是一次性完成。在某些情况下，我们还展示了我们的延迟数据结构化算法具有几乎最优的效率，甚至与那些事先知道$r$（查询数量）的算法相比也不逊色。

---

在第2节中，我们通过成员查询问题来举例说明我们的方法。我们确定了在比较树模型下，回答$r$个查询在$n$个元素上的复杂度。在第3节中，我们提出了一个随机算法来解决成员查询问题，其性能与信息理论下界相匹配（忽略渐进上小的加法项）。接下来，我们展示了几个几何问题的延迟数据结构。在第4节中，我们展示了延迟数据结构对以下二维几何问题是最优的：（1）给定平面上的$n$个点，确定一个查询点是否在它们的凸包内；（2）给定$n$个半平面，确定一个查询点是否在它们的公共交集内；（3）给定$n$个线性约束（两变量），优化一个查询目标函数（也是线性的）。我们通过一个紧密的下界（在代数计算树模型下）在第4.4节中证明了我们的算法是最优的。在第5节中，我们考虑$d$维空间中的支配问题。我们提出了关于Bentley的ECDF搜索树[2]的延迟构建定理。

------

在本文中，所有的对数都是以二为底的。

# 2. Principles of deferred data structuring.  

在本节中，我们将发展延迟数据结构的基本思想。设$X=\left\{x_1, x_2, \cdots, x_n\right\}$是从一个完全有序集合$U$中抽取的$n$个元素。考虑一系列查询，每个查询$q_j$是$U$中的一个元素；对于每个查询，我们必须确定它是否存在于$X$中。

------

如果我们只需要回答一个查询，我们可以将查询$q_1$与$X$中的每个成员进行比较，并在$O(n)$次比较操作中回答查询。这是回答少量查询的首选方法。另一方面，如果我们知道查询的数量$r$很大，我们可以先将$X$中的元素排序，排序的时间复杂度为$p(n)=O(n \log n)$，从而构建出一个二叉搜索树$T_X$。然后对于每个查询，我们可以进行二分查找，每次查询的比较次数为$Q(n)=O(\log n)$；这样总共需要进行$O((n+r) \cdot \log n)$次比较。

------

接下来，我们将确定在集合$X$上回答$r$个查询的复杂度（比较次数）；我们不知道$r$的值，并且每个查询必须在我们知道下一个查询之前就被回答。

## 2.1. The lower bound.  

我们首先证明这个问题的一个信息理论下界。

**定理 1**：在最坏情况下，处理 $r$ 个查询所需的比较次数至少是 $(n+r) \cdot \log (\min {n, r}) - O(\min {n, r})$。

**备注**：注意，上述两种策略（线性搜索或排序后进行二分搜索）都无法在所有 $r \leq n$ 的情况下达到这个下界。

**证明**：如果我们能够先收集 $r$ 个查询并离线处理它们，我们将得到一个集合交集问题，在该问题中，我们需要找出集合 $X = \{x_1, x_2, \cdots, x_n\}$ 和 $Q = \{q_1, \cdots, q_r\}$ 中的共同元素。我们将证明，确定两个集合（大小分别为 $n$ 和 $r$）交集所需的比较次数的下界为 $\Omega((n+r) \cdot \log (\min {n, r}))$。这个离线下界同样适用于我们感兴趣的在线情况。我们将为 $r \leq n$ 的情况给出证明，另一个情况是对称的。

---

由于我们关注的是该问题的下界，我们可以将注意力限制在 $X \cap Q = \varnothing$ 的情况。在这种情况下，算法必须确定集合 $X$ 中每个元素与集合 $Q$ 中每个元素的关系。对手可以确保，对于 $Q$ 中的任意两个元素，至少存在一个 $X$ 中的元素，其值介于它们之间。换句话说，$Q$ 中的元素将 $X$ 划分为至少 $r - 1$ 个非空类。每个这样的类将包含所有位于 $Q$ 中连续两个元素之间的 $X$ 中的成员。我们将通过计算某些排列方式来给出一个信息理论下界，以满足上述约束条件。

------

$Q$ 中元素的排列方式有 $r!$ 种。给定 $Q$ 上的一个全序关系，可以通过 $X$ 中任意选择的 $r - 1$ 个元素来分隔 $Q$ 中的元素，排列方式有 $(r - 1)!$ 种。剩下的 $X$ 中元素可以任意放置。由 $Q$ 中的 $r$ 个有序元素所确定的可用插槽有 $r + 1$ 个。这可以有 $(r + 1)^{n - r + 1}$ 种方式进行排列。设 $I$ 为当 $S \cap Q = \varnothing$ 时，$X$ 和 $Q$ 的所有可能交错方式的总数。那么，以上指定的排列方式数是 $I$ 的下界：

$I \geqq r! \cdot (r - 1)! \cdot (r + 1)^{n - r + 1}$。

由于算法必须识别出至少 $I$ 种可能的排列方式，因此下界是 $\log I$：

$\log I \geqq (n + r) \cdot \log r - 2r \log e$。

这里，$e$ 代表自然对数的底。

## 2.2. Upper bounds.  

我们现在提出两种方法来获得一个上界，该上界与下界相差一个常数倍。第一种方法基于归并排序，而第二种方法基于递归地查找中位数。

### 2.2.1. An approach based on merge-sort.

以下算法在常数因子范围内达到了下界。它使用递归归并排序技术来完全排序集合 $X$。归并排序在 $\log n$ 个阶段进行。每个阶段结束时，集合 $X$ 被划分为若干个大小相等的完全排序子集，这些子集称为“跑”（runs）。每个阶段将上一个阶段得到的所有“跑”配对并合并，创建更长的“跑”。这些阶段与查询集的处理交替进行，直到只剩下一个完全排序的“跑”，此后不再需要对 $X$ 中的元素进行比较。处理一个查询意味着在每个现有的“跑”中进行二分查找。在连续合并阶段之间处理的查询数量，或者等价地，$i$th 查询之前“跑”的最小长度是适当选择的。

------

该算法确保每个“跑”的长度在第 $i$ 个查询之前至少为 $L(i)$。$L(i)$ 的合适选择是 $\Theta(i \log i)$。由于“跑”的长度必须是 2 的幂，因此我们选择

$L(i)=2^{\lceil\log (i \log i)}$。

从一个阶段（“跑”的长度为 1）到长度为 $L(i)$ 的“跑”所需的处理成本是 $O(n \log L(i))$。因此，回答 $r$ 个查询的总成本为 $O(n \log r)$。第 $i$ 个查询的搜索成本的上界是 $n \cdot\lceil\log (L(i)+1)\rceil / L(i)$。对前 $r$ 个查询求和，搜索成本的上界为

$\displaystyle{}\sum_{i=1}^r \cfrac{n}{L(i)} \cdot\lceil\log (L(i)+1)\rceil=O(n \log r)$。

------

定理 2. 对于 $r \leqq n$，回答 $r$ 个查询的总成本为 $O(n \log r)$。

当 $r>n$ 时，我们注意到集合 $X$ 将被我们的方法完全排序。此时，所有查询都可以通过二分查找在 $O(\log n)$ 时间内得到答案。

证明：处理成本和搜索成本都是 $O(n \log r)$，因此回答前 $r$ 个查询的总成本为 $O(n \log r)$。

### 2.2.2. An approach based on recursive median finding. 

我们现在描述一种基于中位数查找的替代方法；算法的伪代码如下。该算法以查询驱动的方式构建二叉搜索树 $T_X$。$T_X$ 的每个内部节点 $v$ 被视为表示 $X$ 的一个子集 $X(v)$——根节点表示 $X$，其左子节点和右子节点分别表示 $X$ 中最小的 $(n-1)/2$ 个元素和最大的 $(n-1)/2$ 个元素，依此类推。令 $LSon(v)$ 和 $RSon(v)$ 分别表示 $v$ 的左子节点和右子节点。我们现在可以将构建 $T_X$ 的过程描述为：对于每个内部节点 $v$，扩展过程包括将 $X(v)$ 分割为两个大小相等的子集——小于 $X(v)$ 中位数的元素将构成 $X(LSon(v))$，而大于中位数的元素将构成 $X(RSon(v))$。我们用 $X(v)$ 的中位数标记节点 $v$。因此，位于第 $i$ 层的节点最多表示 $n / 2^i$ 个元素。随后，$LSon(v)$ 和 $RSon(v)$ 可以继续扩展。由于 $X(v)$ 的中位数可以通过 $3|X(v)|$ 次比较找到[12]，因此节点 $v$ 的扩展需要 $3|X(v)|$ 次比较。如果我们从扩展 $T_X$ 的根节点（表示整个集合 $X$）开始，然后扩展每个新创建的节点，$T_X$ 可以通过 $3n \log n$ 次比较构建完成。

---

查询的搜索过程可以看作是在 $T_X$ 中追踪一条从根到叶的路径。关键的观察是，对于给定的查询 $q_j$，我们只需要扩展那些在搜索过程中经过的节点；这就是之前提到的基于查询驱动的树构建。每次扩展后，最多只有一个新的子节点会被访问。第一个查询 $q_1$ 的回答需要在构建 $T_X$ 的一条根到叶路径时执行 $O(n+n/2+\cdots)=O(n)$ 次操作。因此，回答 $q_1$ 所需的时间与线性搜索的时间相差一个常数因子。在回答 $q_1$ 的过程中，我们已经构建了对后续查询有用的结构；任何将访问已扩展节点的未来搜索，只需进行一次比较即可继续搜索到下一级；此时该节点无需进一步扩展。那些尚未扩展的节点将在其他查询访问它们时被扩展。当回答了 $n$ 个查询并访问了所有 $n$ 个叶节点时，$T_X$ 将完全构建完成。实际上，我们是在省略显式的预处理阶段，也就是说，我们只在需要时进行“预处理”操作。数据结构的构建成本被分摊到多个查询中。

---

**算法的详细描述。** 在树的每个节点中，我们关联一组值和一个标签，这些值和标签有时可能是未定义的。

正文部分：

- 第一步：用根节点初始化树 $T_X$，并将 $n$ 个数据键置于根节点。
- 第二步：获取一个查询 $q$。
- 第三步：结果 $\leftarrow$ SEARCH（根节点，$q$）。
- 第四步：输出结果。
- 第五步：跳转到第二步。

------

过程 SEARCH（v：节点；q：查询）：布尔值；

- 第一步：如果 ($v$ 没有标签)，则调用 EXPAND($v$)。
- 第二步：如果 ($\operatorname{label}(v) = q$)，则返回 true。
- 第三步：如果 ($v$ 是叶节点)，则返回 false。
- 第四步：如果 ($q < \operatorname{label}(v)$)，则返回 SEARCH（$\operatorname{left_child}(v)$， $q$）。
- 第五步：如果 ($q > \operatorname{label}(v)$)，则返回 SEARCH（$\operatorname{right_child}(v)$， $q$）。

------

过程 EXPAND（v：节点）；

- 第一步：$S \leftarrow \operatorname{set}(v)$。
- 第二步：$m \leftarrow$ MEDIAN_FIND($S$)。
- 第三步：$\operatorname{label}(v) \leftarrow m$。
- 第四步：如果 ($|S| = 1$)，则返回。
- 第五步：$S_l \leftarrow [x \mid x \in S \text{ 且 } x < m]$。
- 第六步：$S_r \leftarrow [x \mid x \in S \text{ 且 } x > m]$。
- 第七步：设置 $\operatorname{left_child}(v) \leftarrow S_l$。
- 第八步：设置 $\operatorname{right_child}(v) \leftarrow S_r$。

---

需要注意的是，两个子集 $S_l$ 和 $S_r$ 是通过 MEDIAN_FIND 过程在寻找中位数时计算出来的。一旦找到中位数，确定这两个集合不需要额外的工作。

为了分析我们的算法，我们定义一个关于 $n$ 和 $r$ 的函数如下：

$\displaystyle{}\Lambda(n, r)= \begin{cases}3 n \log r+r \log n, & r \leqq n, \\ (3 n+r) \cdot \log n, & r>n .\end{cases}$ 

注意，$\Lambda(n, r) = \Theta((n + r) \cdot \log \min(n, r))$，因为对于 $r \leq n$，有 $r \cdot \log n \leq n \cdot \log r$。

---

**定理 3.** 处理 $r$ 个查询所需的操作数最多为 $\Lambda(n, r)$。

**证明.** 考虑 $r \leq n$ 的情况。对于每一层的节点，在处理 $r$ 个查询后，不会有超过 $r$ 个节点被扩展。对于前 $\log r$ 层的节点，总成本小于 $3n \log r$。这是因为在前 $\log r$ 层，每一层的所有节点可能都会被扩展。扩展一个节点 $v$ 包括找到 $X(v)$ 的中位数，这在最坏情况下至少需要 $3|X(v)|$ 次比较[12]。对于 $i > \lceil \log r \rceil$，第 $i$ 层的节点扩展成本为 $O\left(r \cdot n / 2^i\right)$，因为扩展第 $i$ 层节点的成本至多是 $3 \cdot n / 2^i$。对除了前 $\lceil \log r \rceil$ 层的所有层进行求和，节点扩展的成本为 $O(n)$。除了扩展成本，我们还需要考虑与搜索相关的成本；每个查询的搜索成本最多是 $\log n$ 次比较。因此，搜索部分的成本总是小于 $r \log n$。

当 $r$ 超过 $n$ 时，扩展成本永远不会超过完全构建 $T_X$ 的成本；这个成本是 $3n \log n$。再次注意，3的系数来自中位数查找过程。

## 2.3. A general paradigm for deferred data structuring.  

我们现在准备陈述延迟数据结构化的通用范式。该范式将隔离一些对于搜索问题而言，能够适应这种方法的关键特性，并简化我们在$\S\S 4$和5中描述的几何搜索问题。它还使我们能够识别出一些不太可能适用这种方法的问题。

------

设$\Pi$为一个具有以下特性的搜索问题。 (1) 搜索在一个包含$n$个数据点的集合$S$上进行（在上述示例中，$S=X$）。 (2) 一个查询$q$可以在$O(n)$时间内得到回答。 (3) 在$O(n)$时间内，我们可以将$S$划分为两个大小相等的子集$S_1$和$S_2$，使得（i）查询$q$在集合$S$上的答案与查询$q$在$S_1$或$S_2$上的答案相等；（ii）在划分$S$的过程中，我们可以计算出一个函数$f(S)$，并且存在一个常数时间过程，TEST$(f(S), q)$，它将确定查询$q$在$S$上的答案应当出现在$S_1$还是$S_2$中。（在上述示例中，$f(S) = \operatorname{MEDIAN}(S)$，而TEST是一个简单的比较操作。）

------

在这些条件下，我们可以采用延迟数据结构化方法，逐步构建搜索树。我们将在$\S\S 4$和5中通过几个几何示例来说明这一范式。

# 3. A randomized algorithm.

在上一节中，我们看到了一个确定性算法，使用延迟数据结构在$O((n+r) \cdot \log \min {n, r})$时间内回答$r$个查询。定理3的上界超过了信息论下界一个常数因子3，这是因为我们使用了[12]中给出的中位数算法。找到$n$个元素的中位数需要$3n$次比较，这导致了上界和下界之间的差距。通过仔细实现，我们可以将常数因子减少到2.5，方法是将中位数算法中生成的部分顺序从父节点传递给子节点。 [3]中给出的更容易实现的算法会导致更高的常数因子。有一个Floyd [7]提出的算法，可以在$3n/2$的期望时间内计算中位数。使用它会将常数因子减少到$3/2$。在这里，我们介绍一个随机算法，其中比较次数将是最优的（以高概率）。

---

随机算法与$\S 2$中的算法仅有一个不同之处。在之前的算法中，我们使用节点存储的值的中位数来进行节点扩展的划分。这里，我们将使用一个“平庸元素”来达到同样的目的。平庸元素将被选择得非常接近中位数。更精确地说，平庸元素的秩将位于$t / 2 \pm t^{2 / 3}$的范围内。我们将使用随机化技术来高效地计算平庸元素。首先，从$t$个元素中随机选择一个大小为$O\left(t^{5 / 6}\right)$的子集。这个随机子集的中位数是一个不错的平庸元素候选。选择随机样本并测试其中位元素是否“平庸”需要$t+O\left(t^{5 / 6}\right)$次比较（见下文第5步）。这个采样过程会重复进行，直到找到一个平庸元素。在算法中，$\S 2$中调用的`MEDIAN_FIND`过程应该替换为下面概述的`MEDIOCRE_FIND`过程。

---

过程 MEDIOCRE_FIND（T：值集合）：值；

- 第1步：令$t = |T|$。
- 第2步：从$T$中随机选择一个大小为$2 \cdot \left\lceil t^{5 / 6} \right\rceil + 1$的样本$S$。
- 第3步：令$m \leftarrow$ MEDIAN_FIND $(S)$。
- 第4步：通过与$T - S$中的每个元素比较来计算$m$的秩。
- 第5步：如果$m$的秩不在$(t / 2) \pm t^{2 / 3}$范围内，则返回第2步。
- 第6步：返回$m$。

------

注意，在第4步中，我们不需要将$m$与$S$中的元素进行比较，因为我们假设过程MEDIAN_FIND隐式地为我们提供了相对于$m$的$S$的划分。在最后几层，我们将恢复使用确定性中位数查找，因为节点大小将过小，不适合使用随机化。一个好的选择是，对于前$\log n - 5$层使用过程MEDIOCRE_FIND，对于之后的层使用过程MEDIAN_FIND。这个随机化算法得出以下定理。

---

**定理 4.** 设$T(n, r)$为在$n$个元素上回答$r$个查询时，随机化算法所进行的比较次数。则以下结论成立，且其概率大于$1 - \cfrac{\log r}{\beta \cdot n}$：

$\displaystyle{}T(n, r) \leqq \begin{cases}(1+\alpha)(n \log r+r \log n), & r \leqq n, \\ (1+\alpha)(n+r) \log n, & r>n,\end{cases}$

其中$\beta$依赖于常数$\alpha$的值。

本节的其余部分将证明这个定理，证明将分为五个引理

---

使用“次优元素”（而不是中位数）可能导致不均匀的划分，从而在创建的二叉搜索树中造成不平衡。然而，以下引理表明，新创建的二叉搜索树的高度不会比$\log n$差太多。我们还将证明，搜索树中每个节点在第$i$层所关联的元素数量接近$n / 2^i$。设搜索树中一个节点的大小为与该节点关联的元素数量。

---

**引理 1.** 设$s_i$为第$i$层某个节点的大小，则有：

$\displaystyle{}n_i\left(1-\cfrac{20}{n_i^{1 / 3}}\right) \leqq s_i \leqq n_i\left(1+\cfrac{20}{n_i^{1 / 3}}\right),$

其中$n_i = \cfrac{n}{2^i}$，并且假设$n_i \geq 22$。

**证明：** 我们将通过对层数进行归纳来证明不等式的一侧。显然，在根节点（即$i=0$）时，不等式是成立的，因为$s_0 = n$。假设不等式对于第$i-1$层成立，即

$s_{i-1} \leqq n_{i-1} \cdot\left(1+20 / n_{i-1}^{1 / 3}\right)$

现在我们将$s_{i-1}$个元素根据次优元素进行划分。设$s_i$为两个划分集中的较大者。根据次优元素的定义，我们有

$s_i \leqq s_{i-1} / 2+s_{i-1}^{2 / 3}$. 

利用$(1+x)^a \leq 1 + a \cdot x$，其中$0 \leq a \leq 1$，我们得到：

$\displaystyle{}s_i \leqq n_i\left(1+\cfrac{1}{n_i^{1 / 3}}\left(11 \cdot 2^{2 / 3}+\cfrac{40}{3} \cdot \cfrac{2^{1 / 3}}{n_i^{1 / 3}}\right)\right) .$


对于$n_i \geqq 22$，我们注意到：

$\displaystyle{}\left(11 \cdot 2^{2 / 3}+\cfrac{40}{3} \cdot \cfrac{2^{1 / 3}}{n_i^{1 / 3}}\right) \leqq 20 .$


这意味着我们得到所需的结果：

$\displaystyle{}s_i \leqq n_i\left(1+\cfrac{20}{n_i^{1 / 3}}\right)$

前提是$n_i \geq 22$。

---

**引理 2.** 随机算法中二叉搜索树的高度将是 $\log n + O(1)$。

**证明：** 在第 $k = \log n - 5$ 层时，我们将不再使用次优元素来扩展节点。相反，我们使用存储在节点中的元素的中位数来划分这些元素。此时，引理 1 仍然适用，因为 $n_k = 32 \geq 22$，并且我们有：

$\displaystyle{}s_k \leqq n_k\left(1+\cfrac{20}{n_k^{1 / 3}}\right) \leqq 2^8$

因此，总层数最多为 $k + 8$。树的高度被限制在 $\log n + 3$ 之内。

根据引理 2，可以得出结论：在随机二叉搜索树中的搜索成本将接近最优。现在我们来考虑构建树的成本，特别是节点扩展的总成本。以下结果表明，随机样本的中位数是整个集合的次优元素，并且具有非常高的概率。

---

**引理 3.** 设 $p(t)$ 为在随机采样的单次迭代中，对于大小为 $t$ 的集合，未能得到次优元素的概率。那么，

$\displaystyle{}p(t) \leqq 2 \cdot t^{1 / 2} \cdot \exp \left(-4 \cdot t^{1 / 6}\right) \leqq \cfrac{1}{4 t} .$

**证明：** 设 $T$ 为一个大小为 $t$ 的集合，经过一次随机采样过程后，首先从 $T$ 中选择一个大小为 $s(t) = 2 \cdot f(t) + 1$ 的随机子集，其中 $f(t) = \lceil t^{5 / 6} \rceil$。然后测试该子集 $S$ 的中位数是否为 $T$ 的次优元素。换句话说，$S$ 的中位数在 $T$ 中的排名应该落在区间 $t / 2 \pm t^{2 / 3}$ 内。设 $P(x_r)$ 为元素 $x_r$（$T$ 中第 $r$ 位元素）是 $S$ 的中位数的事件：

$\displaystyle{}P\left(x_r\right)=\binom{r-1}{f(t)} \cdot\left(\cfrac{t-r}{f(t)}\right) /\binom{t}{s(t)}, \quad f(t)<r \leqq t-f(t) .$


设 $d(t) = t^{2 / 3}$。为了简化后续描述，我们将 $f(t)$ 和 $d(t)$ 分别记作 $f$ 和 $d$。显然，

$\displaystyle{}p(t)=\sum_{r=f+1}^{t / 2-d} P\left(x_r\right)+\sum_{r=t / 2+d}^{t-f} P\left(x_r\right)=\cfrac{2 s}{t-2 f} \sum_{r=f+1}^{t / 2-d}\left(\cfrac{r-f}{r}\right) \cdot\binom{r}{f} \cdot\binom{t-r}{f} /\binom{t}{2 \cdot f} .$


我们利用斯特林公式：

$\displaystyle{}n!=(2 \pi n)^{1 / 2}\left(\cfrac{n}{e}\right)^n e^{k_n}, \quad \cfrac{1}{12 n+1}<k_n<\cfrac{1}{12 n}$

经过大量简化，得到以下不等式：

$\displaystyle{}p(t)<2 \cdot f^{1 / 2} \cdot \exp \left(\cfrac{-4 f d^2}{t^2}\right)$


根据 $f(t)$ 和 $d(t)$ 的选择，$p(t)$ 的界限立即得到。下面的不等式也容易验证：

$\displaystyle{}p(t)<2 \cdot t^{1 / 2} \cdot \exp \left(-4 t^{1 / 6}\right)<\cfrac{1}{4 t} .$

---

现在考虑随机算法中扩展节点的整体成本。首先，是找到小随机样本的中位数的成本。引理 5 将表明，即使将所有树的中位数查找成本累加起来，找到小随机样本的中位数的成本也是很小的。更重要的是，判断样本的中位数是否为整个集合的次优元素的成本。由于“次优性”测试隐式地确定了精确的分割（参见 MEDIOCRE_FIND 程序的第 5 步），因此实际的分割操作没有额外的成本。考虑正在构建的树中的第 $i$ 层。设 $m = 2^i$ 为该层的最大节点数。与这一层节点相关的集合的大小必须在区间 $\left(n_i / 2\right) \pm 20 \cdot n^{2 / 3}$ 之间，其中 $n_i = n / m$ 为这些集合的平均大小。假设每次随机采样都能得到一个次优元素。这意味着，测试次优性的总成本为 $n$。然而，会有一些不好的情况，我们没有生成次优元素。设在第 $i$ 层中这样的实例的数量为 $s$。下一个引理表明，具有高概率地，$s$ 被限制在 $\varepsilon m$ 以内，其中 $\varepsilon$ 是一个适当小的常数。设 $c_i$ 为第 $i$ 层测试次优性的成本。当 $s \leq \varepsilon \cdot m$ 时，我们有

$\displaystyle{}c_i \leqq n+n \cdot \varepsilon\left(1+\cfrac{20}{n_i^{1 / 3}}\right)=(1+\alpha) \cdot n$ 

由于在所有层次上都有 $n_i > 1$，因此显然 $\alpha \leq 21 \cdot \varepsilon$。

---

引理 4. 设 $C$ 表示除最后 $O(1 / \varepsilon)$ 层之外所有层次的 $c_i$ 之和，则有

$P(C \geqq(1+\alpha) \cdot n \cdot \log r) \leqq \log r / k^2 \cdot n$.

证明：设随机变量 $\zeta_i$ 表示第 $i$ 层中 $l = (1 + \varepsilon) \cdot m$ 次随机采样中坏实例的数量。我们已经对 $p(t)$ 有了界限，其中 $p(t)$ 是单次随机采样在大小为 $t$ 的节点上的坏实例概率。在第 $i$ 层的 $l$ 次采样中，节点的大小不相等。因此，设 $p$ 表示该层节点上 $p(t)$ 的最大值。设 $E(\zeta)$ 和 $D(\zeta)$ 分别表示随机变量 $\zeta$ 的均值和标准差。切比雪夫不等式表示：

$P(|\zeta-E(\zeta)| \geqq$ $\lambda \cdot D(\zeta)) \leqq 1 / \lambda^2$. 

由于 $E(\zeta_i) = l \cdot p$ 且 $D(\zeta_i) = \sqrt{l \cdot p \cdot (1 - p)}$，我们得到：

$\displaystyle{}P\left(\zeta_i \geqq l-m\right) \leqq \cfrac{1 \cdot p \cdot(1-p)}{m \cdot \varepsilon^2} \quad \text { when } p \leqq \cfrac{\varepsilon}{2 \cdot(1+\varepsilon)}$ 

利用 $p(t)$ 的界限以及第 $i$ 层节点大小的下界，我们得到 $P(s > \varepsilon m) = P(c_i \geq (1 + \alpha) \cdot n) \leq \cfrac{k}{\varepsilon^2} \cdot n$，对于除最后 $O(\log 1 / \varepsilon)$ 层之外的所有层，$k$ 是一个小常数。选择 $\beta = \cfrac{\varepsilon^2}{k}$ 并将概率求和到前 $\log r$ 层，得到所需的界限。

---

理 5. 当 $r < n$ 时，随机样本中寻找中位数的总成本为 $O\left(n^{5 / 6} \cdot r^{1 / 6}\right)$，概率为 $1 - \cfrac{\log r}{\beta \cdot n}$。

证明：在大小为 $t$ 的节点上寻找中位数的成本为 $3t$。设该节点的两个子节点大小分别为 $k \cdot t$ 和 $(1 - k) \cdot t$，其中 $k$ 在 $\cfrac{1}{2}$ 和 1 之间。寻找子节点中位数的成本与 $C(k) \cdot t^{5 / 6}$ 成正比，其中 $C(k) = \left(k^{5 / 6} + (1 - k)^{5 / 6}\right)$。显然，$C(k)$ 在 $k = \cfrac{1}{2}$ 时达到最大值。定义 $C = C\left(\cfrac{1}{2}\right) = 2^{1 / 6}$。因此，从第 $i$ 层到第 $i+1$ 层，寻找中位数的成本最多增加一个因子 $C$。我们知道在第一级的中位数寻找成本为 $3 \cdot n^{5 / 6}$。因此，前 $\log r$ 层的中位数寻找总成本为

$3 \cdot n^{5 / 6} \cdot\left(1+C+C^2 \cdots C^{\log r-1}\right)$

这个和为 $O\left(n^{5 / 6} \cdot r^{1 / 6}\right)$，因为 $C \leq 2^{1 / 6}$。当 $r > n$ 时，中位数寻找的成本界限变为 $O(n)$。在我们目前的分析中，我们忽略了在给定节点上寻找中位数时的重复操作。这是必要的，因为并非每个随机样本的中位数都会是整个集合的“平庸元素”。然而， 引理 4 中的分析同样适用于中位数寻找成本，因为它仅仅是界定了在某一层中“平庸元素”寻找过程的重复次数。

定理 4 直接从引理 2、4 和 5 中得出。

# 4. Planar convex hull and linear programming problems.  

## 4.1. Point membership in a convex hull. 

在本节中，我们考虑以下问题。给定平面中的一组数据点 $P = \left\{ p_1, p_2, \cdots, p_n \right\}$，每个数据点 $p_i$ 由其两个坐标 $p_i = \left( p_{ix}, p_{iy} \right)$ 确定。$P$ 的凸包记作 $\mathrm{CH}(P)$。我们的任务是回答一系列查询：“查询点 $q_j = \left( q_{jx}, q_{jy} \right)$ 是否包含在 $\mathrm{CH}(P)$ 中？”

---

我们首先提出两种基于预处理的方法。对于所有 $r$ 的值，哪种方法都不是最优的。令 $\mathrm{BCH}(P)$ 表示那些位于 $\mathrm{CH}(P)$ 边界上的点。单个查询可以通过以下方式在 $O(n)$ 时间内回答：计算查询点 $q_j$ 到所有数据点的极角。若查询点包含在 $\mathrm{CH}(P)$ 中，当且仅当该角度范围 $\geq 180^{\circ}$。另外，我们可以通过首先在 $O(n \log h)$ 时间内构建 $\mathrm{CH}(P)$ 来回答 $r$ 个查询，其中 $h$ 是 $\mathrm{BCH}(P)$ 中的点数 [6], [11]。然后，选择一个点 $O$，位于 $\mathrm{CH}(P)$ 的内部，并通过从 $O$ 到 $\mathrm{CH}(P)$ 的每个顶点的 $h$ 条半无限直线将平面分成 $h$ 个扇形。每个扇形包含 $\mathrm{CH}(P)$ 边界上的一条边。在任何扇形中，所有位于该边与 $O$ 同侧的点必须位于 $\mathrm{CH}(P)$ 内。为了回答查询，我们首先通过对角度进行二分查找，确定查询点位于哪个扇形中，这需要 $O(\log h)$ 时间。然后，我们可以根据查询点所在扇形的边界测试其是否在 $\mathrm{CH}(P)$ 内。这需要总共 $O((n+r) \cdot \log h)$ 次操作来回答 $r$ 个查询。

---

我们采用延迟数据结构的方法来解决点成员问题，基于的是Kirkpatrick-Seidel的自顶向下凸包算法 [6]。$\mathrm{CH}(P)$ 的边界由上链和下链组成。每条链都是从 $P$ 中的最左点到最右点的一系列边。考虑一条垂直线将 $P$ 分成两个非空子集。这样的直线将与每条链上的恰好一条边相交；这些边被称为与这条直线对应的上切线和下切线。当垂直线将 $P$ 分成大小相等的两个子集时（我们称之为中位线），对应的切线称为 $P$ 的切线。Kirkpatrick 和 Seidel 表明，切线可以通过 $O(|P|)$ 的操作计算得到。

---

接下来，我们描述我们的延迟数据结构。在以下描述中，我们只考虑上链和切线；对下链和切线的推理是类似的。数据结构包含一个二叉搜索树 $T_P$，其中每个内部节点 $v$ 表示 $P$ 的一个子集 $P(v)$（其中 $P(\text{root}) = P$）。与 $v$ 关联的是一个 $x$-区间 $R_v = [x_L(v), x_R(v)]$；$P(v)$ 包含恰好那些 $x$ 坐标位于 $R_v$ 之间的点。我们通过计算 $P(v)$ 的中位线来扩展一个节点。$P(v)$ 的成员被分成两个子集：中位线左边的点和右边的点。这些子集分别与 $v$ 的两个子节点关联。现在可以计算出 $P(v)$ 的切线，所需的时间为 $O(|P(v)|)$ 次操作。可能存在 $R_v$ 两条垂直线所对应的切线在链中相邻的情况。实际上，两个切线可能是相同的。在这些退化情况下，我们不需要重新计算 $P(v)$ 的切线。这些退化情况可以通过 $R_v$ 边界上垂直线所对应的切线来识别（这些切线将由 $v$ 的祖先节点计算得出）。如果在某个节点上发现上切线和下切线都退化，我们将不再扩展该节点；这样的节点将是 $T_P$ 的叶节点。由于每次扩展节点时至少会发现一个新的切线，$T_P$ 的内部节点数（因此也就是叶节点数）永远不会超过 $h$。

---

查询的搜索过程遍历了搜索树中的一条从根到叶的路径。当第一次访问某个节点 $v$ 时，该节点会被扩展。在任何节点 $v$ 上，搜索会根据查询点的 $x$ 坐标决定是否进展到左子节点或右子节点。此外，我们还会测试查询点是否位于 $P(v)$ 的上切线下方（该切线在两侧延伸至无穷远）。如果在搜索路径上的任何节点处该测试失败，我们就知道查询点位于 $\mathrm{CH}(P)$ 之外。对下链/切线也有类似的测试。

---

图 1 展示了一个例子，其中两个查询 $q_1$ 和 $q_2$ 导致了根节点及其两个子节点的扩展。查询 $q_1$ 位于 $P$ 的中位线左侧，并且位于 $P$ 的下切线之上（通过虚线向左延伸）。这导致了 LSon（根节点）被扩展；此时我们发现 $q_1$ 位于左子节点的下切线下方，因此在 $\mathrm{CH}(P)$ 之外。注意，根节点和 LSon（根节点）的下切线在 $P$ 的某个点处相交；这意味着我们在 LSon（根节点）的右子树中将不会再次计算下切线。类似地，查询 $q_2$ 扩展了根节点的右子节点；它被发现位于 RSon（根节点）的上切线和下切线之间，因此位于 $\mathrm{CH}(P)$ 之内。

---

定理 5：处理 $r$ 个凸包成员查询的操作次数为 $O(\Lambda(n, r))$。

证明：$T_P$ 的深度从不超过 $\log n$。此外，$i$ 层的一个节点的扩展时间为 $O\left(n / 2^i\right)$。这符合我们的框架。与定理 2 证明中的分析类似，可以得出该结果。

## 4.2. Intersection of half-spaces.

我们考虑以下问题：确定查询点 $q_j=\left(q_{j x}, q_{j y}\right)$ 是否位于 $n$ 个半平面的交集内。设 $H=\left\{h_1, h_2, \cdots, h_n\right\}$ 为界定这些半平面的直线集合。我们假设每个半平面都包含原点。如果不是，我们可以通过应用适当的线性变换，将原点带入交集的公共区域，这一操作在 $O(n)$ 时间内完成（前提是这些半平面的交集非空）。具体方法是找到交集内部的一个点，并将原点映射到这个可行点上 [8]。我们也可以在 $O(n)$ 时间内测试交集是否为空 [8]。设 $H_i$ 为由直线 $h_i$ 边界所围成的半平面（包含原点）。在本节中，我们假设 $H_i$ 的交集是有界的——在第 4.3 节中，我们将展示如何处理无界交集区域的情况。

---

几何对偶性（或极性）[4], [11] 的概念在解决接下来的两个问题中将非常有用。在平面中，这种对偶性转化为点与直线之间的转换。一个点 $p=(a, b)$ 的对偶是直线 $l_p$，其方程为 $a x + b y + 1 = 0$，反之亦然。一个更直观的定义如图 2 所示。直线 $l_p$ 与从原点到点 $p$ 的连线垂直。如果点 $p$ 到原点的距离为 $d$，那么对偶直线 $l_p$ 距离原点的距离为 $1 / d$，并且方向相反。

---

我们现在将对考虑的半平面交集应用对偶变换。直线 $h_i$ 的对偶是一个点，我们将其记为 $p_i$；这些点的集合记为 $P$。$H_i$ 的交集的对偶是所有不在 $\mathrm{CH}(P)$ 中的点的集合。查询点 $q_j$ 的对偶是直线 $L_j$。当且仅当 $L_j$ 不与 $\mathrm{CH}(P)$ 相交时，查询点 $q_j$ 才在 $H_i$ 的交集中。因此，我们的问题转化为判断一系列查询直线是否与一组点的凸包相交。

---

搜索树和节点扩展过程与第 4.1 节完全相同。在每个节点 $v$，我们计算查询线 $L_j$ 与 $P(v)$ 的中位线的交点。我们知道，如果以下任意条件成立，$L_j$ 必须与 $\mathrm{CH}(P)$ 相交：（1）交点位于 $P(v)$ 的上下切线之间；（2）$L_j$ 与当前节点的某个切线相交。如果都不满足，我们必须继续在 $v$ 的左子节点或右子节点中搜索，具体取决于 $L_j$ 与切线的斜率。这三种情况分别由图 3 中的线 $L_1, L_2$ 和 $L_3$ 表示。对于 $L_3$，我们看到 $L_3$ 与 $\mathrm{CH}(P)$ 的任何交点必须位于中位线的左侧；因此，我们继续在 LSon $(v)$ 中进行搜索。

以下定理得出： 定理 6：处理 $r$ 个半平面交集查询的操作次数为 $O(\Lambda(n, r))$。

## 4.3. Two-variable linear programming. 

设 $L(f)$ 为一个具有 $n$ 个约束的两变量线性规划问题，目标函数为 $f$，需要在这些约束下最小化 $f$。Dyer [5] 和 Megiddo [8] 的算法可以在 $O(n)$ 时间内找到单个目标函数的最优解。我们考虑线性规划问题的查询版本。每个查询是一个目标函数 $f_i$，要求我们解决 $L\left(f_i\right)$。

---

该问题的预处理方法包括找到由约束定义的半平面的交集。通过分治法可以在 $O(n \log n)$ 时间内完成。将半平面集合划分为大小几乎相等的两部分。在每个子问题中递归地找到半平面的交集；然后可以在线性时间内合并两个交集 [11]。随后，通过对目标函数斜率进行二分查找，可以在 $O(\log n)$ 时间内回答每个查询。

---

与之前一样，我们借助几何对偶性来解决此问题。我们可以再次假设可行区域 $R_L$ 非空且包含原点。每个约束定义了一个半平面 $H_i$；$R_L$ 是这些半平面的交集。使用 $\S 4.1$ 的符号表示，$R_L$ 的对偶是 $\mathrm{CH}(P)$ 的外部区域。

---

首先，我们假设 $R_L$ 是有界的。这意味着在对偶平面中，原点位于 $\mathrm{CH}(P)$ 内。目标函数 $f_i$ 可以看作是原问题中的一族平行直线。根据 $f_i$ 的斜率，我们只需考虑原点上方或下方的平行直线集合。该集合的直线在对偶平面中对应于一条半无限直线，原点为其一端。我们称这条直线为目标线 $g_i$，并注意到它与 $\mathrm{CH}(P)$ 的边界在一个点相交，该点对应于最优解。

---

搜索树和节点扩展与 $\S 4.2$ 中相同。在某个节点 $v$ 处进行搜索时，我们计算 $g_i$ 与 $P(v)$ 的中位线的交点（如果有的话）。如果没有交点，或者交点不在切线之间，则根据原点位于中位线的左侧（右侧），搜索将继续向左（右）子节点进行。否则，我们向相反方向继续搜索。如果 $g_i$ 与 $P(v)$ 的切线相交，搜索结束。

---

当 $R_L$ 是无界时，对偶平面中的原点不位于 $\mathrm{CH}(P)$ 内。如果 $g_i$ 不与 $\mathrm{CH}(P)$ 相交，则问题的解是无界的。这可以通过在 $O(n)$ 时间内计算从原点到 $P$ 中所有点的极角来检测；这在开始时执行一次。如果 $g_i$ 位于该角度范围定义的圆锥体外，则它不与 $\mathrm{CH}(P)$ 相交。如果 $g_i$ 与 $\mathrm{CH}(P)$ 相交，我们使用与有界情况下相同的搜索过程。对偶平面中，两个在原点处的极端角度之间的点在 $\mathrm{BCH}(P)$ 中由一条切线连接。对于上述终止标准，忽略与该切线的交点。

---

图 4 显示了一个无界可行区域及其对应的对偶凸包。图中展示了两个目标函数 $f_1$ 和 $f_2$ 以及它们的对偶目标线。对偶平面中的弧表示那些不与 $\mathrm{CH}(P)$ 相交的目标线（例如，$g_2$），因此它们具有无界的最优解。

定理 7. 处理 $r$ 个二变量线性规划查询的操作数为 $O(\Lambda(n, r))$。

## 4.4. Lower bounds under the algebraic tree model.

$\S 2$ 中的信息论下界对于我们在本节中考虑的几何问题并不适用。在 $\S 2$ 中，我们使用了比较树计算模型，而在这里我们允许使用算术运算。因此，我们使用代数树计算模型 [1]。

---

代数计算树是一种决定输入向量（在 $\mathbf{R}^n$ 中的一个点）是否属于点集 $W \subseteq \mathbf{R}^n$ 的算法。树中的节点有三种类型：计算节点、分支节点和叶节点。计算节点有一个子节点，可以执行一个常规的算术操作或计算平方根。分支节点的行为类似于比较树中的节点，即它可以与之前计算的值进行比较，并且根据比较结果有两个子节点。叶节点被标记为 "接受" 或 "拒绝"，并且没有子节点。每个加法运算、减法运算或乘以常数的操作的费用为零。其他任何操作或比较的费用为单位成本。代数计算树的复杂度是从根节点到叶节点路径上的最大成本和。如果 $W \subseteq \mathbf{R}^n$，则 $C(W)$ 表示 $W$ 的复杂度，是接受精确集 $W$ 的树的最小复杂度。对于任何点集 $S \subseteq \mathbf{R}^n$，令 #($S$) 表示 $W$ 的连通分支数。文献 [1] 中证明了 $C(W)=\Omega(\log \#(W))$。

---

我们现在展示对于处理 $r$ 个凸包成员查询在 $n$ 个数据点上的代数运算下界，时间复杂度为 $\Omega((n+r) \cdot \log \min {n, r})$。事实上，我们将证明这个下界在离线处理 $r$ 个查询时成立。这个下界是通过从集合不相交问题（SET DISJOINTNESS）进行归约得到的，定义如下：给定两个集合 $X=\left\{x_1, x_2, \cdots, x_n\right\}$ 和 $Q=\left\{q_1, q_2, \cdots, q_r\right\}$，确定它们的交集是否非空。这个问题是 $\S 2$ 中提到的集合交集问题（SET INTERSECTION）的简化版本。我们首先证明集合不相交问题的下界。

---

**定理 8**. 任何解决集合不相交问题（SET DISJOINTNESS）的代数计算树，其复杂度必须为 $\Omega((n+r) \cdot \log \min {n, r})$。

**证明**. 假设没有失去一般性，我们令 $r \leq n$。每个集合不相交问题的实例可以表示为一个点 $\beta = (x_1, \cdots, x_n, q_1, \cdots, q_r)$，其中 $\beta$ 位于 $\mathbf{R}^{n+r}$ 空间中。设 $W \subseteq \mathbf{R}^{n+r}$ 为所有表示不相交集合的点的集合。该问题的复杂度为 $\Omega(\log \#(W))$，其中 $\#(W)$ 是集合 $W$ 的连通分量数量 [1]。考虑那些 $q_i$ 不同的实例。集合 $Q$ 的元素可以按顺序排列为 ${q_{(1)} < q_{(2)} < \cdots < q_{(r)}}$，其中 $(i)$ 表示集合 ${q_1, \cdots, q_r}$ 中第 $i$ 小的值的索引。令 $S_\beta(i) = {x_k : q_{(i)} < x_k < q_{(i+1)}}$，对于 $1 \leq i \leq r-1$。定义 $W^* = {\beta : |S_\beta(i)| = \lfloor n / (r-1) \rfloor, 1 \leq i \leq r-1}$，则 $W^* \subseteq W$。$W^*$ 中不同选择的 $S_\beta$ 集合由形如 $x_i = q_j$ 的超平面分隔。这些超平面完全与 $W$ 不相交。这意味着，如果 $W^*$ 中的两个点被这些超平面分隔，那么它们在 $W$ 中也必须被分隔。因此，$W$ 的连通分量数至少与将 ${x_1, x_2, \cdots, x_n}$ 按照 $S_\beta$ 的定义进行划分的方式数相同。通过计数论的论证可以得到，这个数量至少为

$r!\cfrac{n!}{(\lfloor(n / r-1)\rfloor!)^{r-1}} .$

由此可以得出，该问题的复杂度为 $\Omega((n+r) \cdot \log r)$。

---

**定理 9**. 处理 $r$ 个凸包成员查询的复杂度是 $\Omega((n+r) \cdot \log \min {n, r})$。

**证明**. 通过从集合不相交问题（SET DISJOINTNESS）进行 $O(n+r)$ 时间的归约。假设两个集合的元素都位于区间 $[0, 2\pi)$ 上。每个元素 $x_i$ 映射到单位圆上的一个点 $p_i$，其极坐标为 $\left(1, x_i\right)$。这构成了我们的数据集 $P$；注意到 $\mathrm{BCH}(P) = P$。集合 $Q$ 中的每个元素 $q_j$ 映射到一个点 $r_j$，其极坐标为 $\left(1, q_j\right)$。点 $r_j$ 位于 $\mathrm{CH}(P)$ 中当且仅当 $q_j \in X$。因此，集合不相交问题 $\alpha_{n+r}$ 等价于凸包成员查询（HULL_MEMBERSHIP）。

这个下界扩展到了 $\S\S 4.2$ 和 4.3 中的问题。

## 4.5. Effect of the number of points on the convex hull. 

在本节中，我们回到确定查询点是否位于给定 $n$ 个数据点的凸包内的问题。我们展示了当凸包边界上的数据点数 $h$ 远小于 $n$ 时，可以实现显著的改进。显然，当 $h$ 较小时，定理 4 的保证太弱，因为通过 Kirkpatrick-Seidel 算法，可以在 $O(n \log h)$ 操作内找到 $\mathrm{CH}(P)$；随后，查询可以在 $O(\log h)$ 时间内得到答案。这为回答 $r$ 个查询提供了 $O((n+r) \log h)$ 的时间上界。这似乎与定理 9 的下界相矛盾，但请记住，在下界的归约中，所有 $n$ 个数据点都位于凸包的边界上。当 $r$ 超过 $h$ 时，$\S 4.1$ 中的算法可以实现时间上界 $O(n \log h + r \log n)$，因为节点扩展的成本仅为 $O(n \log h)$。然而，搜索的成本不幸的是随着 $r \log n$ 增长，因为尽管叶子节点数只有 $h$，但 $T_P$ 的深度可能随着 $\log n$ 增长。

---

为了绕过这个困难，我们以交错的方式构造两个二叉搜索树 $T_P$ 和 $T_D$。让 $T$ 为算法 $\S 4.1$ 构造的搜索树的完全展开版本。它有 $h$ 个叶子，并且可以在 $O(n \log h)$ 时间内构造。树 $T_P$ 和 $T_D$ 将是 $T$ 的部分展开版本。$T_P$ 是通过按照 $\S 4.1$ 中的算法处理查询得到的版本。另一个树 $T_D$ 是通过延迟深度优先遍历部分构造 $T$ 得到的。

---

深度优先遍历一个具有 $l$ 个叶子的树可以看作由 $l$ 个阶段组成，每个阶段以到达一个新的叶子为结束。类似地，$T_D$ 的深度优先构造可以分解为 $h$ 个阶段。这些 $h$ 个阶段与在搜索树 $T_P$ 上处理前 $h$ 个查询的过程交织在一起。每个阶段也可以看作是在树 $T_D$ 上处理一个明智选择的查询。因此，$T_D$ 的延迟构造的成本与 $T_P$ 相同的上界。

---

当 $r$ 超过 $h$ 时，在处理完 $T_P$ 上的前 $h$ 个查询后，树 $T_D$ 将完全构建完成。此时，$T_P$ 本身可能尚未完全展开；事实上，它可能只展开了一个叶子节点。由于 $\mathrm{CH}(P)$ 现在已由 $T_D$ 完全确定，我们可以在进一步处理查询时不再使用这两棵搜索树。我们现在可以采用楔形法来回答每个查询，时间为 $O(\log h)$（见 §4.1）。由于构造 $T_D$ 的成本为 $O(n \log h)$，因此得出以下定理。

---

**定理 10** 处理 $r$ 个凸包成员查询的成本是 $O\left(\Lambda^{\prime}(n, r, h)\right)$，其中

$\Lambda^{\prime}(n, r, h)= \begin{cases}n \log r, & r \leqq h, \\ (n+r) \cdot \log h, & r>h .\end{cases}$ 

类似的结果适用于 $\S\S 4.2$ 和 4.3 中的问题。

# 5. Domination problems.

在本节中，我们研究了一个与 $k$ 维空间中的点支配问题相关的问题。这个问题并不直接适用于 $\S 2$ 末尾提出的范式。然而，通过高维的类似分治方法，我们能够将我们的技术适应于这种问题。

---

设 $p_i$ 表示点 $p$ 在 $k$ 维空间中的第 $i$ 坐标。我们说点 $p$ 支配点 $q$，当且仅当对于所有的 $i$，$1 \leq i \leq k$，都有 $p_i \geq q_i$。Bentley [2] 考虑了支配计数问题，这也叫做 ECDF 搜索问题。在这个问题中，我们给定了一个 $k$ 维空间中的点集 $P = {p_1, p_2, \dots, p_n}$，对于每个查询点 $q$，我们需要报告被 $q$ 支配的点的数量。

---

Bentley 使用多维分治策略来解决这个问题。他构建了一种数据结构，称为 ECDF 树，在经过一个预处理阶段后，这个树可以在 $O(\log^k n)$ 时间内回答每个查询，而预处理阶段的时间复杂度为 $O(n \log^{k-1} n)$。这个结果适用于固定维度数（$k$）并且 $n$ 为 2 的幂的情况。然而，Monier [9] 的更详细分析表明，这个结果对于任意的 $n$ 和 $k$ 都是有效的。事实上，Monier 表明，$O$ 结果中的常数为 $1 / (k-1)!$。在以下分析中，我们也假设维度数是固定的，且 $n$ 是 2 的幂。我们的结果可以通过引入 Monier 的结果，推广到任意的 $k$ 和 $n$。

---

多维分治的基本范式如下：给定一个涉及 $n$ 个点的 $k$ 维空间问题，首先将其划分为两个子问题，每个子问题包含 $n / 2$ 个点在 $k$ 维空间中，然后递归地在 $(k-1)$ 维空间中解决一个最多包含 $n$ 个点的问题。当应用于支配计数问题时，这个范式会产生以下的搜索或计数策略：

1. 找到一个 $(k-1)$ 维超平面 $M$，将点集 $P$ 划分为两个子集 $P_1$ 和 $P_2$，每个子集包含 $n / 2$ 个点。我们假设 $M$ 的形式为 $x_k=c$，因此，$P_1$ 中的所有点的第 $k$ 坐标都小于 $c$，而 $P_2$ 中的所有点的第 $k$ 坐标都大于 $c$。
2. 如果查询点 $q$ 位于与 $P_1$ 相同的一侧（即 $q_k < c$），那么只需要在 $P_1$ 中递归搜索。显然，查询点 $q$ 不能支配 $P_2$ 中的任何点。
3. 否则，$q$ 位于与 $P_2$ 相同的一侧（即 $q_k > c$），我们知道 $q$ 在第 $k$ 坐标上支配了 $P_1$ 中的所有点。此时，我们将 $P_1$ 和 $q$ 投影到超平面 $M$ 上，并递归地在 $(k-1)$ 维空间中搜索。同时，我们还在 $P_2$ 中继续进行 $k$ 维空间的搜索。

在图 5 中，我们展示了这个策略在二维空间中的应用。

---

在一维空间中，ECDF 搜索问题简化为在给定数据集中找到查询值的秩。 一维 ECDF 搜索树是对 $P$ 中 $n$ 个点的最优二叉搜索树。 $k$ 维 ECDF 树是一个递归构建的数据结构。该树的根包含 $M$，即第 $k$ 维的中位超平面。左子树是 $P_1$ 中的 $n / 2$ 个点的 $k$ 维 ECDF 树，其中 $P_1$ 是位于 $M$ 以下的点。类似地，右子树是 $P_2$ 中的 $n / 2$ 个点的 $k$ 维 ECDF 树，其中 $P_2$ 是位于 $M$ 以上的点。根节点还包含一个 $(k-1)$ 维的 ECDF 树，表示投影到超平面 $M$ 上的 $P_1$ 中的点。

---

为了回答查询 $q$，搜索算法将查询点的第 $k$ 坐标 $q_k$ 与中位平面 $M$ 上的定义值 $c$ 进行比较。如果 $q_k$ 小于 $c$，则搜索仅限于 $P_1$ 中的点。此时，算法会递归地在左子树中进行搜索。另一方面，如果 $q_k$ 大于 $c$，则算法会递归地在右子树中进行搜索，并且还会在根节点存储的 $(k-1)$ 维 ECDF 树中进行搜索。对于一维 ECDF 树，算法就是标准的二叉树搜索。对于固定的 $k$，构建 $k$ 维 ECDF 树的预处理时间为 $p(n) = O\left(n \log^k n\right)$，而回答单个查询所需的时间为 $q(n) = O\left(\log^k n\right)$。

---

我们现在将延迟数据结构技术应用于 $k$ 维 ECDF 树。与之前一样，我们不执行任何预处理来构建搜索树。ECDF 树是在回答查询的过程中按需构建的。最初，所有点都存储在 $k$ 维 ECDF 树的根节点。一般来说，当查询搜索到一个未展开的节点 $v$ 时，我们计算中位超平面 $M_v$，并根据 $\boldsymbol{M}_v$ 将数据点进行分区。然后，将这两个集合传递到 $v$ 的两个子节点。同时，我们初始化一个 $(k-1)$ 维的 ECDF 树，该树将在节点 $v$ 处创建。即使是这些低维树也将在回答查询的过程中按需创建。将延迟数据结构应用于 ECDF 树得出了以下定理。

---

**定理 11**：在 $k$ 维空间中回答 $r$ 个支配查询的代价为 $O(F(n, r, k))$，其中

$F(n, r, k)= \begin{cases}n \log ^k r+r \log ^k n, & r \leqq n, \\ n \log ^k n+r \log ^k n, & r>n .\end{cases}$ 

**证明**：该证明将通过对 $k$ 和 $n$ 进行归纳来完成。我们很容易看到，通过延迟构建 ECDF 树来回答查询所需的时间与非延迟构建树的过程相比并没有变化。本证明将集中在处理代价中的节点扩展部分。显然，我们不需要考虑 $r > n$ 的情况，因为节点扩展代价不会超过非延迟 ECDF 树的总预处理代价。令 $f(n, r, k)$ 表示在 $k$ 维空间中，使用 $k$ 维 ECDF 树回答 $r$ 个查询时，扩展节点的最坏情况代价。当 $r$ 超过 $n$ 时，我们有 $f(n, r, k) = O\left(n \cdot \log^k n\right)$，因为 $n$ 个查询，每个查询都会导致不同的叶节点，足以完全扩展 ECDF 树。接下来，我们将证明当 $r \leq n$ 时，$f(n, r, k) = O\left(n \cdot \log^k r\right)$。

---

这个归纳的基础是 $k=1$ 的情况。考虑一维 ECDF 树。它是一个最优的二叉搜索树，我们可以引用定理 3 来证明该定理的有效性。这确立了我们关于 $k$ 的归纳基础，换句话说，当 $r \leq n$ 时，$f(n, r, 1) = O(n \cdot \log r)$。归纳假设是该结果在最多 $k-1$ 维时是有效的，即当 $r \leq n$ 时，$f(n, r, k-1) = O\left(n \cdot \log^{k-1} r\right)$。现在我们证明它对于 $k$ 维也必须是有效的。在我们嵌套归纳的第二层中，我们专注于 $k$ 维 ECDF 树，并对 $n$ 进行归纳。显然，当 $n=1$ 时，$k$ 维 ECDF 树会满足上述定理，前提是 $r \leq n$。现在我们假设该结果对于最多 $n-1$ 个点的 $k$ 维情况有效。为了完成证明，我们展示在给定的假设下，结果可以扩展到 $n$ 个点的 $k$ 维情况。

---

考虑 $P$ 中 $n$ 个点的 $k$ 维 ECDF 树的根节点，记为 $V$。它包含一个中位超平面，记为 $M_V$，该超平面将 $P$ 中的 $n$ 个点划分为两个相等的子集 $P_1$ 和 $P_2$。回想一下，$P_1$ 是 $P$ 中所有位于 $M_V$ 以下的点的集合；$P_2$ 是 $P$ 中所有位于 $M_V$ 以上的点的集合。$V$ 的左子树和右子树分别是 $P_1$ 和 $P_2$ 的 $k$ 维 ECDF 树。我们还在 $V$ 存储一个 $(k-1)$ 维 ECDF 树，记为 $T_1$，它用于存储 $P_1$ 中点在 $M_V$ 上的投影。这个低维树在 $P_1$ 和 $P_2$ 之间创造了一种不对称性。这个不对称性可能会使我们的证明变得相当复杂。因此，为了本证明的目的，我们将对 ECDF 树的结构做一个简化假设。我们假设 $V$ 还包含一个 $(k-1)$ 维 ECDF 树，记为 $T_2$，它用于存储 $P_2$ 中点在 $M_V$ 上的投影。

---

ECDF 树的搜索过程也进行了修改，引入了对称性。给定一个查询 $q$，我们首先根据中位超平面 $M_V$ 测试它。如果它位于 $M_V$ 之上，则搜索继续在 $V$ 的右子树和 $T_1$ 中进行。另一方面，如果 $q$ 位于 $M_V$ 之下，我们将在 $V$ 的左子树和 $T_2$ 中继续搜索。搜索 $T_2$ 是多余的，因为 $q$ 位于 $M_V$ 以下，不能支配 $P_2$ 中的任何点。这些修改不仅在根节点处进行，而是在 ECDF 树中的所有节点处进行。很容易看出，这些修改只能增加我们节点扩展算法的运行时间。此外，这些更改导致执行冗余操作，但不会改变我们算法的结果。因此，显然，任何针对修改后 ECDF 树的节点扩展成本的上界也适用于原始的延迟数据结构。

---

现在我们继续完成 $r \leq n$ 的归纳证明。令 $r_1$ 表示位于中位超平面 $M_V$ 以下的查询数量。这些查询会在根节点的左子树中继续搜索。令 $r_2 = r - r_1$ 表示剩余的查询，它们位于中位超平面 $M_V$ 之上，因此继续在右子树中搜索。考虑处理这些查询所涉及的节点扩展成本。找到中位超平面 $M_V$ 需要 $O(n)$ 次操作。位于 $M_V$ 以下的 $r_1$ 个查询在 $V$ 的左子树（一个包含 $n / 2$ 个点的 $k$ 维 ECDF 树）和 $T_2$（一个包含 $n / 2$ 个点的 $(k-1)$ 维 ECDF 树）中处理。剩下的 $r_2$ 个查询则在 $V$ 的右子树（一个包含 $n / 2$ 个点的 $k$ 维 ECDF 树）和 $T_1$（一个包含 $n / 2$ 个点的 $(k-1)$ 维 ECDF 树）中处理。这为我们提供了以下关于处理 $r$ 个查询所涉及的总节点扩展成本的上界：

$\begin{aligned}
f(n, r, k)= & \max _{r_1+r_2=r}\left\{f\left(\cfrac{n}{2}, r_1, k\right)+f\left(\cfrac{n}{2}, r_2, k\right)+f\left(\cfrac{n}{2}, r_1, k-1\right)\right. 
\left.+f\left(\cfrac{n}{2}, r_2, k-1\right)+O(n)\right\} .
\end{aligned}$ 

---

使用归纳假设，我们知道不等式右侧函数的确切形式。特别地，我们知道这些函数是凸的。这意味着不等式的右侧在 $r_1 = r_2 = r / 2$ 时取得最大值。综合所有这些，我们得到了期望的结果：

$f(n, r, k)=O\left(n \cdot \log ^k r\right), \quad r \leqq n .$

再次注意，这个结果仅在固定 $k$ 的情况下有效，并且 $n$ 是 2 的幂。在一般情况下，$O$ 结果中的常数依赖于 $k$。Monier 对 Bentley 算法的详细分析 [9] 也将我们的结果扩展到了任意的 $n$ 和 $k$

---

Bentley [2] 实际上对构建 ECDF 树的预处理时间有一个稍微更好的上界。他利用了预排序技术，将 $k$-维 ECDF 树在 $n$ 个点上的预处理时间上界提高到了 $O\left(n \cdot \log^{k-1} n\right)$。他首先通过第一个坐标对所有 $n$ 个点进行排序，时间复杂度为 $O(n \cdot \log n)$。这个排序在每一步中都得以保持，特别是在将点分成两个子集时，对于某个坐标的中位超平面进行划分。考虑二维 ECDF 树。最开始，所有的 $n$ 个点按照第一个坐标的顺序存储在根节点中。在第一个查询之后，这些 $n$ 个点将按照中位超平面进行划分，并传递到子节点。在这个划分过程中，第一个坐标的顺序被保持。设 $P_1$ 为传递到左子树的点集，$P_2$ 为传递到右子树的点集。在原始的 ECDF 树中，我们会为 $P_1$ 中的点构建一个一维的 ECDF 树并存储在根节点。而现在，我们只需将 $P_1$ 中的点按照第一个坐标的顺序存储在根节点。这一过程会在每个二维 ECDF 树的节点处重复进行。我们现在将二维 ECDF 树作为递归构建 $k$-维 ECDF 树的基本数据结构。实际上，我们已经去除了原来的一维 ECDF 树。构建预排序 $k$-维 ECDF 树的预处理时间变为 $O\left(n \cdot \log^{k-1} n\right) + O(n \cdot \log n)$。这个新的数据结构也可以像之前的结构一样延迟构建，我们得到了以下结果。

---

**定理 12.** 在 $k$-维空间中回答 $r$ 个支配搜索查询的代价是 $O(G(n, r, k))$，其中

$G(n, r, k)= \begin{cases}n \log n+n \log ^{k-1} r+r \log ^k n, & r \leqq n, \\ n \log ^{k-1} n+r \log ^k n, & r>n .\end{cases}$

**证明.** 该证明可以通过对定理 11 的证明进行简单的修改得到。注意，当 $r > n$ 时，预排序的代价被节点扩展的代价所涵盖。

# 6. Conclusion.

延迟数据结构的范式已经应用于一些搜索问题。在所有情况下，我们考虑了在线查询，并在处理查询的过程中构建搜索树。对于所研究的问题，我们的方法在现有的预处理阶段和搜索阶段策略上有所改进。一个有趣的未解问题是设计用于动态数据集的延迟数据结构，在这些数据集中，插入和删除操作可以与查询处理并发进行。

---

最近邻问题 [13] 要求找出与查询点最接近的 $n$ 个数据点。该问题通过使用 Voronoi 图在 $O(\log n)$ 的搜索时间内解决；Voronoi 图的构建时间为 $O(n \log n)$。目前没有已知的自顶向下的分治算法能够最优地构建 Voronoi 图。构建左侧和右侧 $n / 2$ 点的平分线的显然的自顶向下方法（参见 [14] 关于两个点集的平分线的定义）失败了，因为排序就相当于计算这个平分线。因此，是否能够为最近邻搜索问题设计一种延迟数据结构仍是一个有趣的未解问题。值得注意的是，$\S 2$ 的技术可以用于解决一维最近邻问题。
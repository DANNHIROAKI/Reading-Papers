### 学习基于相似性图的路由方法

#### 摘要

近年来，相似性图已成为高效最近邻搜索的主流范式，其性能优于传统的基于树和局部敏感哈希（LSH）的方法。相似性图通过贪婪路由执行搜索：查询会在图中遍历，并在每个节点向与查询距离最近的相邻节点移动。然而，在实际应用中，相似性图往往容易受到局部最小值的影响，这导致查询无法到达最近邻，而是停留在次优节点中。

本文提出了一种学习路由函数的方法，通过整合图的全局结构信息来克服局部最小值问题。具体而言，我们通过为图中的节点添加额外的表示向量，使其能够学习从起始节点到查询最近邻的最优路由。

通过详尽的实验，我们证明了所提出的可学习路由方法能够有效减少局部最小值问题，并显著提升整体搜索性能。

## 1. 引言

最近邻搜索（NNS）是广泛应用于各种机器学习系统中的一个重要子程序，包括非参数分类／回归，语言建模，信息检索，推荐系统等领域。现代应用需要处理海量数据，因此最近邻搜索方法的可扩展性已成为机器学习领域高度关注的问题。

形式上，最近邻搜索问题可以描述如下：给定数据库

$$
S=\left\{v_1, \ldots, v_N\right\} \subset \mathbf{R}^D
$$


以及一个査询

$$
q \in \mathbf{R}^D
$$


需要找到数据库中与查询最接近的点

$$
v \in S,
$$


其接近程度由某种度量（例如欧几里得距离）衡量。

------

目前，针对高效最近邻搜索的研究主要分为三大类：

1. **基于分区树的方法**（Bentley, 1975; Sproull, 1991; McCartin-Lim et al., 2012; Dasgupta & Freund, 2008; Dasgupta & Sinha, 2013）：
    这些方法通过分层划分搜索空间，将数据划分为大量区域（对应于树叶节点），在搜索时仅访问少量可能包含目标点的区域。
2. **局部敏感哈希（LSH）方法**（Indyk & Motwani, 1998; Datar et al., 2004; Andoni & Indyk, 2008; Andoni et al., 2015）：
    此类方法将数据库中的点映射到若干哈希桶中，使得相邻点更容易发生哈希碰撞，而距离较远的点碰撞概率较低。在查询阶段，对查询点进行哈希映射，并计算与对应桶中所有点的距离。
3. **相似性图方法**（Navarro, 2002; Malkov & Yashunin, 2016; Fu & Cai, 2016; Fu et al., 2017）：
    该方法将数据库表示为图结构，在搜索阶段通过贪婪探索遍历图。与基于LSH和树的搜索方法相比，实验证明相似性图具有更高的性能（Malkov & Yashunin, 2016）。本文的研究属于最近邻搜索中基于相似性图的范畴。

------

更具体地说，相似性图的典型搜索过程如下：

数据库被组织成一个图，其中每个顶点对应一个数据点，相邻数据点的顶点通过边相连。搜索算法从某个顶点（随机或预定义）开始迭代探索图。在每次迭代中，查询会贪婪地尝试优化当前位置，移动到与查询距离最近的相邻顶点。

路由过程将在以下两种情况下停止：

1. 没有更近的相邻顶点；
2. 达到运行时间预算限制。

---

研究表明 (Navarro, 2002)，如果相似性图包含从数据库 $S$ 构建的 Delaunay 图中的所有边，那么上述贪婪路由可以保证找到精确的最近邻。然而，对于高维数据来说，完整 Delaunay 图的存储和遍历由于边的数量极多而变得不可行 (Beaumont et al., 2007)。因此，当前最先进的实际方法使用近似 Delaunay 图，通过限制顶点的最大度数来减少复杂度。然而，这种近似往往会导致局部最小值问题，即图遍历会卡在某个次优顶点，该顶点没有距离查询更近的邻居。

------

本文认为，局部最小值问题的主要原因在于路由决策仅基于每个顶点的局部信息，而没有明确考虑图的全局结构。我们的方法旨在通过为给定的相似性图学习路由函数来克服这一问题。具体来说，我们为每个顶点增加一个额外的紧凑表示，该表示在搜索阶段用于路由决策。这些表示通过显式最大化给定相似性图中的最优路由概率进行学习，从而明确考虑查询分布和全局图结构。此外，我们发现这些表示的维度通常可以小于原始数据的维度，这提高了路由计算的效率。

------

### 总结

本文的贡献总结如下：

1. 提出了一种在最先进的相似性图中学习路由函数的算法。该算法明确考虑了全局图结构，并减少了局部最小值问题。
2. 通过实验验证，该可学习路由在相同的运行时间预算下，显著提高了三个开源数据集的搜索准确率。
3. 我们的算法 PyTorch 源代码已在线发布 ${}^{1}$。

------

本文剩余部分的结构如下：第 2 节讨论相关工作，第 3 节介绍提出的可学习路由算法，第 4 节展示实验评估，第 5 节进行总结与讨论。

## 2. 相关工作

本节回顾了与我们方法相关的现有研究中的主要思想，这些思想将在方法描述中被引用。

------

### **最近邻搜索问题**

最近邻搜索问题在机器学习领域已被研究了数十年。关于最近邻搜索问题的两大经典研究方向包括局部敏感哈希（LSH）和分区树方法。这些方法具有坚实的理论基础，并可以估计搜索时间或成功搜索的概率 (Andoni & Indyk, 2008; Dasgupta & Sinha, 2013)。

最近，相似性图的范式已被证明在最近邻搜索中具有较高的效率。尽管相似性图目前尚未提供严格的理论保证，但其实验性能远高于树或LSH方法 (Malkov & Yashunin, 2016)。

------

### **相似性图**

对于一个数据库
$$
S=\left\{v_i \in \mathbf{R}^D \mid i=1, \ldots, n\right\}
$$

相似性图是一个图结构，其中每个顶点对应一个数据点 $v$。如果 $v_j$ 是 $v_i$ 的 $k$ 个最近邻之一（即 $v_j \in NN_k(v_i)$），则顶点 $v_i$ 与 $v_j$ 通过一条边相连。

在这种图中，搜索通过贪婪路由执行。查询从随机顶点开始，并在每一步从当前顶点移动到与查询距离最近的相邻顶点。当查询到达局部最小值或运行时间预算用尽时，搜索过程终止。

上述过程最早由 Navarro (2002) 提出，开启了基于相似性图的最近邻搜索研究。此后，许多基于该思想的方法被开发出来 (Malkov & Yashunin, 2016; Fu & Cai, 2016; Fu et al., 2017)。

本文旨在改进最新的相似性图之一——分层可导航小世界图 (HNSW) (Malkov & Yashunin, 2016) 的路由算法，因为该方法在常见基准测试中表现优越，并且其代码已公开。此外，其他类型的相似性图也可以使用我们提出的可学习路由方法。

------

在搜索过程中，HNSW 相似性图 (Malkov & Yashunin, 2016) 使用一个大小为 $L$ 的优先队列，存储需要被搜索过程访问的图顶点。当 $L=1$ 时，搜索等同于贪婪路由；当 $L>1$ 时，搜索过程类似于光束搜索 (Beam Search) (Shapiro, 1987)，从而降低搜索过程的贪婪性。

通常，通过调整 $L$ 可以在运行时间和搜索准确率之间进行权衡。

------

### **学习搜索**

学习搜索 (Learning to Search) (Daumé et al., 2009) 是一类解决结构化预测问题的方法，它通过学习在可能解空间中导航的方式来解决问题。这些方法通过引入一个参数化的搜索过程模型，并调整其参数以适应最优搜索策略。

学习搜索方法已广泛应用于多种任务，如词性标注 (Chang et al., 2015)、机器翻译 (Wiseman & Rush, 2016a; Negrinho et al., 2018)、场景标注 (Cheng et al., 2017) 等领域。

------

学习搜索可以被视为模仿学习 (Imitation Learning) (Ross et al., 2011; Ho & Ermon, 2016) 的扩展方法：训练一个搜索“代理”来模仿专家的搜索过程。这些专家是能够最优解决特定搜索问题的算法，例如生成最佳翻译结果。虽然专家决策不总是易于获取，但在有标签的训练数据上，通常可以通过任何精确搜索算法计算得到。

据我们所知，学习搜索方法尚未被应用于近似最近邻搜索任务。然而，该方法与前文讨论的相似性图搜索任务高度契合，具有广泛的应用潜力。

## 3. 方法

我们提出了一种模型，该模型直接学习如何在给定的相似性图中找到最近邻。为此，我们将图路由算法重新表述为一个概率模型，并通过最大化大量训练查询的最优路由概率来对其进行训练。

### 3.1. 随机搜索模型

在相似性图中进行导航的典型方法是光束搜索（算法 1）。本质上，这是一种迭代算法，它从已访问顶点的堆中逐步扩展到最近的顶点。当堆为空或运行时间预算用尽时，过程停止。本文聚焦于后一种预算设置，其中用户指定距离计算的限制。

---

我们将此算法推广为一种随机搜索：随机搜索不是选择与查询距离最小的顶点，而是从当前堆 $H$ 上的顶点中，根据 softmax 概率分布采样下一个顶点：

$$
\begin{equation*}
P\left(v_{i} \mid q, H\right)=\frac{e^{-d\left(v_{i}, q\right) / \tau}}{\sum_{v_{j} \in H} e^{-d\left(v_{j}, q\right) / \tau}} \tag{1}
\end{equation*}
$$

一旦随机搜索结束，它会从已访问的顶点集合 $V$ 上的 softmax 分布中采样 $k$ 个顶点作为搜索结果返回。如果 $\tau \rightarrow 0^{+}$，算法将恢复为原始的光束搜索（算法 1）。当 $\tau>0$ 时，算法有时可能会选择次优顶点。

---

我们的核心思想是将原始数据空间中的距离 $d\left(v_{i}, q\right)$ 替换为可学习映射的负内积： $-\left\langle f_{\theta}\left(v_{i}\right), g_{\theta}(q)\right\rangle$,从而得到以下概率分布：

$$
\begin{equation*}
P\left(v_{i} \mid q, H, \theta\right)=\frac{e^{\left\langle f_{\theta}\left(v_{i}\right), g_{\theta}(q)\right\rangle}}{\sum_{v_{j} \in H} e^{\left\langle f_{\theta}\left(v_{j}\right), g_{\theta}(q)\right\rangle}} \tag{2}
\end{equation*}
$$

其中，$f_{\theta}(\cdot)$ 是用于数据库点的神经网络，$g_{\theta}(\cdot)$ 是用于查询的另一个神经网络。网络参数 $f_{\theta}$ 和 $g_{\theta}$ 被联合训练，以帮助随机搜索找到实际最近邻 $v^{*}$ 并将其作为 $k$ 个输出数据点之一返回。

---

我们将在后文讨论具体的网络架构和优化细节。需要注意的是，使用我们可学习路由的算法 1 根据内积值 $\left\langle f_{\theta}\left(v_{i}\right), g_{\theta}(q)\right\rangle$ 返回前 $k$ 个结果，而原始最近邻搜索问题要求根据欧几里得距离找到最近邻。因此，作为最终搜索步骤，我们将基于原始空间中查询的欧几里得距离对检索到的前 $k$ 个数据点进行重新排序。

### 3.2. 最优路由

为了训练我们的模型选择最优顶点，我们引入了**最优路由**的概念——一种遵循从起始顶点到实际最近邻 $v^{*}$ 的最短路径的路由，并将其作为重新排序的前 $k$ 个候选项之一返回。为了简化讨论，我们假设计算预算足够大，使得算法能够通过该路由到达 $v^{*}$。

---

对于最优路由的正式定义，我们引入一个**oracle 函数** $\operatorname{Ref}(H)$。该函数从 $H$ 中选择在图边跳跃数上最接近实际最近邻 $v^{*}$ 的顶点。若一系列顶点序列满足以下条件，则该序列为最优路由：在每次迭代中，它扩展 $v_{i} \sim \operatorname{Ref}(H)$，直到找到实际最近邻 $v^{*}$。一旦找到 $v^{*}$，算法应将 $\operatorname{Ref}(V)$ 选为前 $k$ 个顶点之一。

---

在实际操作中，训练查询的 $\operatorname{Ref}(H)$ 值的获取过程如下：
我们通过简单的**广度优先搜索（BFS）算法**计算图中每个顶点到 $v^{*}$ 的跳跃距离，并返回跳跃次数最少的顶点。

为了提高训练效率，我们在训练开始之前为每个训练查询预先计算跳跃距离，并将所有训练查询的预计算距离存储在一个持久缓存中，以便在训练过程中动态访问。

---

为了优化内存需求，我们仅存储与查询搜索过程中可能访问的顶点相关的距离。这些顶点的选择基于一个简单的启发式规则：如果存在从起始顶点到实际最近邻 $v^{*}$ 的近似最优路径且经过该顶点，则选择该顶点。

具体而言，我们考虑所有路径，这些路径的长度最多比起始顶点到 $v^{*}$ 的最优路径长 $m=5$ 跳。

### 3.3. Training objective

我们训练概率搜索模型 (公式 2) 以执行最优路由。最直接的方法是显式最大化最优路由的对数似然函数：

$$
J_{\text {naive }}=\underset{q, v^*}{E} \log P(\operatorname{Opt}(q) \mid q, \theta)=\underset{\substack{q, v^*}}{E} \sum_{\substack{v_i, H_i \in  O p t(q)}} \log P(v_i \mid q, H_i, \theta)+\log P(v^* \in T o p K \mid q, V, \theta))
$$

其中，$v_{i}, H_{i} \in Opt(q)$ 表示在查询 $q$ 的最优路由过程中，每一步的顶点和堆状态的迭代过程；而 $P\left(v^{*} \in \operatorname{Top} K \mid q, V, \theta\right)$ 表示实际最近邻 $v^{*}$ 被选择为路由算法访问的前 $k$ 个数据点之一的概率。如果实际最近邻 $v^{*}$ 属于最终的前 $k$ 个候选点，则查询的整体搜索将成功，因为最终的 $k$ 个候选点会根据原始距离重新排序。

---

最大化目标函数 (公式 3) 只能训练算法在最优路由轨迹上的顶点进行搜索。然而，当应用于未见过的查询时，以这种方式学习的路由可能表现较差。

一旦搜索算法在任意路由步骤中出错（例如，选择了一个非最优顶点），错误顶点将被加入其堆 $H$ 中。因此，在发生单次错误后，搜索算法将进入训练过程中从未遇到的状态。换句话说，算法没有被训练来补偿其错误，导致一个小错误可能破坏后续所有的路由步骤。

---

为了缓解这一问题，我们调整了训练过程，使其更加接近**模仿学习（Imitation Learning）**的范式 (Attia & Dayan, 2018)。直观地说，我们允许算法基于当前参数 $f_{\theta}(\cdot)$ 和 $g_{\theta}(\cdot)$ 进行图的路由，并可能选择次优顶点。当搜索结束时，我们更新参数 $\theta$，强制算法在每个访问的顶点中遵循最优路由，即使之前发生了错误。

---

形式上，我们最大化以下目标函数：

$$
J_{i m i t}=\underset{q, v^*}{E} \sum_{\substack{v_i, H_i \in  \operatorname{Search}_\theta(q)}} \log P\left(v_i \in \operatorname{Re} f\left(H_i\right) \mid q, H_i, \theta\right)+\left.\log P\left(v^* \in \operatorname{Top} K \mid q, V, \theta\right)\right)
$$

其中，$v_{i}, H_{i} \in \operatorname{Search}*{\theta}(q)$ 表示在参数 $\theta$ 定义的路由（由 $f*{\theta}(\cdot)$ 和 $g_{\theta}(\cdot)$ 控制）下，查询 $q$ 的搜索过程中出现的顶点序列及相应的堆状态。注意，这与公式 (3) 不同，在公式 (3) 中我们只考虑最优路由轨迹。

---

在最大化公式 (4) 时，第一项 $\log P\left(v_{i} \in \operatorname{Ref}\left(H_{i}\right) \mid q, H_{i}, \theta\right)$ 的梯度通过对公式 (2) 关于 $\theta$ 求导得到。

第二项表示在搜索结束后，真实最近邻 $v^{*}$ 被选为前 $k$ 个最近候选点之一的概率。从数学上讲，该概率是从 (2) 中不放回采样 $k$ 个候选顶点时，$v^{*}$ 被选择为其中之一的概率。然而，精确计算此概率需要遍历所有可能的前 $k$ 个元素组合，对于较大的 $k$ 是不可行的。因此，我们采用类似于 (Wiseman & Rush, 2016b) 的近似方法。

具体而言，我们从 $v_{0}, \ldots, v_{k-1} \sim P\left(v_{i} \mid q, V \backslash\left\{v^{*}\right\}\right)$ 中不放回采样 $k-1$ 个顶点，然后计算 $v^{*}$ 从剩余顶点中被采样的概率： $P\left(v^{*} \mid q, V \backslash\left\{v_{0}, \ldots, v_{k-1}\right\}\right)$.

---

我们的方法可以被视为模仿学习中 **DAGGER 算法** (Ross et al., 2011) 的一个特例。实际上，在模仿学习的框架下，随机搜索算法 (2) 定义了一个**代理**。该代理通过模仿“专家”的决策进行训练，这些专家决策是通过广度优先搜索 (BFS) 预先计算得到的最优路径。

---

公式 (3) 和 (4) 之间的区别在图 1 中有直观展示。

- **公式 (3)：教师强制训练（Teacher Forcing）** (Williams & Zipser, 1989)。
  目标函数仅考虑最优路径上的顶点，粗体线条表示访问的顶点序列，红色箭头表示训练监督信号。
- **公式 (4)：模仿学习（Imitation Learning）** (Attia & Dayan, 2018)。
  模型在第 3 步发生错误并偏离最优路径，目标函数根据模型实际访问的顶点进行计算。在每个访问的顶点，“专家”指导参数如何调整以接近最优路径。

**图 1**
左侧：教师强制训练，目标函数仅累加最优路由上的点。
右侧：模仿学习，模型第 3 步出错偏离最优路由，目标函数根据模型实际访问的点进行计算。

### 3.4. 模型架构

上述算法允许 $f$ 和 $g$ 使用任意可微函数，这为模型设计提供了广泛的选择，例如线性投影、前馈神经网络以及图神经网络 (Zhou et al., 2018)。我们实验中使用的架构如图 2 所示。

**图 2**
大部分实验中使用的网络架构。

- **顶部**：Conv 模块，由图卷积层、ELU 非线性激活层以及全连接层组成。残差连接贯穿其中，该模块以层归一化结束。
- **左下角**：数据库分支 $f_{\theta}(\cdot)$，包含三个 Conv 模块，后接由两个带有 ELU 非线性的全连接层组成的前馈网络 (FFN)。
- **右下角**：查询分支 $g_{\theta}(\cdot)$，通常是恒等变换或线性映射。

---

#### **非对称架构设计**

我们的网络架构是**非对称的**，即 $f_{\theta}(\cdot)$ 和 $g_{\theta}(\cdot)$ 不共享参数。

1. **数据库分支 $f_{\theta}(\cdot)$**
   包含三个图卷积层 (Kipf & Welling, 2016)，采用 ELU 非线性激活 (Clevert et al., 2015)，并使用层归一化 (Ba et al., 2016) 和残差连接 (He et al., 2016) 来加速收敛。
   需要注意的是，由于顶点表示 $f_{\theta}(v)$ 可以离线预计算，因此 $f_{\theta}(\cdot)$ 的计算复杂度可以较高。
2. **查询分支 $g_{\theta}(\cdot)$**
   必须具有较高的计算效率，因为它需要在查询开始搜索之前进行在线计算。本文针对 $g_{\theta}(\cdot)$ 实验了两种选择：
   - **$g_{\theta}(q)=q$**：恒等变换。在这种情况下，$g_{\theta}(\cdot)$ 不需要额外的计算成本。
   - **$g_{\theta}(q)=W \times q$**，其中 $W \in \mathbf{R}^{d \times D}$：该方法将 $f_{\theta}(v)$ 和 $g_{\theta}(q)$ 的表示维度降至 $d$。如果 $d < D$，则计算内积 $\left\langle f_{\theta}(\cdot), g_{\theta}(q)\right\rangle$ 的复杂度为 $O(d)$，提高了路由效率。但这种选择在搜索阶段需要额外的 $O(d \times D)$ 查询预处理成本。

---

#### **训练过程**

我们的随机搜索模型 (公式 2) 使用小批量梯度下降算法在当前参数 $\theta$ 下诱导的概率分布上训练，这些概率分布基于路由轨迹的采样。

在所有实验中，我们采用 **Adam** (Kingma & Ba, 2014) 算法进行随机梯度下降 (SGD) 训练。同时，我们观察到采用 **One Cycle 学习率调度** (Smith & Topin, 2017) 可以显著加快收敛速度。

### 3.5. 搜索

模型训练完成后，我们会对所有数据库中的点离线预计算 $f_{\theta}\left(v_{i}\right)$，而查询会在运行时实时转换为 $q \rightarrow g_{\theta}(q)$。

搜索过程与算法 1 相同，唯一的区别是路由决策基于内积 $\left\langle f_{\theta}(\cdot), g_{\theta}(q)\right\rangle$ 而不是原始欧几里得距离。在路由停止后，根据 $\left\langle f_{\theta}(\cdot), g_{\theta}(q)\right\rangle$ 的最大值选取访问的前 $k$ 个顶点，并根据原始空间中查询的欧几里得距离对这些顶点重新排序。

------

### 3.6. 可扩展性

如后文所示，大部分实验在包含 100,000 个顶点和 100,000 个训练查询的图上进行。在此规模下，使用 12 核 CPU 预计算训练查询的 $\operatorname{Ref}(v)$ 函数大约需要 20 分钟。

使用单张 1080Ti GPU 进行深度神经网络 (DNN) 训练，采用第 3.4 节描述的架构，平均需要约 12 小时。

我们预计，算法训练可以扩展到更大规模的图上，训练时间将线性增长。此外，通过使用多 GPU 或图神经网络加速技术 (Chen et al., 2018)，训练性能可以进一步提升。不过，本研究未进行此类实验。

## 4. 实验

### 4.1. 示例实验

我们首先通过一个示例实验展示局部最小值问题及所提出可学习路由的优势。在该实验中，我们使用一个包含 33 个二维点的小型数据库，并将其组织成一个相似性图，如图 3 所示。

对于查询 $q$，基于原始数据点的贪婪路由（黄色边）陷入局部最小值，无法到达实际的最近邻。而基于学习表示的贪婪路由（橙色边）成功访问了真实最近邻。在该实验中，我们采用一个简单的两层感知机 (MLP) 作为 $f_{\theta}(\cdot)$，其隐藏层大小为 128。

------

**图 3**
 基于原始数据和学习表示的贪婪路由示例。数据库包含 33 个数据点，组织成相似性图。

当查询 $q$（灰色显示）进行搜索时，基于原始距离的贪婪路由（黄色显示）未找到真实值（深灰色显示），而是陷入了局部最小值。相比之下，基于学习表示的贪婪路由（橙色显示）成功到达最近邻。

### 4.2. 问题与数据集

本文聚焦于**预算限制的最近邻搜索** (Yu et al., 2017)，即用户指定计算次数的限制。在实验中，我们设置最大距离计算次数 ($DCS$)，并在此预算下比较不同方法的性能。

主要性能衡量指标为 **Recall@R**，其定义为真实最近邻出现在前 $R$ 个候选结果中的查询比例。

------

在以下实验中，我们设置 $DCS=128, 256, 512$，分别研究低、中、高 **Recall@1** 范围内的路由性能。

需要注意的是，所提出的可学习路由针对每个特定的 $DCS$ 值进行独立训练，以便顶点表示能够适应具体问题设置。我们始终基于**分层可导航小世界图 (Hierarchical Navigable Small World, HNSW)** (Malkov & Yashunin, 2016) 的底层结构训练路由表示，该图简称为 **NSW**。

------

### 数据集与设置

我们在三个公开可用的数据集上评估所提出的方法，这些数据集被广泛用作大规模最近邻搜索的基准：

1. **SIFT100K 数据集** (Jégou et al., 2011)：
    从包含 100 万个 128 维 SIFT 描述符中采样得到。我们将 100,000 个向量用作训练查询，并从剩余 10,000 个查询向量进行评估。
2. **DEEP100K 数据集** (Babenko & Lempitsky, 2016)：
    包含来自网络的自然图像中，通过 CNN 提取的 96 维特征向量，随机选择 100,000 个子集。我们从学习集中抽取 100,000 个训练查询，使用原始 10,000 个查询进行评估。
3. **GloVe100K 数据集** (Pennington et al., 2014)：
    包含维基百科 2014 和 Gigaword 5 中 300 维标准化 GloVe 向量表示。我们将原始 400,000 个词嵌入随机分为基础集和训练集，每个包含 100,000 个向量，并从剩余向量中抽取 10,000 个查询用于评估。

------

对于每个数据集，我们在基础集中构建 NSW 图，并将顶点的最大出度设置为 $\operatorname{Max} M=16$。同时，根据第 3 节描述的方法，为 $DCS=128, 256, 512$ 学习路由表示。

### 4.3. 路由评估

在第一组实验中，我们量化了使用学习表示替代原始数据点后路由性能的提升。

在此实验中，我们考虑了 128 和 256 的距离计算预算，并且不执行降维处理，即 $g_{\theta}(q)=q$。

------

**图 4** 展示了搜索算法根据跳跃次数找到实际最近邻的查询比例。

对于所有数据集，学习表示在路由性能上表现更佳，尤其是在极端预算（128 次距离计算）下。

例如，在 **SIFT100K** 数据集中，当 $DCS=128$ 和 $DCS=256$ 时，搜索算法分别实现了约 **15%** 和 **12%** 的更高成功检索率。

### 4.4. 搜索性能

在最重要的实验中，我们比较了 NSW 图在基于原始数据点和学习表示的路由性能。具体而言，我们进行了以下比较：

- **无降维情况 ($g_{\theta}(q)=q$)**：我们的方法与使用原始数据点进行路由的 NSW 图进行比较。
- **降维情况 ($g_{\theta}(q)=W \times q, W \in \mathbf{R}^{d \times D}$)**：我们的方法与以下基线进行比较：
   首先，通过 PCA 将基础向量压缩到维度 $d$（在基础集上训练）；然后在截断后的向量上构建新的 NSW 图。在搜索过程中，基于截断向量进行路由决策，并根据 $D$ 维向量对前 $K$ 个结果进行重新排序。

---

我们在 NSW 图上使用向量表示进行路由，并在距离计算预算耗尽之前收集长度为 $k$ 的候选列表。然后，根据查询与原始向量之间的距离对候选项进行重新排序，最终返回最佳候选项作为答案。

需要注意的是，当基于原始向量进行路由时，不需要执行重新排序。因此，除基于原始数据点的 NSW 方法外，所有比较方法都保留 $k$ 次距离计算用于重新排序阶段。

---

在降维场景中，我们针对 $\times 2$ 和 $\times 4$ 的压缩率 $C$ 进行了实验。在这种情况下，这些方法额外保留 $d$ 次距离计算用于矩阵-向量乘法。因此：

- **完整维度情况**：用于路由的距离计算预算为

$$
rDCS=(DCS−k)rDCS = (DCS - k)
$$

- **降维情况**：用于路由的距离计算预算为

$$
rDCS=C×(DCS−k−d)rDCS = C \times (DCS - k - d)
$$

所有实验结果均汇总在表 1 中，并列出了相应的 $k$ 和 $rDCS$ 值。以下是一些**关键观察结果**：

------

**表 1**：基于不同顶点表示的搜索性能 Recall@1。

- **前 $k$ 个候选项**是根据路由表示收集的，随后根据查询与原始数据点之间的距离重新排序。重新排序后最近的候选项作为最终搜索结果返回。
- **$rDCS$** 表示算法允许专门用于路由过程的距离计算次数。
- **$k$ 和 $rDCS$ 的值**设置为确保搜索过程总共执行恰好 $DCS$ 次距离计算。

---

首先，我们比较了**无降维情况下的路由性能**。在所有三个数据集中，基于学习表示且 $k=8$ 的搜索明显优于基于原始数据点的路由。例如，在 $DCS=128$ 时，所提出的方法在 **Recall@1** 上最多提升了 **13%**。

---

**压缩表示的路由性能**（后续通过重新排序）相比于完整尺寸表示的路由表现出显著更高的召回率，前提是 $d$ 远小于 $DCS$ 预算，即 $rDCS$ 不会变得过小。在大多数测试点中，我们观察到在相同 $DCS$ 预算下，使用压缩表示进行路由（包括 PCA 和本文方法）可获得性能提升。这表明压缩向量能够保留足够的信息以生成精确的候选列表，同时在相同计算成本下访问更多的顶点。

---

在低计算预算的激进运行点中，所提出的**可学习路由**的优势更为显著。然而，正如图 4 所示，在所有预算条件下，可学习路由总是能更快地到达真实最近邻。

**图 4**
展示了 $DCS=128$ 和 $DCS=256$ 条件下，根据跳跃次数成功找到实际最近邻的查询比例。在所有数据集中，学习表示提供了更高的路由质量。

---

**学习的低维表示**相较于 PCA 截断向量表现出更优的路由质量。在 $DCS=128$ 和 $DCS=256$ 的条件下，使用学习表示显著提高了搜索性能，尤其是在 **DEEP100K** 和 **GloVe100K** 数据集上。例如，在 **GloVe100K** 数据集中，基于我们低维向量的性能比基于 PCA 截断数据点的路由性能高出最多 **21%**。

### 4.5. 消融实验

在本节中，我们比较了所提出方法中 $f_{\theta}(\cdot)$ 的不同架构和训练目标。所有消融实验均在 **GloVe100K** 数据集上进行，实验设置为 $DCS=256, k=32$，并将维度压缩到 $d=\frac{D}{4}$。比较的方案如下：

- **PCA**：基于 PCA 截断向量进行路由，详细信息见第 4 节。
- **Ours**：本文提出的主要算法（第 3 节描述，第 4 节评估）。对于 $f_{\theta}(\cdot)$，我们采用图 2 中的架构，由三个包含 256 个滤波器的卷积块组成，后接一个前馈网络。前馈网络包含两个具有 4096 个隐藏单元和 ELU 非线性的全连接层。
- **Ours + Feed-forward**：与 Ours 相同，但 $f_{\theta}(\cdot)$ 是一个不包含卷积块的前馈网络。
- **Ours + Teacher Forcing**：与 Ours 相同，但训练目标替换为公式 (3)。代理仅在最优路由上训练，而不是自身的搜索轨迹。
- **Ours + TopK only**：与 Ours 相同，但训练目标仅包括 $\log P\left(v^{*} \in TopK \mid q, V, \theta\right)$ 项。因此，该代理只训练选择最佳顶点，而不学习如何遵循最优路由。

---

在第 3 节中，我们讨论了**朴素目标函数** (公式 3) 的问题，并提出了基于**模仿学习**范式的优化目标 (公式 4)。在本实验中，我们还对这些目标的优化效果进行了比较，结果如表 2 所示。

当模型使用 **教师强制训练目标 (Teacher Forcing)** 进行训练时，尽管其目标函数值更优，但召回率显著较低。这一结果是预期的，因为该模型未经过训练来处理自身的错误。

令人惊讶的是，仅使用 **TopK 目标** 训练仍然提供了较具竞争力的结果。

------

**表 2**：针对不同 $f_{\theta}(\cdot)$ 架构和训练目标的消融研究，基于 **GloVe100K 数据集** 的实验结果。实验设置为 $DCS=256, k=32$，压缩率为 $\times 4$。

### 4.6. 与现有 NNS 方法的比较

最后，我们将所提出的方法与现有的 NNS 方法在预算 $DCS=512$ 条件下进行了比较。

具体而言，比较中包括来自 Annoy 库 (Bernhardsson, 2012) 的**随机分区树集成方法**，它被认为是最有效的非图算法之一 ${ }^{2}$。我们还报告了最新的 **NSG 图** (Fu et al., 2017) 和多层 **HNSW 图** 的结果。实验结果汇总在表 3 中。

**表 3**：与现有 NNS 方法的实验比较结果。我们在 $DCS=512$ 预算下（无降维处理）提供了 **Recall@1** 值。

---

NSW 在学习表示上的表现优于所有基于原始数据的图方法，最多提升了 **9.4%**。

需要注意的是，本文方法的优势在高维问题上更加显著，这表明我们的可学习路由在高维空间中更具优势，因为高维空间中的路由问题更加复杂。

在 **SIFT100K** 数据集中，最高的搜索精度由 **NSG 图** 实现。然而，需要指出的是，我们提出的可学习路由同样可以应用于 **NSG 图**，进一步提高其性能。

## 5. 结论

本文提出了一种用于相似性图中 NNS 的**可学习路由算法**。

我们建议基于学习得到的顶点表示执行路由，这些表示经过优化，可提供从起始顶点到实际最近邻的最优路径。

通过实验评估，我们证明了本文算法对局部最小值问题更不敏感，并且在相同的计算预算下实现了更高的召回率。

本文方法的优势需要通过对大量训练查询进行离线深度神经网络 (DNN) 训练来实现，该训练过程不会增加额外的在线计算成本。

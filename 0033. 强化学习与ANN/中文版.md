#### 摘要

相似图（Similarity Graphs）是最近邻搜索（NNS）问题中的一个活跃研究方向。关于相似图构建的新算法不断被理论研究者和实践者提出和分析。然而，现有的构建算法大多基于启发式方法，并未明确最大化目标性能指标，即搜索召回率。因此，目前尚不清楚相似图的性能是否已达到瓶颈，或者是否可以通过更具理论基础的方法构建更高效的图。

本文提出了一种新的系统性算法，该算法基于邻接矩阵优化，明确地最大化了搜索效率。具体而言，我们提出了一种基于边概率定义的相似图的概率模型，并展示了如何将这些概率的学习过程建模为一个强化学习任务。实验结果证实，该构建方法可以用于改进现有的最先进相似图，从而在相同的距离计算次数下实现更高的召回率。此外，我们分析了学习到的图，并揭示了导致搜索更高效的结构特性。

## 1. 引言

本文讨论了最近邻搜索（NNS）这一长期存在的问题，该问题广泛应用于许多机器学习任务中，例如推荐服务、信息检索等。NNS问题的形式化描述如下：给定数据库 $D=\left\{v_{1}, \ldots, v_{N}\right\} \subset$ $\mathbb{R}^{d}$ 以及查询 $q \in \mathbb{R}^{d}$, 需要找到与查询最接近的数据点 $v \in D$。这里的距离依据某种度量标准（例如欧几里得距离）。随着实际任务中数据库大小 $|D|$ 的不断增长，NNS 的效率和可扩展性变得尤为关键。

---

因此，如何高效地解决 NNS 问题引起了机器学习社区的广泛关注。基于划分树（Bentley, 1975; Sproull, 1991; McCartin-Lim et al., 2012; Dasgupta & Freund, 2008; Dasgupta & Sinha, 2013）和局部敏感哈希（LSH）（Indyk & Motwani, 1998; Datar et al., 2004; Andoni & Indyk, 2008; Andoni et al., 2015）的成熟方法已被机器学习研究者开发了数十年，这些方法在实际应用中表现良好，并提供了理论保障。

近年来，相似图方法（Navarro, 2002; Malkov & Yashunin, 2016; Fu & Cai, 2016; Fu et al., 2017）被证明在性能上优于基于树和 LSH 的技术（Aumüller et al., 2017）。这些方法将数据库表示为图结构，并在搜索阶段通过波束搜索遍历图。虽然这些方法尚未得到完整的理论支持，但其卓越的实际表现已将研究焦点转向基于该范式的新方法开发。

---

由于最近邻搜索（NNS）问题的重要性，理论研究者（Laarhoven, 2018）和实践者（Fu & Cai, 2016; Malkov & Yashunin, 2016; Fu et al., 2017; Iwasaki & Miyazaki, 2018）不断提出和分析新的相似图构建算法。然而，这些研究大多提出的是基于启发式的方法，并未明确优化搜索效率。此外，不同方法通常仅在部分数据集上表现优越，这表明这些启发式方法并不具有普适性。

------

在本文中，我们提出了一种新的相似图构建方法，该方法通过优化图的邻接矩阵明确最大化搜索效率。具体而言，我们定义了一个基于边概率的相似图概率模型，并从数据中学习这些概率，以最大化大规模训练查询集的搜索效率。该任务可以自然地建模为强化学习问题。最终，该算法生成的图在性能上优于通过启发式方法构建的图。

---

总而言之，本文的贡献如下：

1. 我们开发了一种新的相似图构建算法，该算法明确优化搜索效率。据我们所知，所有现有方法均基于启发式策略，这些方法在适用性上可能存在局限性。
2. 通过在常用基准测试上的实验，我们证明了该算法可用于优化当前最先进的相似图，从而在相同的距离计算次数下实现更高的召回率。我们还分析了学习到的图结构，并探究了导致性能提升的特性。
3. 我们展示了强化学习工具在大规模实际应用中的创新性应用，该工具明确优化了具有数百万条边的相似图的质量。

------

本文其余部分的安排如下：首先，我们讨论相关的先前研究。然后，我们详细介绍基于强化学习的图构建算法，并对其进行实验分析，确认其相较于启发式方法的优势。此外，我们的算法和实验源代码可在网上获取。

## 2. 相关工作

在本节中，我们简要回顾与我们方法相关的先前研究中的一些思想。

**最近邻搜索技术。** 现有的最近邻搜索（NNS）方法主要分为三个研究方向。

第一类方法基于划分树（Bentley, 1975; Sproull, 1991; McCartin-Lim et al., 2012; Dasgupta & Freund, 2008; Dasgupta & Sinha, 2013）。这些方法将搜索空间按层次结构划分为多个区域，每个区域对应树的叶节点。在搜索过程中，查询仅访问有限数量的潜在区域。

第二类是局部敏感哈希（LSH）方法（Indyk & Motwani, 1998; Datar et al., 2004; Andoni & Indyk, 2008; Andoni et al., 2015）。这些方法利用多个哈希函数将数据库中的点映射到若干存储桶（buckets）中，使得相邻的点具有较高的哈希碰撞概率，而距离较远的点则具有较低的碰撞概率。在搜索阶段，查询点同样会被哈希化，并计算与相应存储桶中所有点之间的距离。

第三类是基于相似图的方法（Navarro, 2002; Malkov & Yashunin, 2016; Fu & Cai, 2016; Fu et al., 2017; Iwasaki & Miyazaki, 2018）。这些方法将数据库表示为一个有向图，在搜索阶段，查询通过波束搜索（beam search）遍历图。实验表明，相似图方法的实际性能远高于基于 LSH 和树结构的方法（Yu. A. Malkov, 2016）。

更具体地说，相似图的典型搜索过程如下：数据库组织成一个图，其中每个顶点对应一个数据点，相邻数据点对应的顶点通过边进行连接。搜索算法从一个起始顶点（随机或预定义）出发，并从该顶点开始迭代探索图。在每次迭代中，查询通过从候选池中选择与查询距离最近的顶点来改进其位置。当候选池中没有更近的顶点时，路由过程停止。

---

**相似图的构建过程。** 最近关于相似图方法的研究通常在图构建过程中采用不同的启发式策略，从而形成了多种变体。例如，最新的 HNSW 算法（Yu. A. Malkov, 2016）通过将数据库中的项连续插入图结构来构建图。这一过程为高效的图导航提供了远程边。此外，该算法还提出了一种嵌套层次结构，以进一步加快搜索速度。

另一个最新的图算法 NSG（Fu et al., 2017）将 k 近邻图作为初始图结构，然后通过将每个节点作为查询点执行搜索过程，将节点与搜索过程中访问的顶点连接，并根据剪枝策略选择边。

最近提出的基于图的方法 NGT-onng（Iwasaki & Miyazaki, 2018）则提供了一组启发式策略，用于图构建，并针对特定精度范围找到最优的入度和出度。

研究表明（Fu et al., 2017; Iwasaki & Miyazaki, 2018），不同图算法的优势在不同数据集上表现各异，这表明现有启发式方法存在一定的局限性。相比之下，我们的方法旨在通过数据学习图结构，明确优化搜索效率。

---

**数据结构学习。** 最近的一些研究工作（Kraska et al., 2018; 2019）提出使用机器学习方法替代传统的数据库索引结构，例如 B 树和布隆过滤器（Bloom Filters）。尽管这些方法与我们的研究方向相关，但它们并未直接应用于相似图的构建，而本文正是专注于这一问题。

------

**用于离散结构的强化学习。** 我们的方法部分受到了近年来强化学习在不同机器学习流程中用于结构学习的成功案例的启发。其中最知名的应用案例可能是深度神经网络（DNN）结构的学习（Zoph & Le, 2016）。另一个相关的研究是 DeepPath（Xiong et al., 2017），该研究利用强化学习来学习知识图谱的结构。在本文中，我们证明了强化学习同样适合于最近邻搜索（NNS）的相似图构建问题。

## 3. 方法

本节描述了我们基于强化学习的相似图构建方法。

### 3.1. 将相似图构建视为优化问题

首先，我们引入一个相似图的概率模型。该模型将图的概率定义为各个边的联合概率。每条边被建模为一个独立的伯努利随机变量 $b_{i} \sim \operatorname{Bern}\left(p_{i}\right)$ 该变量决定该边是否应存在于图中。因此，图 $G$ 的概率是所有边概率的乘积：$P(G)=P\left(b_{1}, b_{2}, \ldots, b_{n}\right)=$ $\prod_{i} p_{i}^{b_{i}}\left(1-p_{i}\right)^{1-b_{i}}$。 我们的目标是最大化以下目标函数：
$$
\begin{gather*}
P^{*}(G)=\underset{P(G)}{\arg \max } E_{q \sim p(q)} E_{G \sim P(G)} \mathcal{R}(G, q)  \tag{1}\\
\mathcal{R}(G, q)=\mathcal{F}(\operatorname{Accuracy}(G, q), \operatorname{Complexity}(G, q))
\end{gather*}
$$

其中，$E_{q \sim p(q)}$ 表示对查询分布的期望值。$\operatorname{Accuracy}(G, q)$ 和 $\operatorname{Complexity}(G, q)$ 分别代表高搜索召回率和高搜索效率。函数 $\mathcal{F}(\cdot, \cdot)$ 扮演“收益”（acquisition）函数的角色，将 $\operatorname{Accuracy}(G, q)$ 和 $\operatorname{Complexity}(G, q)$ 组合为一个标量值。我们将在下一节详细解释这些术语。

---

通过求解优化问题 (1)，我们找到一组边的概率 $\left\{p_{1}, \ldots, p_{n}\right\}$，在期望意义上同时最大化准确性并最小化搜索复杂度，其中图 $G \sim P(G)$。

最终，我们得到一个确定性的图 $G^{*}$，其定义为： $G^{*}=\arg \max _{G} P^{*}(G)$, 该图对应于保留边概率 $p \geq 0.5$ 的边，并去除概率 $p < 0.5$ 的边。随后，该图可以与标准搜索算法配合用于最近邻搜索（NNS）。

对于大规模问题，直接优化二次数量级的边是不可行的。在这种情况下，我们从某个初始相似图 $\hat{G}$ 出发，并通过优化问题 (1) 对其边进行裁剪和精简。最终得到的子图 $G^{*} \subseteq \hat{G}$ 在最近邻搜索性能方面更加高效。

对于小规模数据集，我们的目标是优化完整图结构，因为完整图一定包含最优解。

### 3.2. 马尔可夫决策过程（MDP）

现在我们将优化问题 (1) 表述为一个马尔可夫决策过程（MDP）。我们将初始图 $\hat{G}$ 和搜索算法视为环境 $\mathcal{E}$。MDP 智能体通过两个可用动作 $a$ 与环境交互：“移除”或“保留”一条边。

环境状态定义为： $s=\left(q, v_{i}, v_{a d j}, V, H\right)$ 其中包含查询 $q$、当前顶点 $v_{i}$、其相邻顶点 $v_{adj}$、已访问的顶点集合 $V$ 和候选堆 $H$。状态转移函数 $\mathcal{T}$ 表示搜索算法。在本文中，我们采用标准的 HNSW 搜索算法（Yu. A. Malkov, 2016），并将强化学习智能体嵌入到搜索过程之中，具体实现见算法 1。

---

**会话（Sessions）。**

我们引入会话 $\tau$ 的概念，将其定义为对单个查询 $q$ 的搜索过程。在每一步中，搜索过程访问一个顶点并更新状态 $s$。智能体获取状态 $s$ 并决定从该顶点出发保留哪些边。随后，搜索算法处理保留下来的边并选择下一个顶点。当搜索终止后，智能体会基于整个会话获得奖励 $\mathcal{R}$。

---

**奖励函数（Reward function）。**

我们的奖励函数 $\mathcal{R}(\tau)$ 综合了搜索过程中的两个关键指标：准确性和复杂度。

1. **准确性（Accuracy）：** 对于某个会话，如果实际的最近邻被成功找到，则使用指示函数 $I[\tau]$ 进行奖励。这一项鼓励智能体最大化搜索召回率。例如，它可能会排除导致搜索过程陷入局部最优解的边。
2. **复杂度（Complexity）：** 第二个指标度量会话中的距离计算次数 $DCS$。这一项鼓励智能体剪枝无关边，从而降低搜索复杂度。

---

我们将奖励函数定义为：
$$
\begin{equation*}
\mathcal{R}(\tau)=I[\tau] \cdot \max \left(D C S_{\max }-D C S, 1\right) \tag{2}
\end{equation*}
$$

其中，$D C S_{\text{max}}$ 是距离计算预算，用于限制每次查询的搜索复杂度。

直观地说，我们希望智能体在找到实际的最近邻之后，尽量减少计算复杂度，同时不降低准确性。如果最近邻未被找到，则无论 $DCS$ 如何，奖励 $R(\tau)=0$。相反，如果最近邻被找到，那么计算效率越高（即 $DCS$ 越小），智能体获得的奖励就越高。

对于较小的 $D C S_{\max }$ 值，智能体更倾向于牺牲某些查询的准确性，以提高其他查询的搜索效率。此外，我们观察到 $D C S_{\max }$ 的取值会通过改变目标函数的“陡峭度”影响算法的收敛速度。在实际应用中，我们根据平均顶点度和期望召回率区域，通过实验调整该参数。

### 3.3. 策略网络架构

在我们的方法中，智能体是一个预测边概率的策略网络。为简便起见，我们使用一个前愦神经网络结构，该网络对每条边分别进行处理：

$$
\pi_\theta(b \mid s)=\prod_i^n \pi_\theta\left(b_i \mid x_i(s)\right) \text { 。 }
$$


网络的输入是一条边，该边表示为源顶点和目标顶点的拼接向量：

$$
x_i(s)=\left[v_{\text {source }}, v_{\text {target }}\right],
$$

网络输出该边的存在概率。

网络本身由两层带有 ELU 激活函数的线性层组成，之启是一个带有 sigmoid 非线性函数的线性层。
虽然可以采用更强大的网络架构（例如图卷积网络（Graph Convolutional Networks，Kipf \＆
Welling，2016）），但由于 GPU 内存限制和训练时间较长，这些架构通常不适用于大规模场景。

### 3.4. 策略优化

现在，我们可以应用基于策略的强化学习（RL）方法，直接优化期望奖励函数 (2)。我们的方法整体流程如图 1 所示。

**图 1. 基于强化学习的图构建方案概览。** 图中展示了环境与智能体之间的交互过程。
 左侧：环境是一个带有搜索算法的相似图。在每一步中，搜索算法访问一个节点并更新环境状态。
 右侧：智能体接收状态并使用策略网络预测哪些边需要保留。然后，搜索过程处理保留的边并转移到下一个节点。当搜索结束时，智能体获得整个会话的总奖励。

------

在 REINFORCE（Williams & Peng, 1991）、PPO（Schulman et al., 2017）、ACKTR（Wu et al., 2017）等基于策略的方法中，我们发现 TRPO（Schulman et al., 2015）具有最快的收敛速度和最高的奖励值。

TRPO 的主要实际缺点是需要大量会话以执行精确的自然梯度更新。然而，在我们的场景中，每个会话仅需运行一次搜索算法，因此可以高效地并行采样大量搜索轨迹。

------

此外，我们针对该设置调整了两种常用的策略优化技巧：

1. **奖励基线（Reward Baselines）：** 为了加快收敛速度并减少梯度方差，我们使用奖励基线方法。算法针对每个训练查询维护一个单独的基线，作为该查询奖励的移动平均值。
2. **策略熵（Policy Entropy）：** 我们在训练目标中添加了策略熵以促进探索。这一经典技术（Williams & Peng, 1991）可防止智能体过早收敛到次优的确定性策略。

### 3.5. 大规模数据库上的训练

对于大规模问题，我们的方法在可考虑的边数量上存在限制。如果允许智能体在任意顶点之间绘制边，则边的数量会随着数据库规模呈二次方增长。因此，在典型的 NNS 问题中，基于完整图的大型数据库训练实际上是不可行的。

为了解决此问题，我们将智能体限制为预定义的边子集。具体而言，我们首先基于现有的启发式方法构建图，并允许智能体从该图中选择边。在所有实验中，初始图的顶点度数与基准图相等或略大，而这些基准图本身往往包含冗余边。

------

为了加速训练，我们还采用了以下启发式方法：

如果在训练过程中，智能体对某条边的预测在长时间内保持过于自信（例如概率接近 0 或 1），我们将该边视为确定性边，并不再对其进行优化。这一启发式方法降低了优化问题的复杂性，使智能体能够将注意力集中在预测较不确定的边上。

作为未来的研究方向，开发一种有效的方法来扩展搜索空间是值得探索的。例如，在训练过程中通过交互式动态添加新边来扩大搜索范围。

## 4. 实验

在本节中，我们对使用该方法构建的图进行评估和分析。首先，我们对一个小型数据集学习到的玩具示例图进行可视化，并描述一些有趣的观察结果。随后，我们将构建的图与最新的基于图的方法进行实验比较，并分析学习到的图所呈现的特性。

### 4.1. 玩具示例

我们对 MNIST8x8 数据集（Dua & Graff, 2017）的一个小子集使用该方法构建的图进行可视化分析。具体而言，我们从基础数据集中随机抽取 100 个 64 维向量，并将整个数据集用作训练查询集。

在此实验中，我们使用贪婪搜索作为搜索算法：在当前查询位置的邻居中选择距离最近的顶点作为下一个顶点。强化学习智能体从完整图开始训练，我们将 $D C S_{\max }$ 设置为 150。

训练结束后，我们手动移除搜索算法从未使用过的边。这些边既不会影响召回率，也不会影响 $D C S$，但会对顶点度分布带来噪声。

---

在收敛时，构建的图实现了 **0.957 的召回率**。平均而言，搜索算法需要 **22 次距离计算 ($DCS$)**，并在 **2.85 次图跳跃** 后终止。平均出度从 **99 降低到 2.45**。

最后，我们使用 tSNE 方法（Maaten & Hinton, 2008）将基础向量投影到二维平面，并在图 2（左图）中展示了图结构。顶点的颜色对应于 MNIST 的类别标签。搜索算法的起始顶点是基础集合的中位数点（medoid）。

**图 2.** 左图：在 MNIST8x8 数据集的 100 个向量上构建的图。优化是在完整图上执行的。颜色对应于 MNIST 的类别标签。提供高效导航的顶点（“枢纽”节点）用较大的节点尺寸表示。每个 MNIST 类别包含最多两个枢纽节点。右图：获得的图的出度直方图。大多数顶点的出度为零，只有少数顶点的出度大于 6。所有高出度的顶点均为枢纽节点。

------

为了分析学习到的相似图的特性，我们对所有查询运行搜索算法，并汇总以下统计数据：

1. 每个节点被访问的频率；
2. 每个节点作为实际最近邻的查询数量。

以下是从图 2 中总结出的几个关键观察结果，并结合我们的直觉解释适合 NNS 问题的图特性：

- **枢纽节点的出现：** 图中出现了一些称为“枢纽”的节点，这些节点提供了高效的图导航。每个 MNIST 类别包含一个或两个枢纽节点。起始节点通过连接到枢纽实现快速导航到查询区域。在第一步中，搜索会导航到一个枢纽节点，然后要么直接找到答案，要么跳转到另一个更接近实际最近邻的局部枢纽节点。枢纽的存在使得搜索算法仅需两到三次跳跃就能找到答案。同时，由于枢纽数量较少，平均节点出度保持较低。
- **大多数顶点不参与导航：** 搜索算法仅在某些顶点是查询的实际最近邻时才会访问这些顶点。这些顶点通常是终端节点，因此它们的出度几乎为零。

---

此外，我们在图 2（右图）中绘制了构建图的出度直方图。大多数顶点的出度为零，只有少数顶点的出度大于 6。这大致类似于截断幂律分布的出度分布。有趣的是，所有高出度节点都是枢纽节点。

先前的研究（Malkov & Ponomarenko, 2016）探讨了具有截断幂律度分布的图在 NNS 问题中的性质，并表明这种度分布可能会提供高效的搜索性能。在我们的方法中，这些特性是通过在完整图上优化搜索性能自然涌现的。

### 4.2. 数据集

我们在以下三个公开数据集上评估了所提出的方法：

1. **SIFT100K 数据集**（Jégou et al., 2011）：从 100 万个 128 维 SIFT 描述符中抽取的子集。我们选取 100,000 个向量作为学习集，剩余向量作为训练查询。需要注意的是，原始学习集中包含测试查询，因此我们手动将其删除。我们选取 20,000 个数据点用于验证，并使用 10,000 个保留查询向量进行评估。
2. **SIFT1M 数据集**：包含从 SIFT1B（Jégou et al., 2011）中抽取的 100 万个 SIFT 描述符。我们从学习集中抽取 100 万个训练查询。同样，保留 20,000 个查询用于验证，并使用原始 10,000 个保留查询进行评估。
3. **DEEP100K 数据集**（Babenko & Lempitsky, 2016）：包含从互联网上的自然图像中通过 CNN 提取的 10 亿个 96 维特征向量的子集。基础集包含 100,000 个向量。我们从学习集中抽取 200,000 个训练查询和 20,000 个验证查询，并使用原始的 10,000 个查询进行评估。
4. **DEEP1M 数据集**：与 DEEP100K 相同，但基础集和学习集扩展到 100 万个数据点。
5. **GloVe1M 数据集**（Pennington et al., 2014）：包含 220 万个在 Common Crawl 数据上训练得到的 300 维词嵌入向量。我们将其划分为 100 万个基础集、100 万个学习集、20,000 个验证查询和 10,000 个评估查询。

### 4.3. 搜索性能评估

在本节中，我们将使用该方法构建的图与最先进的基准方法在 SIFT100K 和 DEEP100K 数据集上进行比较。具体评估如下：

- **HNSW**：当前最先进的图之一，由 Yu. A. Malkov（2016）提出；该方法利用数据库子集上构建的可导航小世界图的嵌套层次结构来确定起始顶点。
- **NSW**：HNSW 图的底层。所有查询从固定顶点开始搜索。
- **NSG**：另一种先进的相似图方法（Fu et al., 2017）；NSG 不使用任何额外的索引结构，而是从数据库的中位数点（medoid）开始搜索。
- **NSW Ours**：将强化学习方法应用于 NSW 图。
- **NSG Ours**：将强化学习方法应用于 NSG 图。

------

我们在每个召回率区间为所有基准图调整超参数。所有图的具体参数列在附录中。

需要注意的是，所提出的基于 RL 的方法也可以应用于带有额外索引结构的图（例如 HNSW 和 NGT）。但这超出了我们评估的范围。

**主要性能度量：** 我们使用 **Recall@1** 作为主要性能指标，该指标表示搜索算法成功找到实际最近邻的查询比例。

大多数针对百万规模的数据集的实验在单个 GPU（GeForce 1080Ti）上大约 **24 小时** 内收敛。对于每个图，我们至少运行强化学习方法 **5 次**，并绘制其均值和标准差。

SIFT100K 和 DEEP100K 数据集的结果绘制在 **图 3** 中，SIFT1M、DEEP1M 和 GloVe1M 的结果绘制在 **图 4** 中。

---

在所有数据集上，我们观察到相较于对应的基准图存在持续性的性能提升。以下是一些关键观察结果：

- **SIFT100K 数据集：** 优化后的 NSG 图始终优于其他评估图。具体而言，与表现最好的 NSG 基准相比，优化后的 NSG 图的召回率最多提高了约 **1%**。
- **DEEP100K 数据集：** 优化后的 NSW 图也优于 HNSW/NSW 图，最高提升约 **1%**。然而，在 **99%+ 的 Recall@1 区间**，性能提升变得不显著。
  - 注意：NSG 图在 SIFT 数据集上表现更优，而 NSW/HNSW 在 DEEP100K 数据集上表现更好。这反映出基于启发式方法的相似图存在一定弱点：不同的启发式算法更适合于不同的数据集。
  - 我们的基于强化学习（RL）的方法可以显著缩小性能差距。例如，在 SIFT100K 数据集中，NSG 比 NSW 高出最多约 **2.5%**，但在优化后的图中，该差距缩小到 **0.4%** 左右。在 DEEP100K 数据集中，NSW/HNSW 比 NSG 高出最多约 **3.0%**，而优化后的 NSW 和 NSG 图之间的最大差距降至约 **1.3%**。
- **较低 Recall@1 区域：** 在所有数据集中，我们在较低的 Recall@1 区域观察到更显著的性能提升。这与我们的假设一致，即 RL 方法主要影响相似图的导航特性。与此同时，随着搜索算法堆大小增加，导航特性的作用会逐渐减弱，这也解释了为什么在高召回率区域性能提升较小。
- **NSW 与 HNSW 比较：** 在所有数据集和所有 Recall@1 区域中，优化后的 NSW 图的性能始终优于或等于 HNSW 图。后者通过额外的索引结构改进导航性能。这表明图的嵌套层次结构是冗余的，可以用优化后的 NSW 底层结构代替，从而提高导航性能。
- **GloVe1M 数据集：** 在最具挑战性的 GloVe1M 数据集中，由于词嵌入的内在维度较高，NSW/HNSW 图表现明显较差。然而，我们的方法缓解了 NSW/HNSW 图在该数据集中的缺陷，并在 **88% Recall@1** 区间超越基准图，提升约 **0.4%**。

### 4.4. 图属性分析

在本节中，我们分析所提出算法学习到的图的特性。我们的主要假设是，该方法在搜索效率方面的优势归因于其能够为图的顶点学习更为专门的角色，这与我们在玩具实验中的观察结果类似。

为了验证这一假设，我们研究了搜索算法频繁访问的顶点的统计属性。在 NSW 和 NSG 图中，都存在一小部分顶点，在前几次图跳跃中帮助搜索过程进行导航。因此，这些顶点的改进可能会对整体搜索效率产生重大影响。

---

我们选取了搜索算法最常访问的 **40 个顶点**，并统计它们在 **$10^5$ 个训练查询**中的访问次数。基准图与我们方法生成的图的访问次数统计结果如 **图 5** 所示。

**图 5** 清晰地表明，与基准图相比，我们的方法生成的图在顶点访问频率分布上更加陡峭（peaky）。换句话说，直接针对最近邻搜索优化的图产生了更为专门化的导航顶点。

**图 5.** 搜索访问频率分布：最常访问的 40 个顶点，按访问频率排序（不包括起始顶点）。

- **第一行：** 基准图访问频率分布；
- **第二行：** 我们方法优化后的图的访问频率分布。

---

有趣的是，我们的强化学习（RL）方法还能够学习新的起始顶点，参见 **图 5** 中 SIFT100K 数据集的 **NSW Ours**。智能体舍弃了初始起始顶点中的所有边，只保留一条。因此，对于每个查询，搜索过程仅通过一次距离计算就能跳转到新的起始节点。

值得注意的是，**图 5** 中分布的“尖峰性”（peakyness）与基于启发式方法的图在不同数据集上的相对性能存在相关性。例如，在 **SIFT100K 数据集** 上，NSG 拥有更显著的枢纽节点，因此在该数据集上优于 NSW（参见 **图 3**）。相比之下，在 **DEEP100K 数据集** 上，NSW 的分布比 NSG 更“尖峰”，因而提供了更好的搜索性能。

我们推测，与基于启发式方法的图相比，我们的算法在学习导航顶点的边时表现更好，从而实现了更精确的路径规划。

### 4.5. 与启发式方法的比较

在本实验中，我们将所提出的方法与一种启发式方法进行比较，该启发式方法可用于改进相似图。

这里，我们考虑基于**幅度剪枝**（magnitude-based pruning）的方法，其中每条边的权重计算如下：
$$
\begin{equation*}
w_{i j}=\frac{n \_v i s i t e d \_e_{i j}+\lambda}{n_{\_} \text {visited\_} v_{i}+\lambda \cdot \text { outdegree }\left(v_{i}\right)} \tag{3}
\end{equation*}
$$

其中，$n\_visited\_e_{i j}$ 和 $n\_visited\_v_{i}$ 分别表示边 $e_{i j}$ 和顶点 $v_{i}$ 的访问频率。我们通过在训练查询上运行搜索过程来计算这些频率。唯一的超参数 $\lambda$ 起到了平滑作用，防止对访问频率较低的顶点进行过度剪枝。在实验中，我们始终使用 $\lambda=0.1$。

随后，我们调整权重阈值，以最大化验证查询的性能。最终，所有权重低于阈值的边都会被剪除。

---

我们在 **DEEP1M 数据集** 上比较了基于 RL 的方法和应用幅度剪枝的 NSW 图，结果如 **图 6** 所示。

实验表明，在所有距离计算预算范围内，我们的方法均优于幅度剪枝方法。此外，我们将幅度剪枝应用于 RL 构建的图后，性能还进一步得到了轻微提升。

## 5. 结论

本文提出了一种新的相似图构建算法，该算法通过优化邻接矩阵，明确地最大化大量训练查询的搜索质量。

该算法基于边的概率定义了图的概率模型，并在强化学习场景中学习这些概率。

实验表明，所提出的方法能够改进由启发式方法构建的相似图的性能。

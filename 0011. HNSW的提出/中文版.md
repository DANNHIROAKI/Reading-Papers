### Efficient and robust approximate nearest neighbor search using Hierarchical Navigable Small World graphs  



# 0. Abstract

我们提出了一种基于可导航小世界图的新方法，用于近似 K 最近邻搜索，并具有可控的层次结构(分层 NSW，HNSW)。该解决方案完全基于图，不需要额外的搜索结构，这些结构通常在大多数邻近图技术的粗略搜索阶段使用。分层 NSW 逐步构建一个多层结构，由存储元素的嵌套子集的层次邻近图组成。每个元素所在的最大层次是通过具有指数衰减概率分布随机选择的。这使得生成的图类似于先前研究的可导航小世界(NSW)结构，同时还具有按其特征距离尺度分离的链接。从上层开始搜索，并利用尺度分离，与 NSW 相比显著提升了性能，并实现了对数复杂度的扩展。此外，使用启发式方法选择邻近图邻居在高召回率和高度聚类数据的情况下显著提高了性能。性能评估表明，所提出的一般度量空间搜索索引能够显著超越以前的开源最新向量仅方法。该算法与跳表结构的相似性允许简单的平衡分布式实现。



# 1. Introduction

不断增长的信息资源量导致了对可扩展和高效相似性搜索数据结构的高需求。K 最近邻搜索(K-NNS)是信息搜索中常用的一种方法。K-NNS 假设定义了数据元素之间的距离函数，旨在找到数据集中与给定查询距离最小的 $K$ 个元素。这类算法在许多应用中得到使用，例如非参数机器学习算法、大规模数据库中的图像特征匹配 [1] 和语义文档检索 [2]。K-NNS 的一种简单方法是计算查询与数据集中每个元素之间的距离，并选择距离最小的元素。不幸的是，简单方法的复杂度与存储元素的数量成线性比例增长，这使得在大规模数据集中不可行。这引发了对快速和可扩展 K-NNS 算法开发的高度关注。

---

精确的 K-NNS 解决方案 [3-5] 仅在相对低维数据的情况下能提供显著的搜索加速，这主要是由于“维度诅咒”。为了解决这个问题，提出了近似最近邻搜索(K-ANNS)的概念，该方法通过允许少量错误来放宽精确搜索的条件。非精确搜索的质量(召回率)定义为找到的真实最近邻的数量与 $K$ 的比例。最流行的 K-ANNS 解决方案基于树算法的近似版本 [6,7]、局部敏感哈希(LSH) [8,9] 和产品量化(PQ) [10-17]。基于邻接图的 K-ANNS 算法 [10, 18-26] 最近受到了欢迎，在高维数据集上提供了更好的性能。然而，邻接图路由的幂律缩放在低维或聚类数据的情况下会导致极端的性能下降。

---

在本文中，我们提出了分层可导航小世界(Hierarchical NSW，HNSW)，这是一种全图基增量 K-ANNS 结构，能够提供更好的对数复杂度缩放。主要贡献包括：明确选择图的入口节点、按不同尺度分隔链接以及使用先进的启发式方法选择邻居。另一方面，Hierarchical NSW 算法可以被视为概率跳表结构 [27] 的扩展，使用邻接图代替链表。性能评估表明，所提的通用度量空间方法能够显著超越之前仅适用于向量空间的开源最先进方法。



# 2. RELATED WORKS  

## 2.1. Proximity graph techniques  

在大多数研究的图算法中，搜索以贪婪路由的形式出现在 k-最近邻(k-NN)图中 [10, 18-26]。对于给定的邻接图，我们从某个入口点开始搜索(可以是随机的或由单独的算法提供)，并迭代地遍历图。在遍历的每一步，算法检查查询与当前基节点邻居之间的距离，然后选择最小距离的相邻节点作为下一个基节点，同时不断跟踪最佳发现的邻居。当满足某些停止条件时(例如，距离计算的数量)，搜索终止。在 k-NN 图中，链接到最近邻的边作为 Delaunay 图的简单近似 [25,26](该图保证基本贪婪图遍历的结果始终是最近邻)。不幸的是，在没有关于空间结构的先前信息的情况下，Delaunay 图无法高效构建，但可以通过使用存储元素之间的距离来进行最近邻的近似。研究表明，使用这种近似的邻接图方法在性能上与其他 k-ANNS 技术(如 kd-trees 或 LSH)具有竞争力 [18-26]。

---

k-NN 图方法的主要缺点是：1)在路由过程中，步骤数量随数据集大小的幂律缩放 [28,29]；2)可能丧失全局连通性，从而导致在聚类数据上的搜索结果较差。为了解决这些问题，许多混合方法被提出，这些方法使用仅适用于向量数据的辅助算法(如 kd-trees [18,19] 和产品量化 [10])通过进行粗搜索来找到更好的入口节点候选。

---

在文献 [25,26,30] 中，作者提出了一种名为可导航小世界(Navigable Small World, NSW，亦称为度量小世界，Metricized Small World, MSW)的邻接图 K-最近邻搜索(K-ANNS)算法，该算法利用了可导航图，即在贪婪遍历过程中，随着网络规模的增大，跳数的增长呈对数或多对数级别 [31,32]。NSW 图是通过按随机顺序连续插入元素构建的，插入时将新元素双向连接到先前插入元素中与之距离最近的 $M$ 个邻居。最近的 $M$ 个邻居是通过该结构的搜索过程找到的(这是从多个随机入口节点进行贪婪搜索的一种变体)。在构建开始时插入元素的最近邻之间的连接后来成为网络枢纽之间的桥梁，保持整体图的连通性，并允许在贪婪路由中跳数以对数方式增长。

---

NSW 结构的构建阶段可以高效并行化，而无需全局同步，并且对准确性没有可测的影响 [26]，因此是分布式搜索系统的良好选择。NSW 方法在某些数据集上表现出色 [33, 34]，然而，由于整体多对数复杂度的增长，该算法在低维数据集上仍然容易遭遇严重的性能下降(在这种情况下，NSW 的性能可能比树形算法低几个数量级 [34])。

## 2.2. Navigable small world models  

具有对数或多对数跳数扩展的贪婪图路由的网络被称为可导航小世界网络 [31,32]。这些网络是复杂网络理论的重要主题，旨在理解现实生活中网络形成的基本机制，以便将其应用于可扩展路由 [32,35,36] 和分布式相似性搜索 [25,26,30,37-40]。

---

最早考虑可导航网络空间模型的工作由 J. Kleinberg 完成 [31, 41]，作为著名米尔格伦实验 [42] 的社交网络模型。Kleinberg 研究了随机 Watts-Strogatz 网络 [43] 的一种变体，使用在 d 维向量空间中的规则格点图，并结合特定长链接长度分布 $r^{-\alpha}$ 的长程链接的增强。当 $\alpha=\mathrm{d}$ 时，通过贪婪路由到达目标的跳数以多对数级别扩展(而对于其他任何 $\alpha$ 值则是幂律扩展)。这一思想激发了许多基于导航效应的 K-NNS 和 K-ANNS 算法的发展 [37-40]。但尽管 Kleinberg 的可导航性标准原则上可以扩展到更一般的空间，为了构建这样的可导航网络，必须提前知道数据分布。此外，Kleinberg 图中的贪婪路由在最好的情况下也会遭遇多对数复杂度的扩展问题。

---

另一类著名的可导航网络是无尺度模型 [32, 35, 36]，这些模型能够再现现实网络的多个特征，并且被宣传用于路由应用 [35]。然而，这些模型生成的网络在贪婪搜索中的幂律复杂度扩展甚至更差 [44]，并且与 Kleinberg 模型一样，无尺度模型也需要对数据分布的全局知识，使其在搜索应用中不可用。

---

上述描述的 NSW 算法使用了一种更简单、以前未知的可导航网络模型，允许去中心化图构建，并适用于任意空间中的数据。有研究提出 [44]，NSW 网络形成机制可能与大规模生物神经网络的可导航性有关(其存在性仍有争议)：类似模型能够描述小型脑网络的生长，同时该模型预测了在大规模神经网络中观察到的多个高级特征。然而，NSW 模型在路由过程中也遭遇了多对数搜索复杂度的问题。



# 3. Motivation

改进 NSW 搜索复杂度的方法可以通过对路由过程的分析来识别，这一过程在 $[32,44]$ 中得到了详细研究。路由过程可以分为两个阶段：“缩小”和“放大” [32]。贪婪算法从一个低度节点开始，进入“缩小”阶段，同时增加节点的度，直到节点链接长度的特征半径达到与查询的距离相当的规模。在此之前，节点的平均度数可能保持相对较小，这会导致被困在遥远的虚假局部最小值的概率增加。

------

在 NSW 中，可以通过从度数最大的节点开始搜索来避免上述问题(良好的候选者是 NSW 结构中首先插入的节点 [44])，直接进入搜索的“放大”阶段。测试表明，将枢纽节点作为起始点显著增加了在该结构中成功路由的概率，并在低维数据上提供了显著更好的性能。然而，单次贪婪搜索仍然只有多对数复杂度的扩展能力，并且在高维数据上表现不如分层 NSW。

---

NSW 中单次贪婪搜索的多对数复杂度扩展的原因在于，总距离计算的数量大致与贪婪算法跳跃的平均次数与贪婪路径上节点的平均度数的乘积成正比。平均跳跃次数呈对数级增长 $[26,44]$，而贪婪路径上节点的平均度数也因以下事实而呈对数级增长：1) 随着网络的增长，贪婪搜索往往通过相同的枢纽 [32,44]；2) 随着网络规模的增加，枢纽连接的平均数量以对数级增长。因此，我们得到结果复杂度的总体多对数依赖关系。

---

分层 NSW 算法的思想是根据链接的长度规模将其分离成不同的层，然后在多层图中进行搜索。在这种情况下，我们可以独立于网络大小评估每个元素所需的固定部分连接，从而实现对数级的可扩展性。在这样的结构中，搜索从仅包含最长链接的上层开始(“放大”阶段)。算法从上层的元素中贪婪地遍历，直到达到局部最小值(见图 1 说明)。之后，搜索切换到下层(该层具有较短的链接)，从之前层的局部最小值元素重新开始，过程重复进行。所有层中每个元素的最大连接数可以保持不变，从而实现可导航小世界网络中路由的对数复杂度扩展。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922160228405.png" alt="image-20240922160228405" style="zoom: 40%;" /> 

图 1. 分层 NSW 思路的示意图。搜索从顶层的一个元素开始(显示为红色)。红色箭头表示从入口点到查询(显示为绿色)的贪婪算法的方向。

---

形成这种分层结构的一种方法是通过引入层来显式设置具有不同长度尺度的连接。对于每个元素，我们选择一个整数级别 $I$，该级别定义了元素所属的最大层。在每一层中，增量构建一个近似 Delaunay 图的邻接图(即仅包含“短”链接的图)。如果我们设置一个指数衰减的概率 $l$(即遵循几何分布)，我们就能获得结构中期望层数的对数缩放。搜索过程是从顶层开始的迭代贪婪搜索，直到零层结束。

---

如果我们合并所有层的连接，结构就类似于 NSW 图(在这种情况下，1 可以对应于 NSW 中的节点度数)。与 NSW 不同，分层 NSW 构建算法不要求在插入之前对元素进行洗牌——随机性通过使用层级随机化实现，因此即使在数据分布暂时变化的情况下，也可以实现真正的增量索引(尽管插入顺序的变化会稍微影响性能，因为构建过程只有部分确定性)。

---

分层 NSW 的概念也与著名的 1D 概率跳表结构非常相似，可以用其术语进行描述。与跳表的主要区别在于，我们通过用邻接图替换链表来推广结构。因此，分层 NSW 方法可以利用相同的方法来构建分布式近似搜索/叠加结构。

---

在元素插入过程中选择邻接图连接时，我们使用一种启发式方法，该方法考虑候选元素之间的距离，以创建多样化的连接(类似的算法在空间近似树中被用来选择树的子节点)，而不是仅选择最近的邻居。该启发式从离插入元素最近的候选者开始检查，只有当某个候选者相对于已连接候选者中的任何一个更接近基元素(插入元素)时，才创建与该候选者的连接(有关详细信息，请参见第 4 节)。

---

当候选者的数量足够大时，该启发式方法允许获得精确的相对邻接图作为子图，这是一种最小子图，可以通过仅使用节点之间的距离推导出 Delaunay 图。相对邻接图能够轻松保持全局连通分量，即使在高度聚类的数据情况下也是如此(见图 2 进行说明)。需要注意的是，该启发式方法创建了额外的边，与精确的相对邻接图相比，这使得可以控制连接的数量，这对搜索性能非常重要。对于一维数据，该启发式方法可以仅通过元素之间的距离信息获得精确的 Delaunay 子图(在这种情况下与相对邻接图重合)，因此可以直接从分层 NSW 转变为一维概率跳表算法。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922160619937.png" alt="image-20240922160619937" style="zoom: 40%;" /> 

图 2. 说明了用于选择图邻居的启发式方法，适用于两个孤立的聚类。一个新元素插入在聚类 1 的边界上。该元素的所有最近邻都属于聚类 1，因此错过了聚类之间 Delaunay 图的边。然而，该启发式方法选择了来自聚类 2 的元素 $e_2$，因此在插入的元素与聚类 1 中的任何其他元素相比，离 $e_2$ 更近的情况下，保持了全局连通性。

------

分层 NSW 邻接图的基本变体也在参考文献 [18] 中使用(称为“稀疏邻接图”)用于邻接图搜索。类似的启发式方法也是 FANNG 算法的重点 [47](在当前手稿的初始版本在线发布后不久)，其基于稀疏邻接图的精确路由特性，给出了稍微不同的解释。



# 4. ALGORITHM DESCRIPTION  

网络构建算法(**算法 1**)通过将存储的元素连续插入图结构中进行组织。对于每个插入的元素，随机选择一个整数最大层 $l$，其概率分布呈指数衰减(通过 $m_L$ 参数进行归一化，见算法 1 第 4 行)。

---

**Algorithm 1**: $\text { INSERT} \left(h n s w, q, M, M_{\max } \text {, efConstruction, } m L\right)$   

**Input**: 多层图 $h n s w$，新元素 $q$，已建立连接的数量 $M$，每层每个元素的最大连接数 $M_{\text{max}}$，动态候选列表的大小 efConstruction，层生成的归一化因子 $m L$

**Output**: 更新 $h n s w$ 插入元素 $q$ 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922161211517.png" alt="image-20240922161211517" style="zoom: 50%;" /> 

---

插入过程的第一阶段从顶部层开始，通过贪婪遍历图以寻找插入元素 $q$ 在该层的 ef 个最近邻。之后，算法继续从下一个层级开始搜索，使用前一层找到的最近邻作为入口点，过程重复。在每一层中，最近邻的寻找是通过**算法 2** 中描述的贪婪搜索算法的变体进行的，该算法是对文献 [26] 中算法的更新版本。为了获得某一层 $I_c$ 中的近似最近邻，搜索过程中保持一个动态列表 $W$，该列表包含 ef 个最近找到的元素(初始填充为入口点)。该列表在每一步中通过评估列表中最近的未评估元素的邻域进行更新，直到评估完列表中每个元素的邻域。与限制距离计算次数相比，Hierarchical NSW 的停止条件具有优势——它允许丢弃那些距离查询比列表中最远元素更远的候选项，从而避免搜索结构的膨胀。与 NSW 类似，该列表通过两个优先队列进行模拟以提高性能。与 NSW 的区别(以及一些队列优化)有：1)入口点是固定参数；2)搜索的质量通过不同的参数 ef 控制，而不是改变多次搜索的数量(在 NSW 中 ef 被设置为 $K$ [26])。在搜索的第一阶段，ef 参数设置为 1(简单贪婪搜索)，以避免引入额外的参数。

---

**Algorithm 2**: $\operatorname{SEARCH}-\operatorname{LAYER}\left(q, e p, e f, l_c\right)$ 

**Input**: 查询元素 $q$，入口点 $e p$，返回与 $q$ 最近的元素数量 ef，层级编号 $l_c$

**Output**: 与 $q$ 最近的 $e f$ 个邻居

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922161601087.png" alt="image-20240922161601087" style="zoom: 50%;" /> 

---

当搜索到达层级小于或等于 $l$ 时，构建算法的第二阶段开始。第二阶段有两个不同之处：1)ef 参数从 1 增加到 efConstruction，以控制贪婪搜索过程的召回率；2)在每层找到的最近邻也用作插入元素的连接候选。

---

**Algorithm 3**: $\operatorname{SELECT}-\operatorname{NEIGHBORS}-\operatorname{SIMPLE}\left(q, C,M\right)$  

**Input**: 基准元素 $q$，候选元素 $C$，要返回的邻居数量 $M$

**Output**: 距离 $q$ 最近的 $M$ 个元素

**Return**: 从 $C$ 中找到的 $q$ 最近的 $M$ 个元素

---

考虑了两种从候选中选择 $M$ 个邻居的方法：简单地连接到最近的元素(**算法 3**)和考虑候选元素之间距离以在不同方向创建连接的启发式方法(**算法 4**)，详见第 3 节。启发式方法有两个附加参数：extendCandidates(默认设置为 false)，用于扩展候选集，仅在极度聚类的数据中有用，以及 keepPrunedConnections，允许每个元素获得固定数量的连接。每层的最大连接数由参数 $M_{\max}$ 定义，零层以上的每层使用特殊参数 $M_{\max 0}$。如果在建立新连接时节点已满，则其扩展连接列表会通过与邻居选择相同的算法(算法 3 或 4)缩减。

---

**Algorithm 4**: $\small\text{SELECT-NEIGHBORS-HEURISTIC}(q,C,M,l_c,extendCandidates, keepPrunedConnections)$ 

**Input**: 基准元素 $q$，候选元素 $C$，要返回的邻居数量 $M$，层级编号 $l_c$，指示是否扩展候选列表的标志 `extendCandidates`，指示是否添加被丢弃元素的标志 `keepPrunedConnections` 

**Output**: 通过启发式方法选择的 $M$ 个元素

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922162617157.png" alt="image-20240922162617157" style="zoom:45%;" /> 

---

插入过程在零层建立了插入元素的连接后终止。

在层次 NSW 中使用的 K-ANNS 搜索算法在算法 5 中呈现。它大致等同于层为 $l=0$ 的项的插入算法。不同之处在于，底层找到的最近邻居现在作为连接的候选者，并返回作为搜索结果。搜索的质量由 ef 参数控制(对应于构造算法中的 efConstruction)。

## 4.1. Influence of the construction parameters  

算法构建参数 $m_L$ 和 $M_{\max 0}$ 负责维护构建图中的小世界可导航性。当 $m_L$ 设置为零(对应于图中的单层)且 $M_{\max }$ 设置为 $M$ 时，会产生具有已研究过的幂律搜索复杂度的有向 k-NN 图 [21, 29](假设使用算法 3 进行邻居选择)。将 $m_L$ 设置为零且 $M_{\max }$ 设置为无穷大会产生具有多对数复杂度的 NSW 图 [25, 26]。最后，将 $m_L$ 设置为某个非零值会导致可控层次图的出现，通过引入层实现对数搜索复杂度(见第 3 节)。

------

为了实现可控层次的最佳性能优势，不同层之间邻居的重叠(即属于其他层的元素邻居的百分比)必须较小。为了减少重叠，我们需要降低 $m_L$。然而，同时降低 $m_L$ 会导致每层贪婪搜索的平均跳数增加，这会对性能产生负面影响。这导致 $m_L$ 参数存在一个最佳值。

---

选择最优的 $m_L$ 的一个简单方法是 $1 / \ln (M)$，这对应于跳表参数 $p=1 / M$，使得层间的平均单个元素重叠。对 Intel Core i7 5930K CPU 上进行的模拟表明，所提出的 $m_L$ 选择是一个合理的选择(见**图 3**，数据基于 1000 万个随机 $\mathrm{d}=4$ 向量)。此外，该图还显示了在低维数据上，$m_L$ 从零增加时的巨大加速效果，以及使用启发式方法选择图连接的影响。对于高维数据，预期同样的行为是困难的，因为在这种情况下，$\mathrm{k}-\mathrm{NN}$ 图的贪婪算法路径已经非常短 [28]。令人惊讶的是，$m_L$ 从零增加在非常高维数据(100k 稠密随机 $d=1024$ 向量，见**图 4**)上导致了可测量的速度提升，并且对层次 NSW 方法没有带来任何惩罚。对于像 SIFT 向量 [1] 这样的真实数据(具有复杂的混合结构)，通过增加 $m_L$ 带来的性能提升更高，但在当前设置下，相比于启发式方法的提升不那么明显(见图 5，基于 500 万个 128 维 SIFT 向量的 1-NN 搜索性能，来自 BIGANN [13] 的学习集)。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922162956430.png" alt="image-20240922162956430" style="zoom: 25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922163044375.png" alt="image-20240922163044375" style="zoom: 25%;" />  <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922163139704.png" alt="image-20240922163139704" style="zoom: 25%;" /> 

图 3. 查询时间与$m_L$的关系图，基于10M随机向量，维度$\mathrm{d}=4$。箭头指示了自动选择的$m_L$值 $1 / \ln (M)$

图 4. 查询时间与$m_L$的关系图，基于100k随机向量，维度$\mathrm{d}=1024$。箭头指示了自动选择的$m_L$值 $1 / \ln (M)$

图 5. 查询时间与$m_L$的关系图，基于5M SIFT学习数据集。箭头指示了自动选择的 $m_L$ 值 $1 / \ln (M)$。

---

$M_{\max 0}$(元素在零层中可以拥有的最大连接数)的选择对搜索性能也有很大影响，尤其是在高质量(高召回率)搜索的情况下。模拟表明，将 $M_{\max }$ 设置为 $M$(如果不使用邻居选择启发式，则对应于每层的 kNN 图)会在高召回率下导致性能严重下降。模拟还表明，$2 \cdot M$ 是 $M_{\max 0}$ 的一个好选择：将参数设置得更高会导致性能下降和过多的内存使用。在**图 6** 中展示了 5M SIFT 学习数据集在 $M_{\max 0}$ 参数变化下的搜索性能结果(在 Intel Core i5 2400 CPU 上完成)。所建议的值在不同召回率下提供了接近最优的性能。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922163257567.png" alt="image-20240922163257567" style="zoom:40%;" /> 

图 6. 查询时间与 $M_{\max 0}$ 参数的关系图，基于 5M SIFT 学习数据集。箭头指示了自动选择的 $M_{\max 0}$ 值 $2 \cdot M$

---

在所有考虑的情况下，使用邻近图的启发式邻居选择方法(算法 4)相比于对最近邻的简单连接(算法 3)会导致更高或相似的搜索性能。这个效果在低维数据中最为明显，在中维数据的高召回率情况下以及在高度聚类数据的情况下也表现突出(意识形态的非连续性可以视为一种局部低维特征)，见**图 7** 的比较(Core i5 2400 CPU)。当使用最近邻作为邻近图的连接时，层次 NSW 算法在聚类数据上无法达到高召回率，因为搜索在聚类边界处停滞。相反，当使用启发式方法时(结合候选扩展，算法 4 的第 3 行)，聚类反而可以带来更高的性能。对于均匀和非常高维的数据，邻居选择方法之间的差异很小(见图 4)，这可能是因为在这种情况下几乎所有的最近邻都是通过启发式方法选择的。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922163350747.png" alt="image-20240922163350747" style="zoom:40%;" /> 

图 7. 邻居选择方法的效果(基准对应于算法 3，启发式对应于算法 4)在聚类(100 个随机孤立簇)和非聚类的 $d=10$ 随机向量数据上的表现。

------

用户剩下的唯一重要构造参数是 $M$。$M$ 的合理范围是从 5 到 48。模拟显示，较小的 $M$ 通常在低召回率和/或低维数据中产生更好的结果，而较大的 $M$ 在高召回率和/或高维数据中更好(见**图 8** 的示例，Core i5 2400 CPU)。该参数还定义了算法的内存消耗(与 $M$ 成正比)，因此应谨慎选择。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922163434112.png" alt="image-20240922163434112" style="zoom:40%;" /> 

图 8. 不同 $M$ 参数下，Hierarchical NSW 在 5M SIFT 学习数据集上的召回误差与查询时间的关系图。

---

efConstruction 参数的选择非常简单。如 [26] 中所建议的，它必须足够大，以在构建过程中产生接近 1 的 K-ANNS 召回率(对于大多数用例，0.95 已足够)。正如 [26] 中所述，这个参数也可以通过使用样本数据进行自动配置。

---

构建过程可以轻松高效地并行化，只需少量同步点(如**图 9** 所示)，对索引质量没有可测量的影响。构建速度与索引质量的权衡通过 efConstruction 参数进行控制。**图 10** 显示了 10M SIFT 数据集的搜索时间与索引构建时间之间的权衡，表明在一台 $4 \times 2.4 \mathrm{GHz}$ 的 10 核 Xeon E54650 v2 CPU 服务器上，只需 3 分钟就可以为 efConstruction 设置为 100 构建出合理质量的索引。进一步增加 efConstruction 只会带来少量额外性能，但会显著延长构建时间。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922163945000.png" alt="image-20240922163945000" style="zoom: 33%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922164024806.png" alt="image-20240922164024806" style="zoom: 33%;" />

图 9. 在两个 CPU 上，使用不同线程数构建 Hierarchical NSW 的 10M SIFT 数据集的构建时间。

图 10. 在 10M SIFT 数据集上，Hierarchical NSW 的查询时间与构建时间之间的权衡图。

## 4.2. Complexity analysis  

### 4.2.1. Search complexity  

单次搜索的复杂性缩放可以在假设我们构建的是精确的 Delaunay 图而不是近似图的情况下严格分析。假设我们在某层找到了最近的元素(这通过 Delaunay 图是可以保证的)，然后下降到下一层。可以证明，在找到该层的最近元素之前，平均步骤数是有常数界限的。

---

实际上，各层与数据元素的空间位置并不相关，因此在遍历图时，存在固定概率 $p=\exp \left(-m_L\right)$，使得下一个节点属于上层。然而，层内搜索始终在到达属于更高层的元素之前终止(否则，搜索在上层将停在其他元素上)，因此在第 $s$ 步未能到达目标的概率被界限为 $\exp \left(-s \cdot m_L\right)$。因此，在某层的期望步骤数被界限为几何级数之和 $S=1 /\left(1-\exp \left(-m_L\right)\right)$，这与数据集大小无关。

---

如果我们假设在大型数据集的极限情况下，Delaunay 图中一个节点的平均度数被常数 $C$ 限制(这对于随机欧几里得数据 [48] 是成立的，但在某些特殊空间中可能会违反)，那么每层中的距离评估的整体平均数目被常数 $C \cdot S$ 限制，与数据集大小无关。

---

而且，由于构造过程中最大层索引的期望值按 $\mathrm{O}(\log (N))$ 进行缩放，因此整体复杂性缩放为 $\mathrm{O}(\log (N))$，这与低维数据集的模拟结果一致。

---

在 Hierarchical NSW 中，最初假设的确切 Delaunay 图由于使用了每个元素固定数量的邻居的近似边选择启发式而违反。因此，为了避免陷入局部最小值，贪心搜索算法在零层上采用了回溯程序。模拟结果表明，至少对于低维数据(**图 11**，$d=4$)，为了获得固定的召回率，所需的 ef 参数(通过回溯过程中最小跳数决定复杂性)与数据集大小的关系会饱和。回溯复杂性是最终复杂性的附加项，因此，根据经验数据，Delaunay 图近似的不准确性并不会改变缩放。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922164208189.png" alt="image-20240922164208189" style="zoom:40%;" /> 

图 11. 获取固定准确度所需的 ef 参数与数据集大小的关系图(对于维度 $d=4$ 的随机向量数据)。

---

对 Delaunay 图近似鲁棒性的这种经验性研究需要平均 Delaunay 图边的数量与数据集无关，以证明在 Hierarchical NSW 中边的近似效果良好，且连接数保持不变。然而，Delaunay 图的平均度数随着维度的增加呈指数级增长 [39]，因此对于高维数据(例如 $d=128$)，上述条件要求数据集极大，这使得这样的经验性研究变得不可行。需要进一步的分析证据来确认 Delaunay 图近似的鲁棒性是否能够推广到更高维空间。

### 4.2.2. Construction complexity  

构建过程通过对所有元素的迭代插入完成，而插入一个元素仅仅是在不同层进行 K-ANN 搜索的一个序列，随后使用启发式方法(在固定的 efConstruction 下具有固定的复杂性)。每个元素被添加的平均层数是一个依赖于 $m_L$ 的常数：

$$E[l+1]=E\left[-\ln (\text { unif }(0,1)) \cdot m_L\right]+1=m_L+1$$

因此，插入的复杂性缩放与搜索的复杂性相同，这意味着至少对于相对低维的数据集，构建时间的缩放为 $\mathrm{O}(N \cdot \log (N))$。

### 4.2.3. Memory cost  

层次 NSW 的内存消耗主要由图连接的存储定义。零层每个元素的连接数为 $M_{\max0}$，而其他层的连接数为 $M_{\max}$。因此，每个元素的平均内存消耗为 $\left(M_{\max0}+m_L \cdot M_{\max }\right) \cdot\text{bytes\_per\_link}$。如果我们将元素的最大总数限制在大约四十亿，我们可以使用四字节的无符号整数来存储连接。测试表明，典型的接近最优的 $M$ 值通常在 6 到 48 之间。这意味着索引的典型内存需求(不包括数据的大小)约为每个对象 60-450 字节，这与模拟结果相符。



# 5. PERFORMANCE EVALUATION  

Hierarchical NSW 算法是在 Non Metric Space Library (nmslib) [49](https://github.com/searchivarius/nmslib)上用 C++ 实现的，该库已经有一个功能性的 NSW 实现(名为 "sw-graph")。由于库的若干限制，为了提高性能，Hierarchical NSW 的实现使用了自定义的距离函数以及 C 风格的内存管理，避免了不必要的隐式寻址，并在图遍历期间允许高效的硬件和软件预取。

---

比较 K-ANNS 算法的性能是一项复杂的任务，因为最先进的技术状态不断变化，新的算法和实现层出不穷。在这项工作中，我们重点比较了在欧几里得空间中具有开源实现的最佳算法。本文中介绍的 Hierarchical NSW 算法的实现也作为开源 nmslib 库的一部分进行分发(https://github.com/searchivarius/nmslib)，同时还提供了一个外部的 C++ 内存高效头文件版本，支持增量索引构建(https://github.com/nmslib/hnsw)。

---

比较部分包括四个部分：与基准 NSW 的比较 (5.1)，与欧几里得空间中最先进算法的比较 (5.2)，在 NSW 失败的一般度量空间中重新运行测试子集 [34] (5.3)，以及与在大型 200M SIFT 数据集上的最先进 PQ 算法的比较 (5.4)。

## 5.1. Comparison with baseline NSW  

对于基准 NSW 算法实现，我们使用了 nmslib 1.1 中的 "sw-graph"(与在 $[33,34]$ 中测试的实现相比略有更新)，以展示在速度和算法复杂性(通过距离计算次数来衡量)上的改进。

---

图 12(a) 展示了在 Core i5 2400 CPU 上进行的 $\mathrm{d}=4$ 随机超立方体数据的 Hierarchical NSW 与基本 NSW 算法的比较(10-NN 搜索)。Hierarchical NSW 在数据集搜索过程中使用的距离计算次数显著更少，尤其是在高召回率下。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922164341746.png" alt="image-20240922164341746" style="zoom: 35%;" /> 

图 12. NSW 与分层 NSW 的比较：(a) 在 1000 万个 4 维随机向量数据集上，距离计算次数与准确度之间的权衡； 

---

图 12(b) 展示了在 $\mathrm{d}=8$ 随机超立方体数据集上进行 10-NN 搜索(固定召回率 0.95)时算法的复杂度规模。结果清楚地表明，Hierarchical NSW 在此设置下的复杂度规模不低于对数级，并且在任何数据集大小下都优于 NSW。由于算法实现的改进，绝对时间上的性能优势(图 12(c))甚至更高。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922164400163.png" alt="image-20240922164400163" style="zoom: 35%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922164430668.png" alt="image-20240922164430668" style="zoom: 35%;" /> 

图 12. NSW 与分层 NSW 的比较：(b-c) 在 8 维随机向量数据集上，距离计算次数 (b) 和原始查询 (c) 时间的性能扩展。

## 5.2. Comparison in Euclid spaces  

比较的主要部分是在向量数据集上进行的，使用了流行的 K-ANNS 基准测试工具 ann-benchmark (https://github.com/erikbern/ann-benchmarks) 作为测试平台。测试系统利用算法的 Python 绑定，依次对一千个查询(从初始数据集中随机提取)运行 K-ANN 搜索，设置预设的算法参数，输出包含召回率和单次搜索的平均时间。考虑的算法包括：

1. 来自 nmslib 1.1 的基准 NSW 算法("sw-graph")。
2. FLANN 1.8.4 [6]。一个流行的库 (https://github.com/mariusmuja/flann)，包含多种算法，内置于 OpenCV (https://github.com/opencv/opencv) 中。我们使用可用的自动调优程序进行多次重跑，以推断最佳参数。
3. Annoy (https://github.com/spotify/annoy)，2016年2月2日版本。基于随机投影树森林的流行算法。
4. VP-tree。一个通用的度量空间算法，具有度量剪枝功能 [50]，作为 nmslib 1.1 的一部分实现。
5. FALCONN (https://github.com/FALCONN-LIB/FALCONN)，版本 1.2。用于余弦相似度数据的新型高效 LSH 算法 [51]。

---

比较是在一个配置为 4 × Xeon E5-4650 v2、运行 Debian 操作系统、配备 128 Gb RAM 的系统上进行的。对于每个算法，我们仔细选择了每个召回范围内的最佳结果，以评估可能的最佳性能(使用测试平台默认值的初始值)。所有测试均在单线程模式下进行。Hierarchical NSW 使用 GCC 5.3 编译，并启用了 -Ofast 优化标志。

---

使用的数据集的参数和描述在**表 1** 中列出。除了 GloVe 数据集外，我们对所有数据集使用了 $L_2$ 距离。对于 GloVe，我们使用余弦相似度，这在向量归一化后等同于 $L_2$ 距离。暴力搜索(BF)的时间由 nmslib 库测量。

| 数据集   | 描述                                  | 大小  | 维度 | BF 时间 | 空间 |
| :------- | :------------------------------------ | :---- | :--- | :------ | :--- |
| SIFT     | 图像特征向量 [13]                     | 1 M   | 128  | 94ms    | L 2  |
| GloVe    | 在推文上训练的词嵌入 [52]             | 1.2 M | 100  | 95ms    | 余弦 |
| CoPhIR   | 从图像中提取的 MPEG-7 特征 [53]       | 2 M   | 272  | 370ms   | L 2  |
| 随机向量 | 超立方体中的随机向量                  | 30 M  | 4    | 590ms   | L 2  |
| DEEP     | 十亿深度图像特征数据集的百万子集 [14] | 1 M   | 96   | 60ms    | L 2  |
| MNIST    | 手写数字图像 [54]                     | 60 k  | 784  | 22ms    | L 2  |

表 1. 向量空间基准测试中使用的数据集参数。

---

向量数据的结果在**图 13** 中展示。对于 SIFT、GloVe、DEEP 和 CoPhIR 数据集，Hierarchical NSW 明显以很大优势超越了其他算法。在低维数据($\mathrm{d}=4$)的情况下，Hierarchical NSW 在高召回率下的速度稍快于 Annoy，而在其他算法中则表现出显著优势。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165540909.png" alt="image-20240922165540909" style="zoom:25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165601778.png" alt="image-20240922165601778" style="zoom:25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165619881.png" alt="image-20240922165619881" style="zoom:25%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165648510.png" alt="image-20240922165648510" style="zoom:25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165707951.png" alt="image-20240922165707951" style="zoom:25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165720752.png" alt="image-20240922165720752" style="zoom:25%;" /> 

图 13. 在五个数据集上对分层 NSW 与开源 K-ANNS 算法实现进行比较的结果，针对 10-NN 搜索。暴力搜索的时间标记为 BF。

## 5.3. Comparison in general spaces  

最近对一般空间(即非对称或违反三角不等式)的算法进行的比较[34]显示，基线 NSW 算法在低维数据集上存在严重问题。为了测试 Hierarchical NSW 算法的性能，我们重复了[34]中的一部分测试，这些测试中 NSW 的表现不佳或不理想。为此，我们使用了内置的 nmslib 测试系统，该系统具有运行[34]测试的脚本。评估的算法包括 VP-tree、置换技术(NAPP 和暴力过滤)[49, 55-57]、基本 NSW 算法以及 NNDescent 生成的邻近图[29](两者与 NSW 图搜索算法配对)。与原始测试一样，对于每个数据集，测试包括 NSW 或 NNDescent 的结果，具体取决于哪个结构表现更好。在这种情况下，Hierarchical NSW 没有使用自定义距离函数或特殊内存管理，导致了一些性能损失。

---

数据集在表 2 中进行了汇总。有关数据集、空间和算法参数选择的更多详细信息，请参阅原始工作[34]。暴力搜索(BF)的时间由 nmslib 库测量。

|   数据集    | 描述                                                         | 大小(M) | d      | BF时间 | 距离                     |
| :---------: | :----------------------------------------------------------- | :-----: | :----- | :----- | :----------------------- |
| Wiki-sparse | TF-IDF(词频-逆文档频率)向量(通过 GENSIM [58]创建)            |    4    | 10$^5$ | 5.9s   | 稀疏余弦                 |
|   Wiki-8    | 从wiki-sparse数据集的稀疏TF-IDF向量创建的主题直方图(通过GENSIM[58]创建) |    2    | 8      | -      | Jensen-Shannon (JS) 散度 |
|  Wiki-128   | 从wiki-sparse数据集的稀疏 TF-IDF 向量创建的主题直方图(通过GENSIM [58] 创建) |    2    | 128    | 1.17 s | Jensen-Shannon (JS) 散度 |
|  ImageNet   | 从LSVRC-2014提取的签名，使用 SQFD(签名二次形式)距离[59]      |    1    | 272    | 18.3 s | SQFD                     |
|     DNA     | 从人类基因组5[34]采样的DNA(脱氧核糖核酸)数据集               |    1    | -      | 2.4 s  | Levenshtein              |

表 2. 用于重复非度量数据测试子集的数据集。

---

结果在图 14 中展示。Hierarchical NSW 显著改善了 NSW 的性能，并在所有测试数据集中处于领先地位。对于维度最低的数据集 wiki-8(使用 JS 散度)，相比 NSW 的提升几乎达到了 3 个数量级。这一重要结果表明了 Hierarchical NSW 的鲁棒性，因为对于原始 NSW，该数据集曾是一个障碍。请注意，为了消除实现效果的影响，wiki-8 的结果以距离计算次数而不是 CPU 时间进行呈现。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165830014.png" alt="image-20240922165830014" style="zoom:25%;" />  <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165847299.png" alt="image-20240922165847299" style="zoom:25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165900820.png" alt="image-20240922165900820" style="zoom:25%;" /> 

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165918730.png" alt="image-20240922165918730" style="zoom:25%;" /> <img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922165935269.png" alt="image-20240922165935269" style="zoom:25%;" /> 

图 14. 在五个数据集上，分层 NSW 与非度量空间库中的通用空间 K-ANNS 算法进行比较的结果，针对 10-NN 搜索。暴力搜索的时间标记为 BF。

## 5.4. Comparison with product quantization based algorithms  

产品量化 K-ANNS 算法 [10-17] 被认为是在十亿规模数据集上的最先进技术，因为它们能够高效压缩存储数据，在实现毫秒级搜索时间的同时仅需适度的 RAM 使用。

---

为了比较 Hierarchical NSW 与 PQ 算法的性能，我们使用了 Facebook 的 Faiss 库(https://github.com/facebookresearch/faiss，2017年5月构建)。自2018年起，Faiss 库拥有自己的 Hierarchical NSW 实现(一个包含最先进 PQ 算法 [12, 15] 实现的新库，在当前手稿提交后发布)，并使用 OpenBLAS 后端进行编译。测试是在一台配置为 4 X Xeon E5-4650 v2、128 GB RAM 的服务器上，对 1B SIFT 数据集的 200M 子集进行的。由于 ann-benchmark 测试平台依赖于 32 位浮点格式(仅存储数据就需要超过 100 GB)，因此不适合这些实验。为了获得 Faiss PQ 算法的结果，我们利用了 Faiss wiki 中的内置脚本(https://github.com/facebookresearch/faiss/wiki/Indexing-1G-vectors)。对于 Hierarchical NSW 算法，我们使用了一个独立于 nmslib 的特殊构建，具有小内存占用、简单的非向量化整数距离函数和增量索引构建支持(https://github.com/nmslib/hnsw)。

---

结果在图 15 中展示，参数汇总在表 3 中。峰值内存消耗通过在索引构建后使用 Linux 的 "time -v" 工具在单独测试运行中进行测量。尽管 Hierarchical NSW 需要显著更多的 RAM，但它可以实现更高的准确性，同时在搜索速度和索引构建速度上大幅提升。

| Algorithm        | Build time | Peak memory (runtime) | Parameters                     |
| :--------------- | :--------- | :-------------------- | :----------------------------- |
| Hierarchical NSW | 5.6 hours  | 64 Gb                 | $M=16$, efConstruction=500 (1) |
| Hierarchical NSW | 42 minutes | 64 Gb                 | $M=16$, efConstruction=40 (2)  |
| Faiss            | 12 hours   | 30 Gb                 | OPQ64, IMI2x14, PQ64 (1)       |
| Faiss            | 11 hours   | 23.5 Gb               | OPQ32, IMI2x14, PQ32 (2)       |

表 3. Hierarchical NSW 与 Faiss 在 10 亿 SIFT 数据集的 2 亿子集上的比较参数

---

图 15 中的插图展示了 Hierarchical NSW 查询时间与数据集大小的缩放关系。需要注意的是，缩放偏离了纯对数，可能是由于数据集的维度相对较高。

<img src="https://raw.githubusercontent.com/DANNHIROAKI/New-Picture-Bed/main/img/image-20240922170029488.png" alt="image-20240922170029488" style="zoom:33%;" /> 

图 15. 与 Faiss 库在 [13] 中的 200M SIFT 数据集上的比较结果。插图显示了分层 NSW 的查询时间与数据集大小的缩放关系。



# 6. DISCUSSION  

通过使用可导航的小世界图的结构分解以及智能邻居选择启发式方法，提出的 Hierarchical NSW 方法克服了基本 NSW 结构的一些重要问题，推动了 K-ANN 搜索的最新进展。Hierarchical NSW 在多种数据集上表现出色，在高维数据的情况下大幅超过开源对手。即使在之前的算法(NSW)相差几个数量级的情况下，Hierarchical NSW 也能够取得第一名。Hierarchical NSW 支持连续增量索引，并且可以作为获取 $\mathrm{k}-\mathrm{NN}$ 和相对邻域图的有效方法，这些都是索引构建的副产品。

---

该方法的鲁棒性是其一大优势，使其在实际应用中非常有吸引力。该算法适用于广义度量空间，在本文测试的所有数据集中表现最佳，从而消除了针对特定问题选择最佳算法的复杂性。我们强调算法鲁棒性的重要性，因为数据可能具有复杂的结构，在不同尺度下有效维度各异。例如，一个数据集可能由随机填充高维立方体的曲线上的点组成，因此在大尺度下是高维的，而在小尺度下是低维的。为了在这样的数据集中执行高效搜索，近似最近邻算法必须在高维和低维情况下都能良好运作。

---

还有几种方法可以进一步提高 Hierarchical NSW 方法的效率和适用性。仍然有一个重要参数会强烈影响索引的构建——每层添加的连接数 $M$。这个参数可以通过使用不同的启发式方法直接推断出来 [4]。对 Hierarchical NSW 在完整的 1B SIFT 和 1B DEEP 数据集上进行比较也是非常有趣的，并且可以增加对元素更新和删除的支持。

---

与基本 NSW 相比，提出的方法一个明显的缺点是失去了分布式搜索的可能性。在 Hierarchical NSW 结构中，搜索总是从最上层开始，因此无法使用 [26] 中描述的相同技术来使结构分布式，因为这会导致更高层元素的拥堵。可以使用一些简单的变通方法来分布该结构，例如在 [6] 中研究的数据在集群节点之间的分区，但在这种情况下，系统的总并行吞吐量与计算节点的数量不太能良好扩展。

---

尽管如此，还有其他已知的方法可以使该结构分布式。Hierarchical NSW 在理念上与著名的一维精确搜索概率跳表结构非常相似，因此可以使用相同的技术使结构分布式 [45]。这可能会导致比基础 NSW 更好的分布式性能，因为它具有对数级扩展性和理想的节点负载均匀性。





